{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TorchEBM - Energy-Based Modeling in PyTorch","text":"\ud83c\udf53 PyTorch Toolkit for Generative Modeling <p>       A high-performance PyTorch library that makes Energy-Based Models accessible and efficient for researchers and practitioners alike.     </p> \u2b50 Star on GitHub <p> </p> <p> TorchEBM provides components for \ud83d\udd2c sampling, \ud83e\udde0 inference, and \ud83d\udcca model training. </p> <p> Getting Started  Examples  API Reference  Development</p>"},{"location":"#what-is-torchebm","title":"What is \ud83c\udf53 TorchEBM?","text":"<p>TorchEBM is a PyTorch library for Energy-Based Models (EBMs), a powerful class of generative models. It provides a flexible framework to define, train, and generate samples using energy-based models.</p>"},{"location":"#core-components","title":"Core Components","text":"<p>TorchEBM is structured around several key components:</p> <ul> <li> <p> Models</p> <p>Define energy functions using <code>BaseModel</code>, from analytical forms to custom neural networks.</p> <p> Details</p> </li> <li> <p> Samplers</p> <p>Generate samples with MCMC samplers like Langevin Dynamics and Hamiltonian Monte Carlo.</p> <p> Details</p> </li> <li> <p> Loss Functions</p> <p>Train models with loss functions like Contrastive Divergence and Score Matching.</p> <p> Details</p> </li> <li> <p> Datasets</p> <p>Use synthetic dataset generators for testing and visualization.</p> <p> Details</p> </li> <li> <p> Visualization</p> <p>Visualize energy landscapes, sampling, and training dynamics.</p> <p> Details</p> </li> <li> <p> Accelerated Computing</p> <p>Accelerate sampling and training with CUDA implementations.</p> <p> Details</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Install the library using pip:</p> <pre><code>pip install torchebm\n</code></pre> <p>Here's a minimal example of defining an energy function and a sampler:</p> <pre><code>import torch\nfrom torchebm.core import GaussianModel\nfrom torchebm.samplers import LangevinDynamics\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GaussianModel(mean=torch.zeros(2), cov=torch.eye(2), device=device)\n\nsampler = LangevinDynamics(model=model, step_size=0.01, device=device)\n\ninitial_points = torch.randn(500, 2, device=device)\nsamples = sampler.sample(x=initial_points, n_steps=100)\n\nprint(f\"Output batch_shape: {samples.shape}\") # (B, len) -&gt; torch.Size([500, 2]) \n</code></pre> <p>Latest Release</p> <p>TorchEBM is currently in early development. Check our GitHub repository for the latest updates and features.</p>"},{"location":"#community-contribution","title":"Community &amp; Contribution","text":"<p>TorchEBM is an open-source project developed with the research community in mind.</p> <ul> <li>Bug Reports &amp; Feature Requests: Please use the GitHub Issues.</li> <li>Contributing Code: We welcome contributions! Please see the Contributing Guidelines. Consider following the Commit Conventions.</li> <li>Show Support: If you find TorchEBM helpful for your work, please consider starring the repository on GitHub! </li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>Please consider citing the TorchEBM repository if it contributes to your research:</p> <pre><code>@misc{torchebm_library_2025,\n  author       = {Ghaderi, Soran and Contributors},\n  title        = {TorchEBM: A PyTorch Library for Training Energy-Based Models},\n  year         = {2025},\n  url          = {https://github.com/soran-ghaderi/torchebm},\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>TorchEBM is available under the MIT License. See the LICENSE file for details.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>This page provides answers to frequently asked questions about TorchEBM. If you have a question that is not answered here, please feel free to open an issue on our GitHub repository.</p>"},{"location":"faq/#general","title":"General","text":"What is TorchEBM? <p>TorchEBM is a PyTorch-based library for Energy-Based Models (EBMs). It provides efficient, scalable, and CUDA-accelerated implementations of sampling, inference, and learning algorithms for EBMs.</p> How does TorchEBM differ from other generative modeling libraries? <p>TorchEBM specializes in energy-based models, which offer flexibility in modeling complex data distributions without requiring a normalized probability function. Unlike libraries for GANs or VAEs, TorchEBM is built around the energy function formulation and leverages MCMC-based sampling techniques.</p> What can I use TorchEBM for? <p>TorchEBM is suitable for a wide range of tasks, including:</p> <ul> <li>Generative modeling and density estimation</li> <li>Unsupervised representation learning</li> <li>Outlier and anomaly detection</li> <li>Exploring complex, high-dimensional energy landscapes</li> <li>Applications in scientific simulation and statistical physics</li> </ul>"},{"location":"faq/#installation-setup","title":"Installation &amp; Setup","text":"What are the system requirements for TorchEBM? <ul> <li>Python 3.8 or newer</li> <li>PyTorch 1.10.0 or newer</li> <li>CUDA (optional, but highly recommended for performance)</li> </ul> Does TorchEBM work on CPU-only machines? <p>Yes, TorchEBM is fully functional on CPU-only machines. However, for optimal performance, especially with large models and datasets, a GPU with CUDA support is recommended.</p> How do I install TorchEBM with CUDA support? <p>First, ensure you have installed CUDA drivers and a version of PyTorch installed that supports your CUDA toolkit. Then, you can install TorchEBM via pip:</p> <pre><code>pip install torchebm\n</code></pre>"},{"location":"faq/#technical","title":"Technical","text":"How do I diagnose sampling problems? <p>Common issues and potential solutions:</p> <ul> <li>Poor Mixing: Try increasing the step size, using more sampling steps, or switching to a more advanced sampler.</li> <li>Numerical Instability: Decrease the step size or check for numerical issues in your energy function.</li> <li>Mode Collapse: Your energy function may be too simple, or you might need a sampler with better exploration capabilities.</li> </ul> How do I train an energy-based model? <p>The basic training loop for an EBM involves these steps:</p> <ol> <li>Define an Energy Function: Typically a neural network that maps inputs to a scalar energy value.</li> <li>Choose a Loss Function: Such as contrastive divergence or maximum likelihood estimation.</li> <li>Set Up a Sampler: To generate negative samples from the model's distribution.</li> <li>Train: Use gradient descent to minimize the loss function.</li> <li>Evaluate: Assess the model's performance on a validation set.</li> </ol> <p>For a practical guide, see the training examples.</p>"},{"location":"faq/#performance","title":"Performance","text":"How can I speed up sampling? <p>To improve sampling performance:</p> <ul> <li>Use a GPU: This is the most effective way to accelerate sampling.</li> <li>Parallelize: Run multiple sampling chains in parallel.</li> <li>Tune Hyperparameters: Optimize sampler-specific parameters like step size.</li> <li>Choose the Right Algorithm: Some samplers are better suited for specific energy landscapes.</li> </ul> Does TorchEBM support distributed training? <p>Currently, TorchEBM is optimized for single-machine, multi-GPU training. Full distributed training support across multiple machines is on our roadmap.</p>"},{"location":"faq/#contributing","title":"Contributing","text":"How can I contribute to TorchEBM? <p>We welcome contributions! You can:</p> <ul> <li>Report Bugs: Open an issue on our GitHub repository.</li> <li>Suggest Features: Let us know what you'd like to see in future versions.</li> <li>Contribute Code: Check out our contributing guidelines to get started.</li> </ul> I found a bug, how do I report it? <p>Please open an issue on our GitHub repository and provide:</p> <ul> <li>A clear description of the problem.</li> <li>Steps to reproduce the issue.</li> <li>The expected versus actual behavior.</li> <li>Your TorchEBM, PyTorch, Python, and CUDA versions.</li> </ul> Can I add my own sampler or energy function? <p>Absolutely! TorchEBM is designed to be extensible. See our guides on:</p> <ul> <li>Custom Energy Models</li> <li>Implementing Custom Samplers</li> </ul>"},{"location":"faq/#future-development","title":"Future Development","text":"What features are planned for future releases? <p>See our Roadmap for planned features. We're always working on adding:</p> <ul> <li>Additional samplers and energy functions</li> <li>More loss functions for training</li> <li>Improved visualization tools</li> <li>Advanced neural network architectures</li> </ul> How stable is the TorchEBM API? <p>TorchEBM is in active development, so the API may evolve. We adhere to semantic versioning and will document any breaking changes in the release notes. </p>"},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tag:hamiltonian","title":"hamiltonian","text":"<ul> <li>            Hamiltonian Mechanics          </li> </ul>"},{"location":"tags/#tag:langevin","title":"langevin","text":"<ul> <li>            Langevin Dynamics Sampling with TorchEBM          </li> </ul>"},{"location":"tags/#tag:sampling","title":"sampling","text":"<ul> <li>            Hamiltonian Mechanics          </li> <li>            Langevin Dynamics Sampling with TorchEBM          </li> </ul>"},{"location":"tags/#tag:tutorial","title":"tutorial","text":"<ul> <li>            Langevin Dynamics Sampling with TorchEBM          </li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#torchebm-api-reference","title":"TorchEBM API Reference","text":"<p>Welcome to the TorchEBM API reference documentation. This section provides detailed information about the classes and functions available in TorchEBM.</p>"},{"location":"api/#package-structure","title":"Package Structure","text":"<p>TorchEBM is organized into several modules:</p> <ul> <li> Core </li> <li> Datasets </li> <li> Samplers</li> <li> Losses</li> <li> Utils</li> <li> CUDA</li> </ul>"},{"location":"api/#getting-started-with-the-api","title":"Getting Started with the API","text":"<p>If you're new to TorchEBM, we recommend starting with the following classes:</p> <ul> <li><code>BaseModel</code>: Base class for all models</li> <li><code>BaseSampler</code>: Base class for all sampling algorithms</li> <li><code>LangevinDynamics</code>: Implementation of Langevin dynamics sampling</li> </ul>"},{"location":"api/#core-components","title":"Core Components","text":""},{"location":"api/#models","title":"Models","text":"<p>TorchEBM provides various built-in models:</p> Model Description <code>GaussianModel</code> Multivariate Gaussian energy function <code>DoubleWellModel</code> Double well potential energy function <code>RastriginModel</code> Rastrigin function for testing optimization algorithms <code>RosenbrockModel</code> Rosenbrock function (banana function) <code>AckleyModel</code> Ackley function, a multimodal test function <code>HarmonicModel</code> Harmonic oscillator energy function"},{"location":"api/#samplers","title":"Samplers","text":"<p>Available sampling algorithms:</p> Sampler Description <code>LangevinDynamics</code> Langevin dynamics sampling algorithm <code>HamiltonianMonteCarlo</code> Hamiltonian Monte Carlo sampling"},{"location":"api/#baseloss-functions","title":"BaseLoss Functions","text":"<p>TorchEBM implements several loss functions for training EBMs:</p> BaseLoss Function Description <code>ContrastiveDivergence</code> Standard contrastive divergence (CD-k) <code>PersistentContrastiveDivergence</code> Persistent contrastive divergence <code>ParallelTemperingCD</code> Parallel tempering contrastive divergence"},{"location":"api/#module-details","title":"Module Details","text":"<p>For detailed information about each module, follow the links below:</p> <ul> <li>Core Module</li> <li>Samplers</li> <li>Losses</li> <li>Utils</li> <li>CUDA</li> </ul>"},{"location":"api/torchebm/","title":"Torchebm","text":""},{"location":"api/torchebm/#torchebm_1","title":"Torchebm","text":""},{"location":"api/torchebm/#contents","title":"Contents","text":""},{"location":"api/torchebm/#subpackages","title":"Subpackages","text":"<ul> <li>Core</li> <li>Cuda</li> <li>Datasets</li> <li>Integrators</li> <li>Interpolants</li> <li>Losses</li> <li>Models</li> <li>Samplers</li> <li>Utils</li> </ul>"},{"location":"api/torchebm/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/#torchebm","title":"torchebm","text":"<p>TorchEBM: Energy-Based Modeling library for PyTorch, offering tools for sampling, inference, and learning in complex distributions.</p>"},{"location":"api/torchebm/core/","title":"Torchebm &gt; Core","text":""},{"location":"api/torchebm/core/#torchebm-core","title":"Torchebm &gt; Core","text":""},{"location":"api/torchebm/core/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/#modules","title":"Modules","text":"<ul> <li>Base_integrator</li> <li>Base_interpolant</li> <li>Base_loss</li> <li>Base_model</li> <li>Base_sampler</li> <li>Base_scheduler</li> <li>Base_trainer</li> <li>Device_mixin</li> </ul>"},{"location":"api/torchebm/core/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/#torchebm.core","title":"torchebm.core","text":"<p>Core functionality for energy-based models, including energy functions, base sampler class, and training utilities.</p>"},{"location":"api/torchebm/core/base_integrator/","title":"Torchebm &gt; Core &gt; Base_integrator","text":""},{"location":"api/torchebm/core/base_integrator/#torchebm-core-base_integrator","title":"Torchebm &gt; Core &gt; Base_integrator","text":""},{"location":"api/torchebm/core/base_integrator/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_integrator/#classes","title":"Classes","text":"<ul> <li><code>BaseIntegrator</code> - Abstract integrator that advances a sampler state according to dynamics.</li> </ul>"},{"location":"api/torchebm/core/base_integrator/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_integrator/#torchebm.core.base_integrator","title":"torchebm.core.base_integrator","text":""},{"location":"api/torchebm/core/base_integrator/classes/BaseIntegrator/","title":"BaseIntegrator","text":""},{"location":"api/torchebm/core/base_integrator/classes/BaseIntegrator/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>DeviceMixin</code>, <code>Module</code>, <code>ABC</code></p> <p>Abstract integrator that advances a sampler state according to dynamics.</p> <p>The integrator operates on a generic state dict to remain reusable across samplers (e.g., Langevin uses only position <code>x</code>, HMC uses position <code>x</code> and momentum <code>p</code>).</p> <p>Methods follow PyTorch conventions and respect <code>device</code>/<code>dtype</code> from <code>DeviceMixin</code>.</p> Source code in <code>torchebm/core/base_integrator.py</code> <pre><code>class BaseIntegrator(DeviceMixin, nn.Module, ABC):\n    \"\"\"\n    Abstract integrator that advances a sampler state according to dynamics.\n\n    The integrator operates on a generic state dict to remain reusable across\n    samplers (e.g., Langevin uses only position `x`, HMC uses position `x` and\n    momentum `p`).\n\n    Methods follow PyTorch conventions and respect `device`/`dtype` from\n    `DeviceMixin`.\n    \"\"\"\n\n    def __init__(\n        self,\n        device: Optional[torch.device] = None,\n        dtype: Optional[torch.dtype] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(device=device, dtype=dtype, *args, **kwargs)\n\n    @abstractmethod\n    def step(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        *args,\n        **kwargs,\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"\n        Advance the dynamical state by one integrator application.\n\n        Args:\n            state: Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).\n            model: Energy-based model providing `forward` and `gradient`.\n            step_size: Step size for the integration.\n            *args: Additional positional arguments specific to the integrator.\n            **kwargs: Additional keyword arguments specific to the integrator.\n\n        Returns:\n            Updated state dict with the same keys as the input `state`.\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def integrate(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        n_steps: int,\n        *args,\n        **kwargs,\n    ) -&gt; Dict[str, torch.Tensor]:\n        \"\"\"\n        Advance the dynamical state by `n_steps` integrator applications.\n\n        Args:\n            state: Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).\n            model: Energy-based model providing `forward` and `gradient`.\n            step_size: Step size for the integration.\n            n_steps: The number of integration steps to perform.\n            *args: Additional positional arguments specific to the integrator.\n            **kwargs: Additional keyword arguments specific to the integrator.\n\n        Returns:\n            Updated state dict with the same keys as the input `state`.\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_integrator/classes/BaseIntegrator/#torchebm.core.base_integrator.BaseIntegrator.step","title":"step  <code>abstractmethod</code>","text":"<pre><code>step(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, *args, **kwargs) -&gt; Dict[str, torch.Tensor]\n</code></pre> <p>Advance the dynamical state by one integrator application.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>Dict[str, Tensor]</code> <p>Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).</p> required <code>model</code> <code>Optional[BaseModel]</code> <p>Energy-based model providing <code>forward</code> and <code>gradient</code>.</p> required <code>step_size</code> <code>Tensor</code> <p>Step size for the integration.</p> required <code>*args</code> <p>Additional positional arguments specific to the integrator.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments specific to the integrator.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Updated state dict with the same keys as the input <code>state</code>.</p> Source code in <code>torchebm/core/base_integrator.py</code> <pre><code>@abstractmethod\ndef step(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    *args,\n    **kwargs,\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"\n    Advance the dynamical state by one integrator application.\n\n    Args:\n        state: Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).\n        model: Energy-based model providing `forward` and `gradient`.\n        step_size: Step size for the integration.\n        *args: Additional positional arguments specific to the integrator.\n        **kwargs: Additional keyword arguments specific to the integrator.\n\n    Returns:\n        Updated state dict with the same keys as the input `state`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_integrator/classes/BaseIntegrator/#torchebm.core.base_integrator.BaseIntegrator.integrate","title":"integrate  <code>abstractmethod</code>","text":"<pre><code>integrate(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, n_steps: int, *args, **kwargs) -&gt; Dict[str, torch.Tensor]\n</code></pre> <p>Advance the dynamical state by <code>n_steps</code> integrator applications.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>Dict[str, Tensor]</code> <p>Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).</p> required <code>model</code> <code>Optional[BaseModel]</code> <p>Energy-based model providing <code>forward</code> and <code>gradient</code>.</p> required <code>step_size</code> <code>Tensor</code> <p>Step size for the integration.</p> required <code>n_steps</code> <code>int</code> <p>The number of integration steps to perform.</p> required <code>*args</code> <p>Additional positional arguments specific to the integrator.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments specific to the integrator.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Updated state dict with the same keys as the input <code>state</code>.</p> Source code in <code>torchebm/core/base_integrator.py</code> <pre><code>@abstractmethod\ndef integrate(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    n_steps: int,\n    *args,\n    **kwargs,\n) -&gt; Dict[str, torch.Tensor]:\n    \"\"\"\n    Advance the dynamical state by `n_steps` integrator applications.\n\n    Args:\n        state: Mapping containing required tensors (e.g., {'x': ..., 'p': ...}).\n        model: Energy-based model providing `forward` and `gradient`.\n        step_size: Step size for the integration.\n        n_steps: The number of integration steps to perform.\n        *args: Additional positional arguments specific to the integrator.\n        **kwargs: Additional keyword arguments specific to the integrator.\n\n    Returns:\n        Updated state dict with the same keys as the input `state`.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/","title":"Torchebm &gt; Core &gt; Base_interpolant","text":""},{"location":"api/torchebm/core/base_interpolant/#torchebm-core-base_interpolant","title":"Torchebm &gt; Core &gt; Base_interpolant","text":""},{"location":"api/torchebm/core/base_interpolant/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_interpolant/#classes","title":"Classes","text":"<ul> <li><code>BaseInterpolant</code> - Abstract base class for stochastic interpolants.</li> </ul>"},{"location":"api/torchebm/core/base_interpolant/#functions","title":"Functions","text":"<ul> <li><code>expand_t_like_x()</code> - Expand time tensor to match spatial dimensions of x.</li> </ul>"},{"location":"api/torchebm/core/base_interpolant/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_interpolant/#torchebm.core.base_interpolant","title":"torchebm.core.base_interpolant","text":"<p>Base class for interpolant schedules.</p>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/","title":"BaseInterpolant","text":""},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for stochastic interpolants.</p> <p>An interpolant defines a conditional probability path between a source distribution (typically Gaussian noise) and a target distribution (data).</p> <p>The interpolation is parameterized as:</p> \\[ x_t = \\alpha(t) x_1 + \\sigma(t) x_0 \\] <p>where \\(x_0 \\sim \\mathcal{N}(0, I)\\) and \\(x_1 \\sim p_{\\text{data}}\\).</p> <p>Subclasses must implement <code>compute_alpha_t</code> and <code>compute_sigma_t</code>.</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>class BaseInterpolant(ABC):\n    r\"\"\"\n    Abstract base class for stochastic interpolants.\n\n    An interpolant defines a conditional probability path between a source\n    distribution (typically Gaussian noise) and a target distribution (data).\n\n    The interpolation is parameterized as:\n\n    \\[\n    x_t = \\alpha(t) x_1 + \\sigma(t) x_0\n    \\]\n\n    where \\(x_0 \\sim \\mathcal{N}(0, I)\\) and \\(x_1 \\sim p_{\\text{data}}\\).\n\n    Subclasses must implement `compute_alpha_t` and `compute_sigma_t`.\n    \"\"\"\n\n    @abstractmethod\n    def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute the data coefficient \\(\\alpha(t)\\) and its time derivative.\n\n        Args:\n            t: Time tensor of shape (batch_size, ...).\n\n        Returns:\n            Tuple of (\\(\\alpha(t)\\), \\(\\dot{\\alpha}(t)\\)).\n        \"\"\"\n        raise NotImplementedError\n\n    @abstractmethod\n    def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute the noise coefficient \\(\\sigma(t)\\) and its time derivative.\n\n        Args:\n            t: Time tensor of shape (batch_size, ...).\n\n        Returns:\n            Tuple of (\\(\\sigma(t)\\), \\(\\dot{\\sigma}(t)\\)).\n        \"\"\"\n        raise NotImplementedError\n\n    def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute the ratio \\(\\dot{\\alpha}(t) / \\alpha(t)\\) for numerical stability.\n\n        This method can be overridden for better numerical precision.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            The ratio tensor.\n        \"\"\"\n        alpha, d_alpha = self.compute_alpha_t(t)\n        return d_alpha / torch.clamp(alpha, min=1e-8)\n\n    def interpolate(\n        self, x0: torch.Tensor, x1: torch.Tensor, t: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute the interpolated sample \\(x_t\\) and conditional velocity \\(u_t\\).\n\n        Args:\n            x0: Noise samples of shape (batch_size, ...).\n            x1: Data samples of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Tuple of (x_t, u_t) where:\n                - x_t = \u03b1(t) x\u2081 + \u03c3(t) x\u2080\n                - u_t = \u03b1\u0307(t) x\u2081 + \u03c3\u0307(t) x\u2080\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x0)\n        alpha, d_alpha = self.compute_alpha_t(t_expanded)\n        sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n        xt = alpha * x1 + sigma * x0\n        ut = d_alpha * x1 + d_sigma * x0\n\n        return xt, ut\n\n    def compute_drift(\n        self, x: torch.Tensor, t: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute drift coefficients for score-based parameterization.\n\n        For the probability flow ODE in score parameterization:\n        dx = [-drift_mean + drift_var * score] dt\n\n        Args:\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Tuple of (drift_mean, drift_var) for score parameterization.\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x)\n        alpha_ratio = self.compute_d_alpha_alpha_ratio_t(t_expanded)\n        sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n        drift_mean = alpha_ratio * x\n        drift_var = alpha_ratio * (sigma**2) - sigma * d_sigma\n\n        return -drift_mean, drift_var\n\n    def compute_diffusion(\n        self, x: torch.Tensor, t: torch.Tensor, form: str = \"SBDM\", norm: float = 1.0\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute diffusion coefficient for SDE sampling.\n\n        Args:\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n            form: Diffusion form ('constant', 'SBDM', 'sigma', 'linear').\n            norm: Scaling factor for diffusion.\n\n        Returns:\n            Diffusion coefficient tensor.\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x)\n        sigma, _ = self.compute_sigma_t(t_expanded)\n        _, drift_var = self.compute_drift(x, t)\n\n        forms = {\n            \"constant\": norm * torch.ones_like(drift_var),\n            \"SBDM\": norm * drift_var / (sigma + 1e-8),\n            \"sigma\": norm * sigma,\n            \"linear\": norm * (1 - t_expanded),\n        }\n        if form not in forms:\n            raise NotImplementedError(f\"Diffusion form '{form}' not implemented\")\n        return forms[form]\n\n    def velocity_to_score(\n        self, velocity: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Convert velocity prediction to score.\n\n        Args:\n            velocity: Predicted velocity of shape (batch_size, ...).\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Score tensor of shape (batch_size, ...).\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x)\n        alpha, d_alpha = self.compute_alpha_t(t_expanded)\n        sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n        alpha = torch.clamp(alpha, min=1e-8)\n        reverse_alpha_ratio = alpha / d_alpha\n        var = sigma**2 - reverse_alpha_ratio * d_sigma * sigma\n        score = (reverse_alpha_ratio * velocity - x) / torch.clamp(var, min=1e-12)\n\n        return score\n\n    def velocity_to_noise(\n        self, velocity: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Convert velocity prediction to noise prediction.\n\n        Args:\n            velocity: Predicted velocity of shape (batch_size, ...).\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Noise tensor of shape (batch_size, ...).\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x)\n        alpha, d_alpha = self.compute_alpha_t(t_expanded)\n        sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n        d_alpha = torch.where(d_alpha.abs() &lt; 1e-8, torch.ones_like(d_alpha) * 1e-8, d_alpha)\n        reverse_alpha_ratio = alpha / d_alpha\n        var = sigma - reverse_alpha_ratio * d_sigma\n        var = torch.where(var.abs() &lt; 1e-12, torch.sign(var) * 1e-12 + (var == 0) * 1e-12, var)\n        noise = (x - reverse_alpha_ratio * velocity) / var\n\n        return noise\n\n    def score_to_velocity(\n        self, score: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Convert score prediction to velocity.\n\n        Args:\n            score: Predicted score of shape (batch_size, ...).\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Velocity tensor of shape (batch_size, ...).\n        \"\"\"\n        drift_mean, drift_var = self.compute_drift(x, t)\n        velocity = drift_var * score - drift_mean\n        return velocity\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.compute_alpha_t","title":"compute_alpha_t  <code>abstractmethod</code>","text":"<pre><code>compute_alpha_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute the data coefficient \\(\\alpha(t)\\) and its time derivative.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor of shape (batch_size, ...).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\\(\\alpha(t)\\), \\(\\dot{\\alpha}(t)\\)).</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>@abstractmethod\ndef compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute the data coefficient \\(\\alpha(t)\\) and its time derivative.\n\n    Args:\n        t: Time tensor of shape (batch_size, ...).\n\n    Returns:\n        Tuple of (\\(\\alpha(t)\\), \\(\\dot{\\alpha}(t)\\)).\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.compute_sigma_t","title":"compute_sigma_t  <code>abstractmethod</code>","text":"<pre><code>compute_sigma_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute the noise coefficient \\(\\sigma(t)\\) and its time derivative.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor of shape (batch_size, ...).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\\(\\sigma(t)\\), \\(\\dot{\\sigma}(t)\\)).</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>@abstractmethod\ndef compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute the noise coefficient \\(\\sigma(t)\\) and its time derivative.\n\n    Args:\n        t: Time tensor of shape (batch_size, ...).\n\n    Returns:\n        Tuple of (\\(\\sigma(t)\\), \\(\\dot{\\sigma}(t)\\)).\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.compute_d_alpha_alpha_ratio_t","title":"compute_d_alpha_alpha_ratio_t","text":"<pre><code>compute_d_alpha_alpha_ratio_t(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute the ratio \\(\\dot{\\alpha}(t) / \\alpha(t)\\) for numerical stability.</p> <p>This method can be overridden for better numerical precision.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The ratio tensor.</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute the ratio \\(\\dot{\\alpha}(t) / \\alpha(t)\\) for numerical stability.\n\n    This method can be overridden for better numerical precision.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        The ratio tensor.\n    \"\"\"\n    alpha, d_alpha = self.compute_alpha_t(t)\n    return d_alpha / torch.clamp(alpha, min=1e-8)\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.interpolate","title":"interpolate","text":"<pre><code>interpolate(x0: Tensor, x1: Tensor, t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute the interpolated sample \\(x_t\\) and conditional velocity \\(u_t\\).</p> <p>Parameters:</p> Name Type Description Default <code>x0</code> <code>Tensor</code> <p>Noise samples of shape (batch_size, ...).</p> required <code>x1</code> <code>Tensor</code> <p>Data samples of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (x_t, u_t) where: - x_t = \u03b1(t) x\u2081 + \u03c3(t) x\u2080 - u_t = \u03b1\u0307(t) x\u2081 + \u03c3\u0307(t) x\u2080</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def interpolate(\n    self, x0: torch.Tensor, x1: torch.Tensor, t: torch.Tensor\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute the interpolated sample \\(x_t\\) and conditional velocity \\(u_t\\).\n\n    Args:\n        x0: Noise samples of shape (batch_size, ...).\n        x1: Data samples of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Tuple of (x_t, u_t) where:\n            - x_t = \u03b1(t) x\u2081 + \u03c3(t) x\u2080\n            - u_t = \u03b1\u0307(t) x\u2081 + \u03c3\u0307(t) x\u2080\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x0)\n    alpha, d_alpha = self.compute_alpha_t(t_expanded)\n    sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n    xt = alpha * x1 + sigma * x0\n    ut = d_alpha * x1 + d_sigma * x0\n\n    return xt, ut\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.compute_drift","title":"compute_drift","text":"<pre><code>compute_drift(x: Tensor, t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute drift coefficients for score-based parameterization.</p> <p>For the probability flow ODE in score parameterization: dx = [-drift_mean + drift_var * score] dt</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (drift_mean, drift_var) for score parameterization.</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def compute_drift(\n    self, x: torch.Tensor, t: torch.Tensor\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute drift coefficients for score-based parameterization.\n\n    For the probability flow ODE in score parameterization:\n    dx = [-drift_mean + drift_var * score] dt\n\n    Args:\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Tuple of (drift_mean, drift_var) for score parameterization.\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x)\n    alpha_ratio = self.compute_d_alpha_alpha_ratio_t(t_expanded)\n    sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n    drift_mean = alpha_ratio * x\n    drift_var = alpha_ratio * (sigma**2) - sigma * d_sigma\n\n    return -drift_mean, drift_var\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.compute_diffusion","title":"compute_diffusion","text":"<pre><code>compute_diffusion(x: Tensor, t: Tensor, form: str = 'SBDM', norm: float = 1.0) -&gt; torch.Tensor\n</code></pre> <p>Compute diffusion coefficient for SDE sampling.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <code>form</code> <code>str</code> <p>Diffusion form ('constant', 'SBDM', 'sigma', 'linear').</p> <code>'SBDM'</code> <code>norm</code> <code>float</code> <p>Scaling factor for diffusion.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Diffusion coefficient tensor.</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def compute_diffusion(\n    self, x: torch.Tensor, t: torch.Tensor, form: str = \"SBDM\", norm: float = 1.0\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute diffusion coefficient for SDE sampling.\n\n    Args:\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n        form: Diffusion form ('constant', 'SBDM', 'sigma', 'linear').\n        norm: Scaling factor for diffusion.\n\n    Returns:\n        Diffusion coefficient tensor.\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x)\n    sigma, _ = self.compute_sigma_t(t_expanded)\n    _, drift_var = self.compute_drift(x, t)\n\n    forms = {\n        \"constant\": norm * torch.ones_like(drift_var),\n        \"SBDM\": norm * drift_var / (sigma + 1e-8),\n        \"sigma\": norm * sigma,\n        \"linear\": norm * (1 - t_expanded),\n    }\n    if form not in forms:\n        raise NotImplementedError(f\"Diffusion form '{form}' not implemented\")\n    return forms[form]\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.velocity_to_score","title":"velocity_to_score","text":"<pre><code>velocity_to_score(velocity: Tensor, x: Tensor, t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Convert velocity prediction to score.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>Tensor</code> <p>Predicted velocity of shape (batch_size, ...).</p> required <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Score tensor of shape (batch_size, ...).</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def velocity_to_score(\n    self, velocity: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Convert velocity prediction to score.\n\n    Args:\n        velocity: Predicted velocity of shape (batch_size, ...).\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Score tensor of shape (batch_size, ...).\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x)\n    alpha, d_alpha = self.compute_alpha_t(t_expanded)\n    sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n    alpha = torch.clamp(alpha, min=1e-8)\n    reverse_alpha_ratio = alpha / d_alpha\n    var = sigma**2 - reverse_alpha_ratio * d_sigma * sigma\n    score = (reverse_alpha_ratio * velocity - x) / torch.clamp(var, min=1e-12)\n\n    return score\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.velocity_to_noise","title":"velocity_to_noise","text":"<pre><code>velocity_to_noise(velocity: Tensor, x: Tensor, t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Convert velocity prediction to noise prediction.</p> <p>Parameters:</p> Name Type Description Default <code>velocity</code> <code>Tensor</code> <p>Predicted velocity of shape (batch_size, ...).</p> required <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Noise tensor of shape (batch_size, ...).</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def velocity_to_noise(\n    self, velocity: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Convert velocity prediction to noise prediction.\n\n    Args:\n        velocity: Predicted velocity of shape (batch_size, ...).\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Noise tensor of shape (batch_size, ...).\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x)\n    alpha, d_alpha = self.compute_alpha_t(t_expanded)\n    sigma, d_sigma = self.compute_sigma_t(t_expanded)\n\n    d_alpha = torch.where(d_alpha.abs() &lt; 1e-8, torch.ones_like(d_alpha) * 1e-8, d_alpha)\n    reverse_alpha_ratio = alpha / d_alpha\n    var = sigma - reverse_alpha_ratio * d_sigma\n    var = torch.where(var.abs() &lt; 1e-12, torch.sign(var) * 1e-12 + (var == 0) * 1e-12, var)\n    noise = (x - reverse_alpha_ratio * velocity) / var\n\n    return noise\n</code></pre>"},{"location":"api/torchebm/core/base_interpolant/classes/BaseInterpolant/#torchebm.core.base_interpolant.BaseInterpolant.score_to_velocity","title":"score_to_velocity","text":"<pre><code>score_to_velocity(score: Tensor, x: Tensor, t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Convert score prediction to velocity.</p> <p>Parameters:</p> Name Type Description Default <code>score</code> <code>Tensor</code> <p>Predicted score of shape (batch_size, ...).</p> required <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Velocity tensor of shape (batch_size, ...).</p> Source code in <code>torchebm/core/base_interpolant.py</code> <pre><code>def score_to_velocity(\n    self, score: torch.Tensor, x: torch.Tensor, t: torch.Tensor\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Convert score prediction to velocity.\n\n    Args:\n        score: Predicted score of shape (batch_size, ...).\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Velocity tensor of shape (batch_size, ...).\n    \"\"\"\n    drift_mean, drift_var = self.compute_drift(x, t)\n    velocity = drift_var * score - drift_mean\n    return velocity\n</code></pre>"},{"location":"api/torchebm/core/base_loss/","title":"Torchebm &gt; Core &gt; Base_loss","text":""},{"location":"api/torchebm/core/base_loss/#torchebm-core-base_loss","title":"Torchebm &gt; Core &gt; Base_loss","text":""},{"location":"api/torchebm/core/base_loss/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_loss/#classes","title":"Classes","text":"<ul> <li><code>BaseContrastiveDivergence</code> - Abstract base class for Contrastive Divergence (CD) based loss functions.</li> <li><code>BaseLoss</code> - Abstract base class for loss functions used in energy-based models.</li> <li><code>BaseScoreMatching</code> - Abstract base class for Score Matching based loss functions.</li> </ul>"},{"location":"api/torchebm/core/base_loss/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_loss/#torchebm.core.base_loss","title":"torchebm.core.base_loss","text":"<p>Base Loss Classes for Energy-Based Models</p>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/","title":"BaseContrastiveDivergence","text":""},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseLoss</code></p> <p>Abstract base class for Contrastive Divergence (CD) based loss functions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The energy-based model to be trained.</p> required <code>sampler</code> <code>BaseSampler</code> <p>The MCMC sampler for generating negative samples.</p> required <code>k_steps</code> <code>int</code> <p>The number of MCMC steps to perform for each update.</p> <code>1</code> <code>persistent</code> <code>bool</code> <p>If <code>True</code>, uses a replay buffer for Persistent CD (PCD).</p> <code>False</code> <code>buffer_size</code> <code>int</code> <p>The size of the replay buffer for PCD.</p> <code>100</code> <code>new_sample_ratio</code> <code>float</code> <p>The ratio of new random samples to introduce into the MCMC chain.</p> <code>0.0</code> <code>init_steps</code> <code>int</code> <p>The number of MCMC steps to run when initializing new chain elements.</p> <code>0</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision training.</p> <code>False</code> <code>clip_value</code> <code>Optional[float]</code> <p>Optional value to clamp the loss.</p> <code>None</code> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>class BaseContrastiveDivergence(BaseLoss):\n    \"\"\"\n    Abstract base class for Contrastive Divergence (CD) based loss functions.\n\n    Args:\n        model (BaseModel): The energy-based model to be trained.\n        sampler (BaseSampler): The MCMC sampler for generating negative samples.\n        k_steps (int): The number of MCMC steps to perform for each update.\n        persistent (bool): If `True`, uses a replay buffer for Persistent CD (PCD).\n        buffer_size (int): The size of the replay buffer for PCD.\n        new_sample_ratio (float): The ratio of new random samples to introduce into the MCMC chain.\n        init_steps (int): The number of MCMC steps to run when initializing new chain elements.\n        dtype (torch.dtype): Data type for computations.\n        device (Optional[Union[str, torch.device]]): Device for computations.\n        use_mixed_precision (bool): Whether to use mixed precision training.\n        clip_value (Optional[float]): Optional value to clamp the loss.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        sampler: BaseSampler,\n        k_steps: int = 1,\n        persistent: bool = False,\n        buffer_size: int = 100,\n        new_sample_ratio: float = 0.0,\n        init_steps: int = 0,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        clip_value: Optional[float] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n            clip_value=clip_value,\n            *args,\n            **kwargs,\n        )\n        self.model = model\n        self.sampler = sampler\n        self.k_steps = k_steps\n        self.persistent = persistent\n        self.buffer_size = buffer_size\n        self.new_sample_ratio = new_sample_ratio\n        self.init_steps = init_steps\n\n        self.model = self.model.to(device=self.device)\n        if hasattr(self.sampler, \"to\") and callable(getattr(self.sampler, \"to\")):\n            self.sampler = self.sampler.to(device=self.device)\n\n        self.register_buffer(\"replay_buffer\", None)\n        self.register_buffer(\n            \"buffer_ptr\", torch.tensor(0, dtype=torch.long, device=self.device)\n        )\n        self.buffer_initialized = False\n\n    def initialize_buffer(\n        self,\n        data_shape_no_batch: Tuple[int, ...],\n        buffer_chunk_size: int = 1024,\n        init_noise_scale: float = 0.01,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Initializes the replay buffer with random noise for PCD.\n\n        Args:\n            data_shape_no_batch (Tuple[int, ...]): The shape of the data excluding the batch dimension.\n            buffer_chunk_size (int): The size of chunks to process during initialization.\n            init_noise_scale (float): The scale of the initial noise.\n\n        Returns:\n            torch.Tensor: The initialized replay buffer.\n        \"\"\"\n        if not self.persistent or self.buffer_initialized:\n            return\n\n        if self.buffer_size &lt;= 0:\n            raise ValueError(\n                f\"Replay buffer size must be positive, got {self.buffer_size}\"\n            )\n\n        buffer_shape = (\n            self.buffer_size,\n        ) + data_shape_no_batch  # shape: [buffer_size, *data_shape]\n        print(f\"Initializing replay buffer with shape {buffer_shape}...\")\n\n        self.replay_buffer = (\n            torch.randn(buffer_shape, dtype=self.dtype, device=self.device)\n            * init_noise_scale\n        )\n\n        if self.init_steps &gt; 0:\n            print(f\"Running {self.init_steps} MCMC steps to populate buffer...\")\n            with torch.no_grad():\n                chunk_size = min(self.buffer_size, buffer_chunk_size)\n                for i in range(0, self.buffer_size, chunk_size):\n                    end = min(i + chunk_size, self.buffer_size)\n                    current_chunk = self.replay_buffer[i:end].clone()\n                    try:\n                        with self.autocast_context():\n                            updated_chunk = self.sampler.sample(\n                                x=current_chunk, n_steps=self.init_steps\n                            ).detach()\n\n                        if updated_chunk.shape == current_chunk.shape:\n                            self.replay_buffer[i:end] = updated_chunk\n                        else:\n                            warnings.warn(\n                                f\"Sampler output shape mismatch during buffer init. Expected {current_chunk.shape}, got {updated_chunk.shape}. Skipping update for chunk {i}-{end}.\"\n                            )\n                    except Exception as e:\n                        warnings.warn(\n                            f\"Error during buffer initialization sampling for chunk {i}-{end}: {e}. Keeping noise for this chunk.\"\n                        )\n\n        self.buffer_ptr.zero_()\n        self.buffer_initialized = True\n        print(f\"Replay buffer initialized.\")\n\n        return self.replay_buffer\n\n    def get_start_points(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Gets the starting points for the MCMC sampler.\n\n        For standard CD, this is the input data. For PCD, it's samples from the replay buffer.\n\n        Args:\n            x (torch.Tensor): The input data batch.\n\n        Returns:\n            torch.Tensor: The tensor of starting points for the sampler.\n        \"\"\"\n        x = x.to(device=self.device, dtype=self.dtype)\n\n        batch_size = x.shape[0]\n        data_shape_no_batch = x.shape[1:]\n\n        if self.persistent:\n            if not self.buffer_initialized:\n                self.initialize_buffer(data_shape_no_batch)\n                if not self.buffer_initialized:\n                    raise RuntimeError(\"Buffer initialization failed.\")\n\n            if self.buffer_size &lt; batch_size:\n                warnings.warn(\n                    f\"Buffer size ({self.buffer_size}) is smaller than batch size ({batch_size}). Sampling with replacement.\",\n                    UserWarning,\n                )\n                indices = torch.randint(\n                    0, self.buffer_size, (batch_size,), device=self.device\n                )\n            else:\n                # stratified sampling for better buffer coverage\n                stride = self.buffer_size // batch_size\n                base_indices = torch.arange(0, batch_size, device=self.device) * stride\n                offset = torch.randint(0, stride, (batch_size,), device=self.device)\n                indices = (base_indices + offset) % self.buffer_size\n\n            start_points = self.replay_buffer[indices].detach().clone()\n\n            # add some noise for exploration\n            if self.new_sample_ratio &gt; 0.0:\n                n_new = max(1, int(batch_size * self.new_sample_ratio))\n                noise_indices = torch.randperm(batch_size, device=self.device)[:n_new]\n                noise_scale = 0.01\n                start_points[noise_indices] = (\n                    start_points[noise_indices]\n                    + torch.randn_like(\n                        start_points[noise_indices],\n                        device=self.device,\n                        dtype=self.dtype,\n                    )\n                    * noise_scale\n                )\n        else:\n            # standard CD-k uses data as starting points\n            start_points = x.detach().clone()\n\n        return start_points\n\n    def get_negative_samples(self, x, batch_size, data_shape) -&gt; torch.Tensor:\n        \"\"\"\n        Gets negative samples using the replay buffer strategy.\n\n        Args:\n            x: (Unused) The input data tensor.\n            batch_size (int): The number of samples to generate.\n            data_shape (Tuple[int, ...]): The shape of the data samples (excluding batch size).\n\n        Returns:\n            torch.Tensor: Negative samples.\n        \"\"\"\n        if not self.persistent or not self.buffer_initialized:\n            # For non-persistent CD, just return random noise\n            return torch.randn(\n                (batch_size,) + data_shape, dtype=self.dtype, device=self.device\n            )\n\n        n_new = max(1, int(batch_size * self.new_sample_ratio))\n        n_old = batch_size - n_new\n\n        all_samples = torch.empty(\n            (batch_size,) + data_shape, dtype=self.dtype, device=self.device\n        )\n\n        # new random samples\n        if n_new &gt; 0:\n            all_samples[:n_new] = torch.randn(\n                (n_new,) + data_shape, dtype=self.dtype, device=self.device\n            )\n\n        # samples from buffer\n        if n_old &gt; 0:\n\n            indices = torch.randint(0, self.buffer_size, (n_old,), device=self.device)\n            all_samples[n_new:] = self.replay_buffer[indices]\n\n        return all_samples\n\n    def update_buffer(self, samples: torch.Tensor) -&gt; None:\n        \"\"\"\n        Updates the replay buffer with new samples using a FIFO strategy.\n\n        Args:\n            samples (torch.Tensor): New samples to add to the buffer.\n        \"\"\"\n        if not self.persistent or not self.buffer_initialized:\n            return\n\n        # Ensure samples are on the correct device and dtype\n        samples = samples.to(device=self.device, dtype=self.dtype).detach()\n\n        batch_size = samples.shape[0]\n\n        # FIFO strategy\n        ptr = int(self.buffer_ptr.item())\n\n        if batch_size &gt;= self.buffer_size:\n            # batch larger than buffer, use latest samples\n            self.replay_buffer[:] = samples[-self.buffer_size :].detach()\n            self.buffer_ptr[...] = 0\n        else:\n            # handle buffer wraparound\n            end_ptr = (ptr + batch_size) % self.buffer_size\n\n            if end_ptr &gt; ptr:\n                self.replay_buffer[ptr:end_ptr] = samples.detach()\n            else:\n                # wraparound case - split update\n                first_part = self.buffer_size - ptr\n                self.replay_buffer[ptr:] = samples[:first_part].detach()\n                self.replay_buffer[:end_ptr] = samples[first_part:].detach()\n\n            self.buffer_ptr[...] = end_ptr\n\n    @abstractmethod\n    def forward(\n        self, x: torch.Tensor, *args, **kwargs\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Computes the CD loss given real data samples.\n\n        Args:\n            x (torch.Tensor): Real data samples (positive samples).\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]:\n                - The contrastive divergence loss.\n                - The generated negative samples.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def compute_loss(\n        self, x: torch.Tensor, pred_x: torch.Tensor, *args, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the contrastive divergence loss from positive and negative samples.\n\n        Args:\n            x (torch.Tensor): Real data samples (positive samples).\n            pred_x (torch.Tensor): Generated negative samples.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The contrastive divergence loss.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return f\"{self.__class__.__name__}(model={self.model}, sampler={self.sampler})\"\n\n    def __str__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return self.__repr__()\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.sampler","title":"sampler  <code>instance-attribute</code>","text":"<pre><code>sampler = sampler\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.k_steps","title":"k_steps  <code>instance-attribute</code>","text":"<pre><code>k_steps = k_steps\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.persistent","title":"persistent  <code>instance-attribute</code>","text":"<pre><code>persistent = persistent\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.buffer_size","title":"buffer_size  <code>instance-attribute</code>","text":"<pre><code>buffer_size = buffer_size\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.new_sample_ratio","title":"new_sample_ratio  <code>instance-attribute</code>","text":"<pre><code>new_sample_ratio = new_sample_ratio\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.init_steps","title":"init_steps  <code>instance-attribute</code>","text":"<pre><code>init_steps = init_steps\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = to(device=device)\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.buffer_initialized","title":"buffer_initialized  <code>instance-attribute</code>","text":"<pre><code>buffer_initialized = False\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.initialize_buffer","title":"initialize_buffer","text":"<pre><code>initialize_buffer(data_shape_no_batch: Tuple[int, ...], buffer_chunk_size: int = 1024, init_noise_scale: float = 0.01) -&gt; torch.Tensor\n</code></pre> <p>Initializes the replay buffer with random noise for PCD.</p> <p>Parameters:</p> Name Type Description Default <code>data_shape_no_batch</code> <code>Tuple[int, ...]</code> <p>The shape of the data excluding the batch dimension.</p> required <code>buffer_chunk_size</code> <code>int</code> <p>The size of chunks to process during initialization.</p> <code>1024</code> <code>init_noise_scale</code> <code>float</code> <p>The scale of the initial noise.</p> <code>0.01</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The initialized replay buffer.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def initialize_buffer(\n    self,\n    data_shape_no_batch: Tuple[int, ...],\n    buffer_chunk_size: int = 1024,\n    init_noise_scale: float = 0.01,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Initializes the replay buffer with random noise for PCD.\n\n    Args:\n        data_shape_no_batch (Tuple[int, ...]): The shape of the data excluding the batch dimension.\n        buffer_chunk_size (int): The size of chunks to process during initialization.\n        init_noise_scale (float): The scale of the initial noise.\n\n    Returns:\n        torch.Tensor: The initialized replay buffer.\n    \"\"\"\n    if not self.persistent or self.buffer_initialized:\n        return\n\n    if self.buffer_size &lt;= 0:\n        raise ValueError(\n            f\"Replay buffer size must be positive, got {self.buffer_size}\"\n        )\n\n    buffer_shape = (\n        self.buffer_size,\n    ) + data_shape_no_batch  # shape: [buffer_size, *data_shape]\n    print(f\"Initializing replay buffer with shape {buffer_shape}...\")\n\n    self.replay_buffer = (\n        torch.randn(buffer_shape, dtype=self.dtype, device=self.device)\n        * init_noise_scale\n    )\n\n    if self.init_steps &gt; 0:\n        print(f\"Running {self.init_steps} MCMC steps to populate buffer...\")\n        with torch.no_grad():\n            chunk_size = min(self.buffer_size, buffer_chunk_size)\n            for i in range(0, self.buffer_size, chunk_size):\n                end = min(i + chunk_size, self.buffer_size)\n                current_chunk = self.replay_buffer[i:end].clone()\n                try:\n                    with self.autocast_context():\n                        updated_chunk = self.sampler.sample(\n                            x=current_chunk, n_steps=self.init_steps\n                        ).detach()\n\n                    if updated_chunk.shape == current_chunk.shape:\n                        self.replay_buffer[i:end] = updated_chunk\n                    else:\n                        warnings.warn(\n                            f\"Sampler output shape mismatch during buffer init. Expected {current_chunk.shape}, got {updated_chunk.shape}. Skipping update for chunk {i}-{end}.\"\n                        )\n                except Exception as e:\n                    warnings.warn(\n                        f\"Error during buffer initialization sampling for chunk {i}-{end}: {e}. Keeping noise for this chunk.\"\n                    )\n\n    self.buffer_ptr.zero_()\n    self.buffer_initialized = True\n    print(f\"Replay buffer initialized.\")\n\n    return self.replay_buffer\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.get_start_points","title":"get_start_points","text":"<pre><code>get_start_points(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Gets the starting points for the MCMC sampler.</p> <p>For standard CD, this is the input data. For PCD, it's samples from the replay buffer.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>The input data batch.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The tensor of starting points for the sampler.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def get_start_points(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Gets the starting points for the MCMC sampler.\n\n    For standard CD, this is the input data. For PCD, it's samples from the replay buffer.\n\n    Args:\n        x (torch.Tensor): The input data batch.\n\n    Returns:\n        torch.Tensor: The tensor of starting points for the sampler.\n    \"\"\"\n    x = x.to(device=self.device, dtype=self.dtype)\n\n    batch_size = x.shape[0]\n    data_shape_no_batch = x.shape[1:]\n\n    if self.persistent:\n        if not self.buffer_initialized:\n            self.initialize_buffer(data_shape_no_batch)\n            if not self.buffer_initialized:\n                raise RuntimeError(\"Buffer initialization failed.\")\n\n        if self.buffer_size &lt; batch_size:\n            warnings.warn(\n                f\"Buffer size ({self.buffer_size}) is smaller than batch size ({batch_size}). Sampling with replacement.\",\n                UserWarning,\n            )\n            indices = torch.randint(\n                0, self.buffer_size, (batch_size,), device=self.device\n            )\n        else:\n            # stratified sampling for better buffer coverage\n            stride = self.buffer_size // batch_size\n            base_indices = torch.arange(0, batch_size, device=self.device) * stride\n            offset = torch.randint(0, stride, (batch_size,), device=self.device)\n            indices = (base_indices + offset) % self.buffer_size\n\n        start_points = self.replay_buffer[indices].detach().clone()\n\n        # add some noise for exploration\n        if self.new_sample_ratio &gt; 0.0:\n            n_new = max(1, int(batch_size * self.new_sample_ratio))\n            noise_indices = torch.randperm(batch_size, device=self.device)[:n_new]\n            noise_scale = 0.01\n            start_points[noise_indices] = (\n                start_points[noise_indices]\n                + torch.randn_like(\n                    start_points[noise_indices],\n                    device=self.device,\n                    dtype=self.dtype,\n                )\n                * noise_scale\n            )\n    else:\n        # standard CD-k uses data as starting points\n        start_points = x.detach().clone()\n\n    return start_points\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.get_negative_samples","title":"get_negative_samples","text":"<pre><code>get_negative_samples(x, batch_size, data_shape) -&gt; torch.Tensor\n</code></pre> <p>Gets negative samples using the replay buffer strategy.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <p>(Unused) The input data tensor.</p> required <code>batch_size</code> <code>int</code> <p>The number of samples to generate.</p> required <code>data_shape</code> <code>Tuple[int, ...]</code> <p>The shape of the data samples (excluding batch size).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Negative samples.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def get_negative_samples(self, x, batch_size, data_shape) -&gt; torch.Tensor:\n    \"\"\"\n    Gets negative samples using the replay buffer strategy.\n\n    Args:\n        x: (Unused) The input data tensor.\n        batch_size (int): The number of samples to generate.\n        data_shape (Tuple[int, ...]): The shape of the data samples (excluding batch size).\n\n    Returns:\n        torch.Tensor: Negative samples.\n    \"\"\"\n    if not self.persistent or not self.buffer_initialized:\n        # For non-persistent CD, just return random noise\n        return torch.randn(\n            (batch_size,) + data_shape, dtype=self.dtype, device=self.device\n        )\n\n    n_new = max(1, int(batch_size * self.new_sample_ratio))\n    n_old = batch_size - n_new\n\n    all_samples = torch.empty(\n        (batch_size,) + data_shape, dtype=self.dtype, device=self.device\n    )\n\n    # new random samples\n    if n_new &gt; 0:\n        all_samples[:n_new] = torch.randn(\n            (n_new,) + data_shape, dtype=self.dtype, device=self.device\n        )\n\n    # samples from buffer\n    if n_old &gt; 0:\n\n        indices = torch.randint(0, self.buffer_size, (n_old,), device=self.device)\n        all_samples[n_new:] = self.replay_buffer[indices]\n\n    return all_samples\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.update_buffer","title":"update_buffer","text":"<pre><code>update_buffer(samples: Tensor) -&gt; None\n</code></pre> <p>Updates the replay buffer with new samples using a FIFO strategy.</p> <p>Parameters:</p> Name Type Description Default <code>samples</code> <code>Tensor</code> <p>New samples to add to the buffer.</p> required Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def update_buffer(self, samples: torch.Tensor) -&gt; None:\n    \"\"\"\n    Updates the replay buffer with new samples using a FIFO strategy.\n\n    Args:\n        samples (torch.Tensor): New samples to add to the buffer.\n    \"\"\"\n    if not self.persistent or not self.buffer_initialized:\n        return\n\n    # Ensure samples are on the correct device and dtype\n    samples = samples.to(device=self.device, dtype=self.dtype).detach()\n\n    batch_size = samples.shape[0]\n\n    # FIFO strategy\n    ptr = int(self.buffer_ptr.item())\n\n    if batch_size &gt;= self.buffer_size:\n        # batch larger than buffer, use latest samples\n        self.replay_buffer[:] = samples[-self.buffer_size :].detach()\n        self.buffer_ptr[...] = 0\n    else:\n        # handle buffer wraparound\n        end_ptr = (ptr + batch_size) % self.buffer_size\n\n        if end_ptr &gt; ptr:\n            self.replay_buffer[ptr:end_ptr] = samples.detach()\n        else:\n            # wraparound case - split update\n            first_part = self.buffer_size - ptr\n            self.replay_buffer[ptr:] = samples[:first_part].detach()\n            self.replay_buffer[:end_ptr] = samples[first_part:].detach()\n\n        self.buffer_ptr[...] = end_ptr\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Computes the CD loss given real data samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Real data samples (positive samples).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple[torch.Tensor, torch.Tensor]: - The contrastive divergence loss. - The generated negative samples.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>@abstractmethod\ndef forward(\n    self, x: torch.Tensor, *args, **kwargs\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Computes the CD loss given real data samples.\n\n    Args:\n        x (torch.Tensor): Real data samples (positive samples).\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n            - The contrastive divergence loss.\n            - The generated negative samples.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseContrastiveDivergence/#torchebm.core.base_loss.BaseContrastiveDivergence.compute_loss","title":"compute_loss  <code>abstractmethod</code>","text":"<pre><code>compute_loss(x: Tensor, pred_x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the contrastive divergence loss from positive and negative samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Real data samples (positive samples).</p> required <code>pred_x</code> <code>Tensor</code> <p>Generated negative samples.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The contrastive divergence loss.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>@abstractmethod\ndef compute_loss(\n    self, x: torch.Tensor, pred_x: torch.Tensor, *args, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the contrastive divergence loss from positive and negative samples.\n\n    Args:\n        x (torch.Tensor): Real data samples (positive samples).\n        pred_x (torch.Tensor): Generated negative samples.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The contrastive divergence loss.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseLoss/","title":"BaseLoss","text":""},{"location":"api/torchebm/core/base_loss/classes/BaseLoss/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>DeviceMixin</code>, <code>Module</code>, <code>ABC</code></p> <p>Abstract base class for loss functions used in energy-based models.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision training.</p> <code>False</code> <code>clip_value</code> <code>Optional[float]</code> <p>Optional value to clamp the loss.</p> <code>None</code> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>class BaseLoss(DeviceMixin, nn.Module, ABC):\n    \"\"\"\n    Abstract base class for loss functions used in energy-based models.\n\n    Args:\n        dtype (torch.dtype): Data type for computations.\n        device (Optional[Union[str, torch.device]]): Device for computations.\n        use_mixed_precision (bool): Whether to use mixed precision training.\n        clip_value (Optional[float]): Optional value to clamp the loss.\n    \"\"\"\n\n    def __init__(\n        self,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        clip_value: Optional[float] = None,\n        *args: Any,\n        **kwargs: Any,\n    ):\n        \"\"\"Initialize the base loss class.\"\"\"\n        super().__init__(device=device, *args, **kwargs)\n\n        # if isinstance(device, str):\n        #     device = torch.device(device)\n        self.dtype = dtype\n        self.clip_value = clip_value\n        self.setup_mixed_precision(use_mixed_precision)\n\n\n    @abstractmethod\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the loss value.\n\n        Args:\n            x (torch.Tensor): Input data tensor from the target distribution.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The computed scalar loss value.\n        \"\"\"\n        pass\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return f\"{self.__class__.__name__}()\"\n\n    def __str__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return self.__repr__()\n\n    def __call__(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Calls the forward method of the loss function.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The computed loss value.\n        \"\"\"\n        x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            loss = self.forward(x, *args, **kwargs)\n\n        if self.clip_value:\n            loss = torch.clamp(loss, -self.clip_value, self.clip_value)\n        return loss\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseLoss/#torchebm.core.base_loss.BaseLoss.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype = dtype\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseLoss/#torchebm.core.base_loss.BaseLoss.clip_value","title":"clip_value  <code>instance-attribute</code>","text":"<pre><code>clip_value = clip_value\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseLoss/#torchebm.core.base_loss.BaseLoss.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the loss value.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor from the target distribution.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The computed scalar loss value.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>@abstractmethod\ndef forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the loss value.\n\n    Args:\n        x (torch.Tensor): Input data tensor from the target distribution.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The computed scalar loss value.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/","title":"BaseScoreMatching","text":""},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseLoss</code></p> <p>Abstract base class for Score Matching based loss functions.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The energy-based model to be trained.</p> required <code>noise_scale</code> <code>float</code> <p>The scale of noise for perturbation in denoising variants.</p> <code>0.01</code> <code>regularization_strength</code> <code>float</code> <p>The coefficient for regularization terms.</p> <code>0.0</code> <code>use_autograd</code> <code>bool</code> <p>Whether to use <code>torch.autograd</code> for computing derivatives.</p> <code>True</code> <code>hutchinson_samples</code> <code>int</code> <p>The number of random samples for Hutchinson's trick.</p> <code>1</code> <code>custom_regularization</code> <code>Optional[Callable]</code> <p>An optional function for custom regularization.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision training.</p> <code>False</code> <code>clip_value</code> <code>Optional[float]</code> <p>Optional value to clamp the loss.</p> <code>None</code> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>class BaseScoreMatching(BaseLoss):\n    \"\"\"\n    Abstract base class for Score Matching based loss functions.\n\n    Args:\n        model (BaseModel): The energy-based model to be trained.\n        noise_scale (float): The scale of noise for perturbation in denoising variants.\n        regularization_strength (float): The coefficient for regularization terms.\n        use_autograd (bool): Whether to use `torch.autograd` for computing derivatives.\n        hutchinson_samples (int): The number of random samples for Hutchinson's trick.\n        custom_regularization (Optional[Callable]): An optional function for custom regularization.\n        use_mixed_precision (bool): Whether to use mixed precision training.\n        clip_value (Optional[float]): Optional value to clamp the loss.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        noise_scale: float = 0.01,\n        regularization_strength: float = 0.0,\n        use_autograd: bool = True,\n        hutchinson_samples: int = 1,\n        custom_regularization: Optional[Callable] = None,\n        use_mixed_precision: bool = False,\n        clip_value: Optional[float] = None,\n        # dtype: torch.dtype = torch.float32,\n        # device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            use_mixed_precision=use_mixed_precision,\n            clip_value=clip_value,\n            *args,\n            **kwargs,  # dtype=dtype, device=device,\n        )\n        self.model = model.to(device=self.device)\n        self.noise_scale = noise_scale\n        self.regularization_strength = regularization_strength\n        self.use_autograd = use_autograd\n        self.hutchinson_samples = hutchinson_samples\n        self.custom_regularization = custom_regularization\n        self.use_mixed_precision = use_mixed_precision\n\n        self.model = self.model.to(device=self.device)\n\n        self.setup_mixed_precision(use_mixed_precision)\n\n    def compute_score(\n        self, x: torch.Tensor, noise: Optional[torch.Tensor] = None\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the score function, \\(\\nabla_x E(x)\\).\n\n        Args:\n            x (torch.Tensor): The input data tensor.\n            noise (Optional[torch.Tensor]): Optional noise tensor for perturbed variants.\n\n        Returns:\n            torch.Tensor: The score function evaluated at `x` or `x + noise`.\n        \"\"\"\n\n        x = x.to(device=self.device, dtype=self.dtype)\n\n        if noise is not None:\n            noise = noise.to(device=self.device, dtype=self.dtype)\n            x_perturbed = x + noise\n        else:\n            x_perturbed = x\n\n        if not x_perturbed.requires_grad:\n            x_perturbed.requires_grad_(True)\n\n        with self.autocast_context():\n            energy = self.model(x_perturbed)\n\n        if self.use_autograd:\n            score = torch.autograd.grad(energy.sum(), x_perturbed, create_graph=True)[0]\n        else:\n            raise NotImplementedError(\n                \"Custom gradient computation must be implemented in subclasses\"\n            )\n\n        return score\n\n    def perturb_data(\n        self, x: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:  # todo: add more noise types\n        \"\"\"\n        Perturbs the input data with Gaussian noise for denoising variants.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]: A tuple containing the perturbed data\n                and the noise that was added.\n        \"\"\"\n\n        x = x.to(device=self.device, dtype=self.dtype)\n        noise = (\n            torch.randn_like(x, device=self.device, dtype=self.dtype) * self.noise_scale\n        )\n        x_perturbed = x + noise\n        return x_perturbed, noise\n\n    def __call__(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Calls the forward method of the loss function.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The computed loss.\n        \"\"\"\n\n        x = x.to(device=self.device, dtype=self.dtype)\n        return self.forward(x, *args, **kwargs)\n\n    @abstractmethod\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the score matching loss given input data.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The computed score matching loss.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the specific score matching loss variant.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The specific score matching loss.\n        \"\"\"\n        pass\n\n    def add_regularization(\n        self,\n        loss: torch.Tensor,\n        x: torch.Tensor,\n        custom_reg_fn: Optional[Callable] = None,\n        reg_strength: Optional[float] = None,\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Adds regularization terms to the loss.\n\n        Args:\n            loss (torch.Tensor): The current loss value.\n            x (torch.Tensor): The input tensor.\n            custom_reg_fn (Optional[Callable]): An optional custom regularization function.\n            reg_strength (Optional[float]): An optional regularization strength.\n\n        Returns:\n            torch.Tensor: The loss with the regularization term added.\n        \"\"\"\n        strength = (\n            reg_strength if reg_strength is not None else self.regularization_strength\n        )\n\n        if strength &lt;= 0:\n            return loss\n\n        if custom_reg_fn is not None:\n            reg_term = custom_reg_fn(x, self.model)\n\n        elif self.custom_regularization is not None:\n            reg_term = self.custom_regularization(x, self.model)\n        # default: L2 norm of score\n        else:\n            score = self.compute_score(x)\n            reg_term = score.pow(2).sum(dim=list(range(1, len(x.shape)))).mean()\n\n        return loss + strength * reg_term\n\n    def __repr__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return f\"{self.__class__.__name__}(model={self.model})\"\n\n    def __str__(self):\n        \"\"\"Return a string representation of the loss function.\"\"\"\n        return self.__repr__()\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.noise_scale","title":"noise_scale  <code>instance-attribute</code>","text":"<pre><code>noise_scale = noise_scale\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.regularization_strength","title":"regularization_strength  <code>instance-attribute</code>","text":"<pre><code>regularization_strength = regularization_strength\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.use_autograd","title":"use_autograd  <code>instance-attribute</code>","text":"<pre><code>use_autograd = use_autograd\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.hutchinson_samples","title":"hutchinson_samples  <code>instance-attribute</code>","text":"<pre><code>hutchinson_samples = hutchinson_samples\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.custom_regularization","title":"custom_regularization  <code>instance-attribute</code>","text":"<pre><code>custom_regularization = custom_regularization\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.use_mixed_precision","title":"use_mixed_precision  <code>instance-attribute</code>","text":"<pre><code>use_mixed_precision = use_mixed_precision\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = to(device=device)\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.compute_score","title":"compute_score","text":"<pre><code>compute_score(x: Tensor, noise: Optional[Tensor] = None) -&gt; torch.Tensor\n</code></pre> <pre><code>    Computes the score function, \\(\n</code></pre> <p>abla_x E(x)).</p> <pre><code>    Args:\n        x (torch.Tensor): The input data tensor.\n        noise (Optional[torch.Tensor]): Optional noise tensor for perturbed variants.\n\n    Returns:\n        torch.Tensor: The score function evaluated at `x` or `x + noise`.\n</code></pre> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def compute_score(\n    self, x: torch.Tensor, noise: Optional[torch.Tensor] = None\n) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the score function, \\(\\nabla_x E(x)\\).\n\n    Args:\n        x (torch.Tensor): The input data tensor.\n        noise (Optional[torch.Tensor]): Optional noise tensor for perturbed variants.\n\n    Returns:\n        torch.Tensor: The score function evaluated at `x` or `x + noise`.\n    \"\"\"\n\n    x = x.to(device=self.device, dtype=self.dtype)\n\n    if noise is not None:\n        noise = noise.to(device=self.device, dtype=self.dtype)\n        x_perturbed = x + noise\n    else:\n        x_perturbed = x\n\n    if not x_perturbed.requires_grad:\n        x_perturbed.requires_grad_(True)\n\n    with self.autocast_context():\n        energy = self.model(x_perturbed)\n\n    if self.use_autograd:\n        score = torch.autograd.grad(energy.sum(), x_perturbed, create_graph=True)[0]\n    else:\n        raise NotImplementedError(\n            \"Custom gradient computation must be implemented in subclasses\"\n        )\n\n    return score\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.perturb_data","title":"perturb_data","text":"<pre><code>perturb_data(x: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Perturbs the input data with Gaussian noise for denoising variants.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple[torch.Tensor, torch.Tensor]: A tuple containing the perturbed data and the noise that was added.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def perturb_data(\n    self, x: torch.Tensor\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:  # todo: add more noise types\n    \"\"\"\n    Perturbs the input data with Gaussian noise for denoising variants.\n\n    Args:\n        x (torch.Tensor): Input data tensor.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]: A tuple containing the perturbed data\n            and the noise that was added.\n    \"\"\"\n\n    x = x.to(device=self.device, dtype=self.dtype)\n    noise = (\n        torch.randn_like(x, device=self.device, dtype=self.dtype) * self.noise_scale\n    )\n    x_perturbed = x + noise\n    return x_perturbed, noise\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the score matching loss given input data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The computed score matching loss.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>@abstractmethod\ndef forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the score matching loss given input data.\n\n    Args:\n        x (torch.Tensor): Input data tensor.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The computed score matching loss.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.compute_loss","title":"compute_loss  <code>abstractmethod</code>","text":"<pre><code>compute_loss(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the specific score matching loss variant.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The specific score matching loss.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>@abstractmethod\ndef compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the specific score matching loss variant.\n\n    Args:\n        x (torch.Tensor): Input data tensor.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The specific score matching loss.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_loss/classes/BaseScoreMatching/#torchebm.core.base_loss.BaseScoreMatching.add_regularization","title":"add_regularization","text":"<pre><code>add_regularization(loss: Tensor, x: Tensor, custom_reg_fn: Optional[Callable] = None, reg_strength: Optional[float] = None) -&gt; torch.Tensor\n</code></pre> <p>Adds regularization terms to the loss.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>Tensor</code> <p>The current loss value.</p> required <code>x</code> <code>Tensor</code> <p>The input tensor.</p> required <code>custom_reg_fn</code> <code>Optional[Callable]</code> <p>An optional custom regularization function.</p> <code>None</code> <code>reg_strength</code> <code>Optional[float]</code> <p>An optional regularization strength.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The loss with the regularization term added.</p> Source code in <code>torchebm/core/base_loss.py</code> <pre><code>def add_regularization(\n    self,\n    loss: torch.Tensor,\n    x: torch.Tensor,\n    custom_reg_fn: Optional[Callable] = None,\n    reg_strength: Optional[float] = None,\n) -&gt; torch.Tensor:\n    \"\"\"\n    Adds regularization terms to the loss.\n\n    Args:\n        loss (torch.Tensor): The current loss value.\n        x (torch.Tensor): The input tensor.\n        custom_reg_fn (Optional[Callable]): An optional custom regularization function.\n        reg_strength (Optional[float]): An optional regularization strength.\n\n    Returns:\n        torch.Tensor: The loss with the regularization term added.\n    \"\"\"\n    strength = (\n        reg_strength if reg_strength is not None else self.regularization_strength\n    )\n\n    if strength &lt;= 0:\n        return loss\n\n    if custom_reg_fn is not None:\n        reg_term = custom_reg_fn(x, self.model)\n\n    elif self.custom_regularization is not None:\n        reg_term = self.custom_regularization(x, self.model)\n    # default: L2 norm of score\n    else:\n        score = self.compute_score(x)\n        reg_term = score.pow(2).sum(dim=list(range(1, len(x.shape)))).mean()\n\n    return loss + strength * reg_term\n</code></pre>"},{"location":"api/torchebm/core/base_model/","title":"Torchebm &gt; Core &gt; Base_model","text":""},{"location":"api/torchebm/core/base_model/#torchebm-core-base_model","title":"Torchebm &gt; Core &gt; Base_model","text":""},{"location":"api/torchebm/core/base_model/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_model/#classes","title":"Classes","text":"<ul> <li><code>AckleyEnergy</code> - No description available.</li> <li><code>AckleyModel</code> - Energy-based model for the Ackley function.</li> <li><code>BaseEnergyFunction</code> - No description available.</li> <li><code>BaseModel</code> - Abstract base class for energy-based models (EBMs).</li> <li><code>DoubleWellEnergy</code> - No description available.</li> <li><code>DoubleWellModel</code> - Energy-based model for a double-well potential.</li> <li><code>GaussianEnergy</code> - No description available.</li> <li><code>GaussianModel</code> - Energy-based model for a Gaussian distribution.</li> <li><code>HarmonicEnergy</code> - No description available.</li> <li><code>HarmonicModel</code> - Energy-based model for a harmonic oscillator.</li> <li><code>RastriginEnergy</code> - No description available.</li> <li><code>RastriginModel</code> - Energy-based model for the Rastrigin function.</li> <li><code>RosenbrockEnergy</code> - No description available.</li> <li><code>RosenbrockModel</code> - Energy-based model for the Rosenbrock function.</li> </ul>"},{"location":"api/torchebm/core/base_model/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_model/#torchebm.core.base_model","title":"torchebm.core.base_model","text":""},{"location":"api/torchebm/core/base_model/classes/AckleyEnergy/","title":"AckleyEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/AckleyEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>AckleyModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class AckleyEnergy(AckleyModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`AckleyEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `AckleyModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/AckleyModel/","title":"AckleyModel","text":""},{"location":"api/torchebm/core/base_model/classes/AckleyModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for the Ackley function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>The <code>a</code> parameter of the Ackley function.</p> <code>20.0</code> <code>b</code> <code>float</code> <p>The <code>b</code> parameter of the Ackley function.</p> <code>0.2</code> <code>c</code> <code>float</code> <p>The <code>c</code> parameter of the Ackley function.</p> <code>2 * pi</code> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class AckleyModel(BaseModel):\n    r\"\"\"\n    Energy-based model for the Ackley function.\n\n    Args:\n        a (float): The `a` parameter of the Ackley function.\n        b (float): The `b` parameter of the Ackley function.\n        c (float): The `c` parameter of the Ackley function.\n    \"\"\"\n    def __init__(\n        self, a: float = 20.0, b: float = 0.2, c: float = 2 * math.pi, *args, **kwargs\n    ):\n        super().__init__(*args, **kwargs)\n        self.a = a\n        self.b = b\n        self.c = c\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the Ackley energy.\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n\n        n = x.shape[-1]\n        sum1 = torch.sum(x**2, dim=-1)\n        sum2 = torch.sum(torch.cos(self.c * x), dim=-1)\n        term1 = -self.a * torch.exp(-self.b * torch.sqrt(sum1 / n))\n        term2 = -torch.exp(sum2 / n)\n        return term1 + term2 + self.a + math.e\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/AckleyModel/#torchebm.core.base_model.AckleyModel.a","title":"a  <code>instance-attribute</code>","text":"<pre><code>a = a\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/AckleyModel/#torchebm.core.base_model.AckleyModel.b","title":"b  <code>instance-attribute</code>","text":"<pre><code>b = b\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/AckleyModel/#torchebm.core.base_model.AckleyModel.c","title":"c  <code>instance-attribute</code>","text":"<pre><code>c = c\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/AckleyModel/#torchebm.core.base_model.AckleyModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the Ackley energy.</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the Ackley energy.\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n\n    n = x.shape[-1]\n    sum1 = torch.sum(x**2, dim=-1)\n    sum2 = torch.sum(torch.cos(self.c * x), dim=-1)\n    term1 = -self.a * torch.exp(-self.b * torch.sqrt(sum1 / n))\n    term2 = -torch.exp(sum2 / n)\n    return term1 + term2 + self.a + math.e\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/BaseEnergyFunction/","title":"BaseEnergyFunction","text":""},{"location":"api/torchebm/core/base_model/classes/BaseEnergyFunction/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class BaseEnergyFunction(BaseModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`BaseEnergyFunction` is deprecated and will be removed in a future version. \"\n            \"Please use `BaseModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/BaseModel/","title":"BaseModel","text":""},{"location":"api/torchebm/core/base_model/classes/BaseModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>DeviceMixin</code>, <code>Module</code>, <code>ABC</code></p> <p>Abstract base class for energy-based models (EBMs).</p> <p>This class provides a unified interface for defining EBMs, which represent the unnormalized negative log-likelihood of a probability distribution. It supports both analytical models and trainable neural networks.</p> <p>Subclasses must implement the <code>forward(x)</code> method and can optionally override the <code>gradient(x)</code> method for analytical gradients.</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class BaseModel(DeviceMixin, nn.Module, ABC):\n    r\"\"\"\n    Abstract base class for energy-based models (EBMs).\n\n    This class provides a unified interface for defining EBMs, which represent\n    the unnormalized negative log-likelihood of a probability distribution.\n    It supports both analytical models and trainable neural networks.\n\n    Subclasses must implement the `forward(x)` method and can optionally\n    override the `gradient(x)` method for analytical gradients.\n    \"\"\"\n    def __init__(\n        self,\n        dtype: torch.dtype = torch.float32,\n        use_mixed_precision: bool = False,\n        *args,\n        **kwargs,\n    ):\n        \"\"\"Initializes the BaseModel base class.\"\"\"\n        super().__init__(*args, **kwargs)\n        self.dtype = dtype\n        self.setup_mixed_precision(use_mixed_precision)\n\n    # @property\n    # def device(self) -&gt; torch.device:\n    #     \"\"\"Returns the device associated with the module's parameters/buffers (if any).\"\"\"\n    #     try:\n    #         return next(self.parameters()).device\n    #     except StopIteration:\n    #         try:\n    #             return next(self.buffers()).device\n    #         except StopIteration:\n    #             return self._device\n\n    @abstractmethod\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the scalar energy value for each input sample.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_dims).\n\n        Returns:\n            torch.Tensor: Tensor of scalar energy values with shape (batch_size,).\n        \"\"\"\n        pass\n\n    def gradient(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the gradient of the energy function with respect to the input, \\(\\nabla_x E(x)\\).\n\n        This default implementation uses `torch.autograd`. Subclasses can override it\n        for analytical gradients.\n\n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, *input_dims).\n\n        Returns:\n            torch.Tensor: Gradient tensor of the same shape as `x`.\n        \"\"\"\n\n        original_dtype = x.dtype\n        device = x.device\n\n        if self.device and device != self.device:\n            x = x.to(self.device)\n            device = self.device\n\n        with torch.enable_grad():  # todo: consider removing conversion to fp32 and uncessary device change\n            x_for_grad = (\n                x.detach().to(dtype=torch.float32, device=device).requires_grad_(True)\n            )\n\n            with self.autocast_context():\n                energy = self.forward(x_for_grad)\n\n            if energy.shape != (x_for_grad.shape[0],):\n                raise ValueError(\n                    f\"BaseModel forward() output expected shape ({x_for_grad.shape[0]},), but got {energy.shape}.\"\n                )\n\n            if not energy.grad_fn:\n                raise RuntimeError(\n                    \"Cannot compute gradient: `forward` method did not use the input `x` (as float32) in a differentiable way.\"\n                )\n\n            gradient_float32 = torch.autograd.grad(\n                outputs=energy,\n                inputs=x_for_grad,\n                grad_outputs=torch.ones_like(energy, device=energy.device),\n                create_graph=False,  # false for standard grad computation\n                retain_graph=None,  # since create_graph=False, let PyTorch decide\n            )[0]\n\n        if gradient_float32 is None:  # for triple checking!\n            raise RuntimeError(\n                \"Gradient computation failed unexpectedly. Check the forward pass implementation.\"\n            )\n\n        gradient = gradient_float32.to(original_dtype)\n\n        return gradient.detach()\n\n    def __call__(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"Alias for the forward method for standard PyTorch module usage.\"\"\"\n        if (x.device != self.device) or (x.dtype != self.dtype):\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            return super().__call__(x, *args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/BaseModel/#torchebm.core.base_model.BaseModel.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype = dtype\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/BaseModel/#torchebm.core.base_model.BaseModel.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the scalar energy value for each input sample.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, *input_dims).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Tensor of scalar energy values with shape (batch_size,).</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>@abstractmethod\ndef forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the scalar energy value for each input sample.\n\n    Args:\n        x (torch.Tensor): Input tensor of shape (batch_size, *input_dims).\n\n    Returns:\n        torch.Tensor: Tensor of scalar energy values with shape (batch_size,).\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/BaseModel/#torchebm.core.base_model.BaseModel.gradient","title":"gradient","text":"<pre><code>gradient(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the gradient of the energy function with respect to the input, \\(\\nabla_x E(x)\\).</p> <p>This default implementation uses <code>torch.autograd</code>. Subclasses can override it for analytical gradients.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input tensor of shape (batch_size, *input_dims).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Gradient tensor of the same shape as <code>x</code>.</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def gradient(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the gradient of the energy function with respect to the input, \\(\\nabla_x E(x)\\).\n\n    This default implementation uses `torch.autograd`. Subclasses can override it\n    for analytical gradients.\n\n    Args:\n        x (torch.Tensor): Input tensor of shape (batch_size, *input_dims).\n\n    Returns:\n        torch.Tensor: Gradient tensor of the same shape as `x`.\n    \"\"\"\n\n    original_dtype = x.dtype\n    device = x.device\n\n    if self.device and device != self.device:\n        x = x.to(self.device)\n        device = self.device\n\n    with torch.enable_grad():  # todo: consider removing conversion to fp32 and uncessary device change\n        x_for_grad = (\n            x.detach().to(dtype=torch.float32, device=device).requires_grad_(True)\n        )\n\n        with self.autocast_context():\n            energy = self.forward(x_for_grad)\n\n        if energy.shape != (x_for_grad.shape[0],):\n            raise ValueError(\n                f\"BaseModel forward() output expected shape ({x_for_grad.shape[0]},), but got {energy.shape}.\"\n            )\n\n        if not energy.grad_fn:\n            raise RuntimeError(\n                \"Cannot compute gradient: `forward` method did not use the input `x` (as float32) in a differentiable way.\"\n            )\n\n        gradient_float32 = torch.autograd.grad(\n            outputs=energy,\n            inputs=x_for_grad,\n            grad_outputs=torch.ones_like(energy, device=energy.device),\n            create_graph=False,  # false for standard grad computation\n            retain_graph=None,  # since create_graph=False, let PyTorch decide\n        )[0]\n\n    if gradient_float32 is None:  # for triple checking!\n        raise RuntimeError(\n            \"Gradient computation failed unexpectedly. Check the forward pass implementation.\"\n        )\n\n    gradient = gradient_float32.to(original_dtype)\n\n    return gradient.detach()\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/DoubleWellEnergy/","title":"DoubleWellEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/DoubleWellEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>DoubleWellModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class DoubleWellEnergy(DoubleWellModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`DoubleWellEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `DoubleWellModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/DoubleWellModel/","title":"DoubleWellModel","text":""},{"location":"api/torchebm/core/base_model/classes/DoubleWellModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for a double-well potential.</p> <p>Parameters:</p> Name Type Description Default <code>barrier_height</code> <code>float</code> <p>The height of the energy barrier between the wells.</p> <code>2.0</code> <code>b</code> <code>float</code> <p>The position of the wells (default is 1.0, creating wells at \u00b11).</p> <code>1.0</code> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class DoubleWellModel(BaseModel):\n    r\"\"\"\n    Energy-based model for a double-well potential.\n\n    Args:\n        barrier_height (float): The height of the energy barrier between the wells.\n        b (float): The position of the wells (default is 1.0, creating wells at \u00b11).\n    \"\"\"\n    def __init__(self, barrier_height: float = 2.0, b: float = 1.0, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.barrier_height = barrier_height\n        self.b = b\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the double well energy: \\(h \\sum_{i=1}^{n} (x_i^2 - b^2)^2\\).\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n\n        return self.barrier_height * (x.pow(2) - self.b**2).pow(2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/DoubleWellModel/#torchebm.core.base_model.DoubleWellModel.barrier_height","title":"barrier_height  <code>instance-attribute</code>","text":"<pre><code>barrier_height = barrier_height\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/DoubleWellModel/#torchebm.core.base_model.DoubleWellModel.b","title":"b  <code>instance-attribute</code>","text":"<pre><code>b = b\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/DoubleWellModel/#torchebm.core.base_model.DoubleWellModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the double well energy: \\(h \\sum_{i=1}^{n} (x_i^2 - b^2)^2\\).</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the double well energy: \\(h \\sum_{i=1}^{n} (x_i^2 - b^2)^2\\).\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n\n    return self.barrier_height * (x.pow(2) - self.b**2).pow(2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/GaussianEnergy/","title":"GaussianEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/GaussianEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>GaussianModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class GaussianEnergy(GaussianModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`GaussianEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `GaussianModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/GaussianModel/","title":"GaussianModel","text":""},{"location":"api/torchebm/core/base_model/classes/GaussianModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for a Gaussian distribution.</p> <p>Parameters:</p> Name Type Description Default <code>mean</code> <code>Tensor</code> <p>The mean vector (\u03bc) of the Gaussian distribution.</p> required <code>cov</code> <code>Tensor</code> <p>The covariance matrix (\u03a3) of the Gaussian distribution.</p> required Source code in <code>torchebm/core/base_model.py</code> <pre><code>class GaussianModel(BaseModel):\n    r\"\"\"\n    Energy-based model for a Gaussian distribution.\n\n    Args:\n        mean (torch.Tensor): The mean vector (\u03bc) of the Gaussian distribution.\n        cov (torch.Tensor): The covariance matrix (\u03a3) of the Gaussian distribution.\n    \"\"\"\n    def __init__(self, mean: torch.Tensor, cov: torch.Tensor, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        if mean.ndim != 1:\n            raise ValueError(\"Mean must be a 1D tensor.\")\n        if cov.ndim != 2 or cov.shape[0] != cov.shape[1]:\n            raise ValueError(\"Covariance must be a 2D square matrix.\")\n        if mean.shape[0] != cov.shape[0]:\n            raise ValueError(\n                \"Mean vector dimension must match covariance matrix dimension.\"\n            )\n\n        self.register_buffer(\"mean\", mean.to(dtype=self.dtype, device=self.device))\n        try:\n            cov_inv = torch.inverse(cov)\n            self.register_buffer(\n                \"cov_inv\", cov_inv.to(dtype=self.dtype, device=self.device)\n            )\n        except RuntimeError as e:\n            raise ValueError(\n                f\"Failed to invert covariance matrix: {e}. Ensure it is invertible.\"\n            ) from e\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the Gaussian energy: \\(E(x) = \\frac{1}{2} (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu)\\).\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n        if x.ndim != 2 or x.shape[1] != self.mean.shape[0]:\n            raise ValueError(\n                f\"Input x expected batch_shape (batch_size, {self.mean.shape[0]}), but got {x.shape}\"\n            )\n\n        x = x.to(dtype=self.dtype, device=self.device)\n        # mean = self.mean.to(device=x.device)\n        cov_inv = self.cov_inv.to(dtype=self.dtype, device=x.device)\n\n        delta = (\n            x - self.mean\n        )  # avoid detaching or converting x to maintain grad tracking\n        # energy = 0.5 * torch.einsum(\"bi,ij,bj-&gt;b\", delta, cov_inv, delta)\n\n        if delta.shape[0] &gt; 1:\n            delta_expanded = delta.unsqueeze(-1)  # (batch_size, dim, 1)\n            cov_inv_expanded = cov_inv.unsqueeze(0).expand(\n                delta.shape[0], -1, -1\n            )  # (batch_size, dim, dim)\n\n            temp = torch.bmm(cov_inv_expanded, delta_expanded)  # (batch_size, dim, 1)\n            energy = 0.5 * torch.bmm(delta.unsqueeze(1), temp).squeeze(-1).squeeze(-1)\n        else:\n            energy = 0.5 * torch.sum(delta * torch.matmul(delta, cov_inv), dim=-1)\n\n        return energy\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/GaussianModel/#torchebm.core.base_model.GaussianModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the Gaussian energy: \\(E(x) = \\frac{1}{2} (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu)\\).</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the Gaussian energy: \\(E(x) = \\frac{1}{2} (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu)\\).\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n    if x.ndim != 2 or x.shape[1] != self.mean.shape[0]:\n        raise ValueError(\n            f\"Input x expected batch_shape (batch_size, {self.mean.shape[0]}), but got {x.shape}\"\n        )\n\n    x = x.to(dtype=self.dtype, device=self.device)\n    # mean = self.mean.to(device=x.device)\n    cov_inv = self.cov_inv.to(dtype=self.dtype, device=x.device)\n\n    delta = (\n        x - self.mean\n    )  # avoid detaching or converting x to maintain grad tracking\n    # energy = 0.5 * torch.einsum(\"bi,ij,bj-&gt;b\", delta, cov_inv, delta)\n\n    if delta.shape[0] &gt; 1:\n        delta_expanded = delta.unsqueeze(-1)  # (batch_size, dim, 1)\n        cov_inv_expanded = cov_inv.unsqueeze(0).expand(\n            delta.shape[0], -1, -1\n        )  # (batch_size, dim, dim)\n\n        temp = torch.bmm(cov_inv_expanded, delta_expanded)  # (batch_size, dim, 1)\n        energy = 0.5 * torch.bmm(delta.unsqueeze(1), temp).squeeze(-1).squeeze(-1)\n    else:\n        energy = 0.5 * torch.sum(delta * torch.matmul(delta, cov_inv), dim=-1)\n\n    return energy\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/HarmonicEnergy/","title":"HarmonicEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/HarmonicEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>HarmonicModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class HarmonicEnergy(HarmonicModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`HarmonicEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `HarmonicModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/HarmonicModel/","title":"HarmonicModel","text":""},{"location":"api/torchebm/core/base_model/classes/HarmonicModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for a harmonic oscillator.</p> <p>Parameters:</p> Name Type Description Default <code>k</code> <code>float</code> <p>The spring constant.</p> <code>1.0</code> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class HarmonicModel(BaseModel):\n    r\"\"\"\n    Energy-based model for a harmonic oscillator.\n\n    Args:\n        k (float): The spring constant.\n    \"\"\"\n    def __init__(self, k: float = 1.0, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.k = k\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the harmonic oscillator energy: \\(\\frac{1}{2} k \\sum_{i=1}^{n} x_i^{2}\\).\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n\n        return 0.5 * self.k * x.pow(2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/HarmonicModel/#torchebm.core.base_model.HarmonicModel.k","title":"k  <code>instance-attribute</code>","text":"<pre><code>k = k\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/HarmonicModel/#torchebm.core.base_model.HarmonicModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the harmonic oscillator energy: \\(\\frac{1}{2} k \\sum_{i=1}^{n} x_i^{2}\\).</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the harmonic oscillator energy: \\(\\frac{1}{2} k \\sum_{i=1}^{n} x_i^{2}\\).\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n\n    return 0.5 * self.k * x.pow(2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RastriginEnergy/","title":"RastriginEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/RastriginEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>RastriginModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class RastriginEnergy(RastriginModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`RastriginEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `RastriginModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RastriginModel/","title":"RastriginModel","text":""},{"location":"api/torchebm/core/base_model/classes/RastriginModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for the Rastrigin function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>The <code>a</code> parameter of the Rastrigin function.</p> <code>10.0</code> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class RastriginModel(BaseModel):\n    r\"\"\"\n    Energy-based model for the Rastrigin function.\n\n    Args:\n        a (float): The `a` parameter of the Rastrigin function.\n    \"\"\"\n    def __init__(self, a: float = 10.0, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.a = a\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the Rastrigin energy.\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n\n        n = x.shape[-1]\n        return self.a * n + torch.sum(\n            x**2 - self.a * torch.cos(2 * math.pi * x), dim=-1\n        )\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RastriginModel/#torchebm.core.base_model.RastriginModel.a","title":"a  <code>instance-attribute</code>","text":"<pre><code>a = a\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RastriginModel/#torchebm.core.base_model.RastriginModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the Rastrigin energy.</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the Rastrigin energy.\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n\n    n = x.shape[-1]\n    return self.a * n + torch.sum(\n        x**2 - self.a * torch.cos(2 * math.pi * x), dim=-1\n    )\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RosenbrockEnergy/","title":"RosenbrockEnergy","text":""},{"location":"api/torchebm/core/base_model/classes/RosenbrockEnergy/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>RosenbrockModel</code></p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class RosenbrockEnergy(RosenbrockModel):\n    def __init__(self, *args, **kwargs):\n        warnings.warn(\n            \"`RosenbrockEnergy` is deprecated and will be removed in a future version. \"\n            \"Please use `RosenbrockModel` instead.\",\n            DeprecationWarning,\n            stacklevel=2\n        )\n        super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RosenbrockModel/","title":"RosenbrockModel","text":""},{"location":"api/torchebm/core/base_model/classes/RosenbrockModel/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseModel</code></p> <p>Energy-based model for the Rosenbrock function.</p> <p>Parameters:</p> Name Type Description Default <code>a</code> <code>float</code> <p>The <code>a</code> parameter of the Rosenbrock function.</p> <code>1.0</code> <code>b</code> <code>float</code> <p>The <code>b</code> parameter of the Rosenbrock function.</p> <code>100.0</code> Source code in <code>torchebm/core/base_model.py</code> <pre><code>class RosenbrockModel(BaseModel):\n    r\"\"\"\n    Energy-based model for the Rosenbrock function.\n\n    Args:\n        a (float): The `a` parameter of the Rosenbrock function.\n        b (float): The `b` parameter of the Rosenbrock function.\n    \"\"\"\n    def __init__(self, a: float = 1.0, b: float = 100.0, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.a = a\n        self.b = b\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Computes the Rosenbrock energy: \\(\\sum_{i=1}^{n-1} \\left[ b(x_{i+1} - x_i^2)^2 + (a - x_i)^2 \\right]\\).\"\"\"\n        if x.ndim == 1:\n            x = x.unsqueeze(0)\n        if x.shape[-1] &lt; 2:\n            raise ValueError(\n                f\"Rosenbrock energy function requires at least 2 dimensions, got {x.shape[-1]}\"\n            )\n\n        # return (self.a - x[..., 0]) ** 2 + self.b * (x[..., 1] - x[..., 0] ** 2) ** 2\n        # return sum(\n        #     self.b * (x[..., i + 1] - x[..., i] ** 2) ** 2 + (self.a - x[i]) ** 2\n        #     for i in range(len(x) - 1)\n        # )\n\n        x_i = x[:, :-1]\n        x_ip1 = x[:, 1:]\n        term1 = (self.a - x_i).pow(2)\n        term2 = self.b * (x_ip1 - x_i.pow(2)).pow(2)\n        return (term1 + term2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RosenbrockModel/#torchebm.core.base_model.RosenbrockModel.a","title":"a  <code>instance-attribute</code>","text":"<pre><code>a = a\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RosenbrockModel/#torchebm.core.base_model.RosenbrockModel.b","title":"b  <code>instance-attribute</code>","text":"<pre><code>b = b\n</code></pre>"},{"location":"api/torchebm/core/base_model/classes/RosenbrockModel/#torchebm.core.base_model.RosenbrockModel.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the Rosenbrock energy: \\(\\sum_{i=1}^{n-1} \\left[ b(x_{i+1} - x_i^2)^2 + (a - x_i)^2 \\right]\\).</p> Source code in <code>torchebm/core/base_model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Computes the Rosenbrock energy: \\(\\sum_{i=1}^{n-1} \\left[ b(x_{i+1} - x_i^2)^2 + (a - x_i)^2 \\right]\\).\"\"\"\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n    if x.shape[-1] &lt; 2:\n        raise ValueError(\n            f\"Rosenbrock energy function requires at least 2 dimensions, got {x.shape[-1]}\"\n        )\n\n    # return (self.a - x[..., 0]) ** 2 + self.b * (x[..., 1] - x[..., 0] ** 2) ** 2\n    # return sum(\n    #     self.b * (x[..., i + 1] - x[..., i] ** 2) ** 2 + (self.a - x[i]) ** 2\n    #     for i in range(len(x) - 1)\n    # )\n\n    x_i = x[:, :-1]\n    x_ip1 = x[:, 1:]\n    term1 = (self.a - x_i).pow(2)\n    term2 = self.b * (x_ip1 - x_i.pow(2)).pow(2)\n    return (term1 + term2).sum(dim=-1)\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/","title":"Torchebm &gt; Core &gt; Base_sampler","text":""},{"location":"api/torchebm/core/base_sampler/#torchebm-core-base_sampler","title":"Torchebm &gt; Core &gt; Base_sampler","text":""},{"location":"api/torchebm/core/base_sampler/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_sampler/#classes","title":"Classes","text":"<ul> <li><code>BaseSampler</code> - Abstract base class for samplers.</li> </ul>"},{"location":"api/torchebm/core/base_sampler/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_sampler/#torchebm.core.base_sampler","title":"torchebm.core.base_sampler","text":""},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/","title":"BaseSampler","text":""},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>DeviceMixin</code>, <code>Module</code>, <code>ABC</code></p> <p>Abstract base class for samplers.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to sample from. For MCMC samplers, this is typically a <code>BaseModel</code> energy function; for learned samplers it may be any <code>nn.Module</code>.</p> required <code>dtype</code> <code>dtype</code> <p>The data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed-precision for sampling.</p> <code>False</code> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>class BaseSampler(DeviceMixin, nn.Module, ABC):\n    \"\"\"\n    Abstract base class for samplers.\n\n    Args:\n        model (nn.Module): The model to sample from. For MCMC samplers, this is\n            typically a `BaseModel` energy function; for learned samplers it may be\n            any `nn.Module`.\n        dtype (torch.dtype): The data type for computations.\n        device (Optional[Union[str, torch.device]]): The device for computations.\n        use_mixed_precision (bool): Whether to use mixed-precision for sampling.\n    \"\"\"\n\n    def __init__(\n        self,\n        model: nn.Module,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(device=device, dtype=dtype, *args, **kwargs)\n        self.model = model\n        self.dtype = dtype\n        # if isinstance(device, str):\n        #     device = torch.device(device)\n        # self.device = device or torch.device(\n        #     \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        # )\n        self.setup_mixed_precision(use_mixed_precision)\n\n        self.schedulers: Dict[str, BaseScheduler] = {}\n\n        # Align child components using the mixin helper\n        self.model = DeviceMixin.safe_to(\n            self.model, device=self.device, dtype=self.dtype\n        )\n\n        # Ensure the energy function has matching precision settings\n        if hasattr(self.model, \"use_mixed_precision\"):\n            self.model.use_mixed_precision = self.use_mixed_precision\n\n    @abstractmethod\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *args,\n        **kwargs,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        \"\"\"\n        Runs the sampling process.\n\n        Args:\n            x (Optional[torch.Tensor]): The initial state to start sampling from.\n            dim (int): The dimension of the state space.\n            n_steps (int): The number of MCMC steps to perform.\n            n_samples (int): The number of samples to generate.\n            thin (int): The thinning factor for samples (currently not supported).\n            return_trajectory (bool): Whether to return the full trajectory of the samples.\n            return_diagnostics (bool): Whether to return diagnostics of the sampling process.\n\n        Returns:\n            Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n                - A tensor of samples from the model.\n                - If `return_diagnostics` is `True`, a tuple containing the samples\n                  and a list of diagnostics dictionaries.\n        \"\"\"\n        raise NotImplementedError\n\n    def register_scheduler(self, name: str, scheduler: BaseScheduler) -&gt; None:\n        \"\"\"\n        Registers a parameter scheduler.\n\n        Args:\n            name (str): The name of the parameter to schedule.\n            scheduler (BaseScheduler): The scheduler instance.\n        \"\"\"\n        self.schedulers[name] = scheduler\n\n    def get_schedulers(self) -&gt; Dict[str, BaseScheduler]:\n        \"\"\"\n        Gets all registered schedulers.\n\n        Returns:\n            Dict[str, BaseScheduler]: A dictionary mapping parameter names to their schedulers.\n        \"\"\"\n        return self.schedulers\n\n    def get_scheduled_value(self, name: str) -&gt; float:\n        \"\"\"\n        Gets the current value for a scheduled parameter.\n\n        Args:\n            name (str): The name of the scheduled parameter.\n\n        Returns:\n            float: The current value of the parameter.\n\n        Raises:\n            KeyError: If no scheduler is registered for the parameter.\n        \"\"\"\n        if name not in self.schedulers:\n            raise KeyError(f\"No scheduler registered for parameter '{name}'\")\n        return self.schedulers[name].get_value()\n\n    def step_schedulers(self) -&gt; Dict[str, float]:\n        \"\"\"\n        Advances all schedulers by one step.\n\n        Returns:\n            Dict[str, float]: A dictionary mapping parameter names to their updated values.\n        \"\"\"\n        return {name: scheduler.step() for name, scheduler in self.schedulers.items()}\n\n    def reset_schedulers(self) -&gt; None:\n        \"\"\"Resets all schedulers to their initial state.\"\"\"\n        for scheduler in self.schedulers.values():\n            scheduler.reset()\n\n    # @abstractmethod\n    def _setup_diagnostics(self) -&gt; dict:\n        \"\"\"\n        Initialize the diagnostics dictionary.\n\n            .. deprecated:: 1.0\n               This method is deprecated and will be removed in a future version.\n        \"\"\"\n        return {\n            \"energies\": torch.empty(0, device=self.device, dtype=self.dtype),\n            \"acceptance_rate\": torch.tensor(0.0, device=self.device, dtype=self.dtype),\n        }\n        # raise NotImplementedError\n\n    # def to(\n    #     self, device: Union[str, torch.device], dtype: Optional[torch.dtype] = None\n    # ) -&gt; \"BaseSampler\":\n    #     \"\"\"\n    #     Move sampler to the specified device and optionally change its dtype.\n    #\n    #     Args:\n    #         device: Target device for computations\n    #         dtype: Optional data type to convert to\n    #\n    #     Returns:\n    #         The sampler instance moved to the specified device/dtype\n    #     \"\"\"\n    #     if isinstance(device, str):\n    #         device = torch.device(device)\n    #\n    #     self.device = device\n    #\n    #     if dtype is not None:\n    #         self.dtype = dtype\n    #\n    #     # Update mixed precision availability if device changed\n    #     if self.use_mixed_precision and not self.device.type.startswith(\"cuda\"):\n    #         warnings.warn(\n    #             f\"Mixed precision active but moving to {self.device}. \"\n    #             f\"Mixed precision requires CUDA. Disabling mixed precision.\",\n    #             UserWarning,\n    #         )\n    #         self.use_mixed_precision = False\n    #\n    #     # Move energy function if it has a to method\n    #     if hasattr(self.model, \"to\") and callable(\n    #         getattr(self.model, \"to\")\n    #     ):\n    #         self.model = self.model.to(\n    #             device=self.device, dtype=self.dtype\n    #         )\n    #\n    #     return self\n\n    def apply_mixed_precision(self, func):\n        \"\"\"\n        A decorator to apply the mixed precision context to a method.\n\n        Args:\n            func: The function to wrap.\n\n        Returns:\n            The wrapped function.\n        \"\"\"\n\n        def wrapper(*args, **kwargs):\n            with self.autocast_context():\n                return func(*args, **kwargs)\n\n        return wrapper\n\n    def to(self, *args, **kwargs):\n        \"\"\"Moves the sampler and its components to the specified device and/or dtype.\"\"\"\n        # Let DeviceMixin update internal state and parent class handle movement\n        result = super().to(*args, **kwargs)\n        # After move, make sure energy_function follows\n        self.model = DeviceMixin.safe_to(\n            self.model, device=self.device, dtype=self.dtype\n        )\n        return result\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype = dtype\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.schedulers","title":"schedulers  <code>instance-attribute</code>","text":"<pre><code>schedulers: Dict[str, BaseScheduler] = {}\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = safe_to(model, device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.sample","title":"sample  <code>abstractmethod</code>","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: int = 10, n_steps: int = 100, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False, *args, **kwargs) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]\n</code></pre> <p>Runs the sampling process.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Optional[Tensor]</code> <p>The initial state to start sampling from.</p> <code>None</code> <code>dim</code> <code>int</code> <p>The dimension of the state space.</p> <code>10</code> <code>n_steps</code> <code>int</code> <p>The number of MCMC steps to perform.</p> <code>100</code> <code>n_samples</code> <code>int</code> <p>The number of samples to generate.</p> <code>1</code> <code>thin</code> <code>int</code> <p>The thinning factor for samples (currently not supported).</p> <code>1</code> <code>return_trajectory</code> <code>bool</code> <p>Whether to return the full trajectory of the samples.</p> <code>False</code> <code>return_diagnostics</code> <code>bool</code> <p>Whether to return diagnostics of the sampling process.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, Tuple[Tensor, List[dict]]]</code> <p>Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]: - A tensor of samples from the model. - If <code>return_diagnostics</code> is <code>True</code>, a tuple containing the samples   and a list of diagnostics dictionaries.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>@abstractmethod\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: int = 10,\n    n_steps: int = 100,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n    *args,\n    **kwargs,\n) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n    \"\"\"\n    Runs the sampling process.\n\n    Args:\n        x (Optional[torch.Tensor]): The initial state to start sampling from.\n        dim (int): The dimension of the state space.\n        n_steps (int): The number of MCMC steps to perform.\n        n_samples (int): The number of samples to generate.\n        thin (int): The thinning factor for samples (currently not supported).\n        return_trajectory (bool): Whether to return the full trajectory of the samples.\n        return_diagnostics (bool): Whether to return diagnostics of the sampling process.\n\n    Returns:\n        Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n            - A tensor of samples from the model.\n            - If `return_diagnostics` is `True`, a tuple containing the samples\n              and a list of diagnostics dictionaries.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.register_scheduler","title":"register_scheduler","text":"<pre><code>register_scheduler(name: str, scheduler: BaseScheduler) -&gt; None\n</code></pre> <p>Registers a parameter scheduler.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the parameter to schedule.</p> required <code>scheduler</code> <code>BaseScheduler</code> <p>The scheduler instance.</p> required Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def register_scheduler(self, name: str, scheduler: BaseScheduler) -&gt; None:\n    \"\"\"\n    Registers a parameter scheduler.\n\n    Args:\n        name (str): The name of the parameter to schedule.\n        scheduler (BaseScheduler): The scheduler instance.\n    \"\"\"\n    self.schedulers[name] = scheduler\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.get_schedulers","title":"get_schedulers","text":"<pre><code>get_schedulers() -&gt; Dict[str, BaseScheduler]\n</code></pre> <p>Gets all registered schedulers.</p> <p>Returns:</p> Type Description <code>Dict[str, BaseScheduler]</code> <p>Dict[str, BaseScheduler]: A dictionary mapping parameter names to their schedulers.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def get_schedulers(self) -&gt; Dict[str, BaseScheduler]:\n    \"\"\"\n    Gets all registered schedulers.\n\n    Returns:\n        Dict[str, BaseScheduler]: A dictionary mapping parameter names to their schedulers.\n    \"\"\"\n    return self.schedulers\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.get_scheduled_value","title":"get_scheduled_value","text":"<pre><code>get_scheduled_value(name: str) -&gt; float\n</code></pre> <p>Gets the current value for a scheduled parameter.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the scheduled parameter.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The current value of the parameter.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If no scheduler is registered for the parameter.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def get_scheduled_value(self, name: str) -&gt; float:\n    \"\"\"\n    Gets the current value for a scheduled parameter.\n\n    Args:\n        name (str): The name of the scheduled parameter.\n\n    Returns:\n        float: The current value of the parameter.\n\n    Raises:\n        KeyError: If no scheduler is registered for the parameter.\n    \"\"\"\n    if name not in self.schedulers:\n        raise KeyError(f\"No scheduler registered for parameter '{name}'\")\n    return self.schedulers[name].get_value()\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.step_schedulers","title":"step_schedulers","text":"<pre><code>step_schedulers() -&gt; Dict[str, float]\n</code></pre> <p>Advances all schedulers by one step.</p> <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dict[str, float]: A dictionary mapping parameter names to their updated values.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def step_schedulers(self) -&gt; Dict[str, float]:\n    \"\"\"\n    Advances all schedulers by one step.\n\n    Returns:\n        Dict[str, float]: A dictionary mapping parameter names to their updated values.\n    \"\"\"\n    return {name: scheduler.step() for name, scheduler in self.schedulers.items()}\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.reset_schedulers","title":"reset_schedulers","text":"<pre><code>reset_schedulers() -&gt; None\n</code></pre> <p>Resets all schedulers to their initial state.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def reset_schedulers(self) -&gt; None:\n    \"\"\"Resets all schedulers to their initial state.\"\"\"\n    for scheduler in self.schedulers.values():\n        scheduler.reset()\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler._setup_diagnostics","title":"_setup_diagnostics","text":"<pre><code>_setup_diagnostics() -&gt; dict\n</code></pre> <p>Initialize the diagnostics dictionary.</p> <pre><code>.. deprecated:: 1.0\n   This method is deprecated and will be removed in a future version.\n</code></pre> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def _setup_diagnostics(self) -&gt; dict:\n    \"\"\"\n    Initialize the diagnostics dictionary.\n\n        .. deprecated:: 1.0\n           This method is deprecated and will be removed in a future version.\n    \"\"\"\n    return {\n        \"energies\": torch.empty(0, device=self.device, dtype=self.dtype),\n        \"acceptance_rate\": torch.tensor(0.0, device=self.device, dtype=self.dtype),\n    }\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.apply_mixed_precision","title":"apply_mixed_precision","text":"<pre><code>apply_mixed_precision(func)\n</code></pre> <p>A decorator to apply the mixed precision context to a method.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <p>The function to wrap.</p> required <p>Returns:</p> Type Description <p>The wrapped function.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def apply_mixed_precision(self, func):\n    \"\"\"\n    A decorator to apply the mixed precision context to a method.\n\n    Args:\n        func: The function to wrap.\n\n    Returns:\n        The wrapped function.\n    \"\"\"\n\n    def wrapper(*args, **kwargs):\n        with self.autocast_context():\n            return func(*args, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"api/torchebm/core/base_sampler/classes/BaseSampler/#torchebm.core.base_sampler.BaseSampler.to","title":"to","text":"<pre><code>to(*args, **kwargs)\n</code></pre> <p>Moves the sampler and its components to the specified device and/or dtype.</p> Source code in <code>torchebm/core/base_sampler.py</code> <pre><code>def to(self, *args, **kwargs):\n    \"\"\"Moves the sampler and its components to the specified device and/or dtype.\"\"\"\n    # Let DeviceMixin update internal state and parent class handle movement\n    result = super().to(*args, **kwargs)\n    # After move, make sure energy_function follows\n    self.model = DeviceMixin.safe_to(\n        self.model, device=self.device, dtype=self.dtype\n    )\n    return result\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/","title":"Torchebm &gt; Core &gt; Base_scheduler","text":""},{"location":"api/torchebm/core/base_scheduler/#torchebm-core-base_scheduler","title":"Torchebm &gt; Core &gt; Base_scheduler","text":""},{"location":"api/torchebm/core/base_scheduler/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_scheduler/#classes","title":"Classes","text":"<ul> <li><code>BaseScheduler</code> - Abstract base class for parameter schedulers.</li> <li><code>ConstantScheduler</code> - Scheduler that maintains a constant parameter value.</li> <li><code>CosineScheduler</code> - Scheduler with cosine annealing.</li> <li><code>ExponentialDecayScheduler</code> - Scheduler with exponential decay.</li> <li><code>LinearScheduler</code> - Scheduler with linear interpolation between start and end values.</li> <li><code>MultiStepScheduler</code> - Scheduler that reduces the parameter value at specific milestone steps.</li> <li><code>WarmupScheduler</code> - Scheduler that combines linear warmup with another scheduler.</li> </ul>"},{"location":"api/torchebm/core/base_scheduler/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_scheduler/#torchebm.core.base_scheduler","title":"torchebm.core.base_scheduler","text":"<p>Parameter schedulers for MCMC samplers and optimization algorithms.</p> <p>This module provides a comprehensive set of parameter schedulers that can be used to dynamically adjust parameters during training or sampling processes. Schedulers are particularly useful for controlling step sizes, noise scales, learning rates, and other hyperparameters that benefit from adaptive adjustment over time.</p> <p>The schedulers implement various mathematical schedules including exponential decay, linear annealing, cosine annealing, multi-step schedules, and warmup strategies. All schedulers inherit from the <code>BaseScheduler</code> abstract base class, ensuring a consistent interface across different scheduling strategies.</p> <p>Mathematical Foundation</p> <p>Parameter scheduling involves updating a parameter value \\(v(t)\\) at each time step \\(t\\) according to a predefined schedule. Common patterns include:</p> <ul> <li>Exponential decay: \\(v(t) = v_0 \\times \\gamma^t\\)</li> <li>Linear annealing: \\(v(t) = v_0 + (v_{end} - v_0) \\times t/T\\)</li> <li>Cosine annealing: \\(v(t) = v_{end} + (v_0 - v_{end}) \\times (1 + \\cos(\\pi t/T))/2\\)</li> </ul> <p>where \\(v_0\\) is the initial value, \\(v_{end}\\) is the final value, \\(T\\) is the total number of steps, and \\(\\gamma\\) is the decay rate.</p> <p>Basic Usage</p> <p>Basic usage with different scheduler types:</p> <pre><code>import torch\nfrom torchebm.core import ExponentialDecayScheduler, CosineScheduler\n\n# Exponential decay for step size\nstep_scheduler = ExponentialDecayScheduler(\n    start_value=0.1, decay_rate=0.99, min_value=0.001\n)\n\n# Cosine annealing for noise scale\nnoise_scheduler = CosineScheduler(\n    start_value=1.0, end_value=0.01, n_steps=1000\n)\n\n# Use in training loop\nfor epoch in range(100):\n    current_step_size = step_scheduler.step()\n    current_noise = noise_scheduler.step()\n    # Use current_step_size and current_noise in your algorithm\n</code></pre> <p>Integration with Samplers</p> <pre><code>from torchebm.samplers import LangevinDynamics\nfrom torchebm.core import LinearScheduler\n\n# Create scheduler for adaptive step size\nstep_scheduler = LinearScheduler(\n    start_value=0.1, end_value=0.001, n_steps=500\n)\n\n# Use with Langevin sampler\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=step_scheduler,\n    noise_scale=0.1\n)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/","title":"BaseScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for parameter schedulers.</p> <p>This class provides the foundation for all parameter scheduling strategies in TorchEBM. Schedulers are used to dynamically adjust parameters such as step sizes, noise scales, learning rates, and other hyperparameters during training or sampling processes.</p> <p>The scheduler maintains an internal step counter and computes parameter values based on the current step. Subclasses must implement the <code>_compute_value</code> method to define the specific scheduling strategy.</p> <p>Mathematical Foundation</p> <p>A scheduler defines a function \\(f: \\mathbb{N} \\to \\mathbb{R}\\) that maps step numbers to parameter values:</p> \\[v(t) = f(t)\\] <p>where \\(t\\) is the current step count and \\(v(t)\\) is the parameter value at step \\(t\\).</p> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>Initial parameter value at step 0.</p> required <p>Creating a Custom Scheduler</p> <pre><code>class CustomScheduler(BaseScheduler):\n    def __init__(self, start_value: float, factor: float):\n        super().__init__(start_value)\n        self.factor = factor\n\n    def _compute_value(self) -&gt; float:\n        return self.start_value * (self.factor ** self.step_count)\n\nscheduler = CustomScheduler(start_value=1.0, factor=0.9)\nfor i in range(5):\n    value = scheduler.step()\n    print(f\"Step {i+1}: {value:.4f}\")\n</code></pre> <p>State Management</p> <pre><code>scheduler = ExponentialDecayScheduler(start_value=0.1, decay_rate=0.95)\n# Take some steps\nfor _ in range(10):\n    scheduler.step()\n\n# Save state\nstate = scheduler.state_dict()\n\n# Reset and restore\nscheduler.reset()\nscheduler.load_state_dict(state)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class BaseScheduler(ABC):\n    r\"\"\"\n    Abstract base class for parameter schedulers.\n\n    This class provides the foundation for all parameter scheduling strategies in TorchEBM.\n    Schedulers are used to dynamically adjust parameters such as step sizes, noise scales,\n    learning rates, and other hyperparameters during training or sampling processes.\n\n    The scheduler maintains an internal step counter and computes parameter values based\n    on the current step. Subclasses must implement the `_compute_value` method to define\n    the specific scheduling strategy.\n\n    !!! info \"Mathematical Foundation\"\n        A scheduler defines a function \\(f: \\mathbb{N} \\to \\mathbb{R}\\) that maps step numbers to parameter values:\n\n        $$v(t) = f(t)$$\n\n        where \\(t\\) is the current step count and \\(v(t)\\) is the parameter value at step \\(t\\).\n\n    Args:\n        start_value (float): Initial parameter value at step 0.\n\n    Attributes:\n        start_value (float): The initial parameter value.\n        current_value (float): The current parameter value.\n        step_count (int): Number of steps taken since initialization or last reset.\n\n    !!! example \"Creating a Custom Scheduler\"\n        ```python\n        class CustomScheduler(BaseScheduler):\n            def __init__(self, start_value: float, factor: float):\n                super().__init__(start_value)\n                self.factor = factor\n\n            def _compute_value(self) -&gt; float:\n                return self.start_value * (self.factor ** self.step_count)\n\n        scheduler = CustomScheduler(start_value=1.0, factor=0.9)\n        for i in range(5):\n            value = scheduler.step()\n            print(f\"Step {i+1}: {value:.4f}\")\n        ```\n\n    !!! tip \"State Management\"\n        ```python\n        scheduler = ExponentialDecayScheduler(start_value=0.1, decay_rate=0.95)\n        # Take some steps\n        for _ in range(10):\n            scheduler.step()\n\n        # Save state\n        state = scheduler.state_dict()\n\n        # Reset and restore\n        scheduler.reset()\n        scheduler.load_state_dict(state)\n        ```\n    \"\"\"\n\n    def __init__(self, start_value: float):\n        r\"\"\"\n        Initialize the base scheduler.\n\n        Args:\n            start_value (float): Initial parameter value. Must be a finite number.\n\n        Raises:\n            TypeError: If start_value is not a float or int.\n        \"\"\"\n        if not isinstance(start_value, (float, int)):\n            raise TypeError(\n                f\"{type(self).__name__} received an invalid start_value of type \"\n                f\"{type(start_value).__name__}. Expected float or int.\"\n            )\n\n        self.start_value = float(start_value)\n        self.current_value = self.start_value\n        self.step_count = 0\n\n    @abstractmethod\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the parameter value for the current step count.\n\n        This method must be implemented by subclasses to define the specific\n        scheduling strategy. It should return the parameter value based on\n        the current `self.step_count`.\n\n        Returns:\n            float: The computed parameter value for the current step.\n\n        !!! warning \"Implementation Note\"\n            This method is called internally by `step()` after incrementing\n            the step counter. Subclasses should not call this method directly.\n        \"\"\"\n        pass\n\n    def step(self) -&gt; float:\n        r\"\"\"\n        Advance the scheduler by one step and return the new parameter value.\n\n        This method increments the internal step counter and computes the new\n        parameter value using the scheduler's strategy. The computed value\n        becomes the new current value.\n\n        Returns:\n            float: The new parameter value after stepping.\n\n        !!! example \"Basic Usage\"\n            ```python\n            scheduler = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.9)\n            print(f\"Initial: {scheduler.get_value()}\")  # 1.0\n            print(f\"Step 1: {scheduler.step()}\")        # 0.9\n            print(f\"Step 2: {scheduler.step()}\")        # 0.81\n            ```\n        \"\"\"\n        self.step_count += 1\n        self.current_value = self._compute_value()\n        return self.current_value\n\n    def reset(self) -&gt; None:\n        r\"\"\"\n        Reset the scheduler to its initial state.\n\n        This method resets both the step counter and current value to their\n        initial states, effectively restarting the scheduling process.\n\n        !!! example \"Reset Example\"\n            ```python\n            scheduler = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=10)\n            for _ in range(5):\n                scheduler.step()\n            print(f\"Before reset: step={scheduler.step_count}, value={scheduler.current_value}\")\n            scheduler.reset()\n            print(f\"After reset: step={scheduler.step_count}, value={scheduler.current_value}\")\n            ```\n        \"\"\"\n        self.current_value = self.start_value\n        self.step_count = 0\n\n    def get_value(self) -&gt; float:\n        r\"\"\"\n        Get the current parameter value without advancing the scheduler.\n\n        This method returns the current parameter value without modifying\n        the scheduler's internal state. Use this when you need to query\n        the current value without stepping.\n\n        Returns:\n            float: The current parameter value.\n\n        !!! example \"Query Current Value\"\n            ```python\n            scheduler = ConstantScheduler(start_value=0.5)\n            print(scheduler.get_value())  # 0.5\n            scheduler.step()\n            print(scheduler.get_value())  # 0.5 (still constant)\n            ```\n        \"\"\"\n        return self.current_value\n\n    def state_dict(self) -&gt; Dict[str, Any]:\n        r\"\"\"\n        Return the state of the scheduler as a dictionary.\n\n        This method returns a dictionary containing all the scheduler's internal\n        state, which can be used to save and restore the scheduler's state.\n\n        Returns:\n            Dict[str, Any]: Dictionary containing the scheduler's state.\n\n        !!! example \"State Management\"\n            ```python\n            scheduler = CosineScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n            for _ in range(50):\n                scheduler.step()\n            state = scheduler.state_dict()\n            print(state['step_count'])  # 50\n            ```\n        \"\"\"\n        return {key: value for key, value in self.__dict__.items()}\n\n    def load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\n        r\"\"\"\n        Load the scheduler's state from a dictionary.\n\n        This method restores the scheduler's internal state from a dictionary\n        previously created by `state_dict()`. This is useful for resuming\n        training or sampling from a checkpoint.\n\n        Args:\n            state_dict (Dict[str, Any]): Dictionary containing the scheduler state.\n                Should be an object returned from a call to `state_dict()`.\n\n        !!! example \"State Restoration\"\n            ```python\n            scheduler1 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n            for _ in range(25):\n                scheduler1.step()\n            state = scheduler1.state_dict()\n\n            scheduler2 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n            scheduler2.load_state_dict(state)\n            print(scheduler2.step_count)  # 25\n            ```\n        \"\"\"\n        self.__dict__.update(state_dict)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.start_value","title":"start_value  <code>instance-attribute</code>","text":"<pre><code>start_value = float(start_value)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.current_value","title":"current_value  <code>instance-attribute</code>","text":"<pre><code>current_value = start_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.step_count","title":"step_count  <code>instance-attribute</code>","text":"<pre><code>step_count = 0\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler._compute_value","title":"_compute_value  <code>abstractmethod</code>","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the parameter value for the current step count.</p> <p>This method must be implemented by subclasses to define the specific scheduling strategy. It should return the parameter value based on the current <code>self.step_count</code>.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed parameter value for the current step.</p> <p>Implementation Note</p> <p>This method is called internally by <code>step()</code> after incrementing the step counter. Subclasses should not call this method directly.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>@abstractmethod\ndef _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the parameter value for the current step count.\n\n    This method must be implemented by subclasses to define the specific\n    scheduling strategy. It should return the parameter value based on\n    the current `self.step_count`.\n\n    Returns:\n        float: The computed parameter value for the current step.\n\n    !!! warning \"Implementation Note\"\n        This method is called internally by `step()` after incrementing\n        the step counter. Subclasses should not call this method directly.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.step","title":"step","text":"<pre><code>step() -&gt; float\n</code></pre> <p>Advance the scheduler by one step and return the new parameter value.</p> <p>This method increments the internal step counter and computes the new parameter value using the scheduler's strategy. The computed value becomes the new current value.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The new parameter value after stepping.</p> <p>Basic Usage</p> <pre><code>scheduler = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.9)\nprint(f\"Initial: {scheduler.get_value()}\")  # 1.0\nprint(f\"Step 1: {scheduler.step()}\")        # 0.9\nprint(f\"Step 2: {scheduler.step()}\")        # 0.81\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def step(self) -&gt; float:\n    r\"\"\"\n    Advance the scheduler by one step and return the new parameter value.\n\n    This method increments the internal step counter and computes the new\n    parameter value using the scheduler's strategy. The computed value\n    becomes the new current value.\n\n    Returns:\n        float: The new parameter value after stepping.\n\n    !!! example \"Basic Usage\"\n        ```python\n        scheduler = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.9)\n        print(f\"Initial: {scheduler.get_value()}\")  # 1.0\n        print(f\"Step 1: {scheduler.step()}\")        # 0.9\n        print(f\"Step 2: {scheduler.step()}\")        # 0.81\n        ```\n    \"\"\"\n    self.step_count += 1\n    self.current_value = self._compute_value()\n    return self.current_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.reset","title":"reset","text":"<pre><code>reset() -&gt; None\n</code></pre> <p>Reset the scheduler to its initial state.</p> <p>This method resets both the step counter and current value to their initial states, effectively restarting the scheduling process.</p> <p>Reset Example</p> <pre><code>scheduler = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=10)\nfor _ in range(5):\n    scheduler.step()\nprint(f\"Before reset: step={scheduler.step_count}, value={scheduler.current_value}\")\nscheduler.reset()\nprint(f\"After reset: step={scheduler.step_count}, value={scheduler.current_value}\")\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def reset(self) -&gt; None:\n    r\"\"\"\n    Reset the scheduler to its initial state.\n\n    This method resets both the step counter and current value to their\n    initial states, effectively restarting the scheduling process.\n\n    !!! example \"Reset Example\"\n        ```python\n        scheduler = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=10)\n        for _ in range(5):\n            scheduler.step()\n        print(f\"Before reset: step={scheduler.step_count}, value={scheduler.current_value}\")\n        scheduler.reset()\n        print(f\"After reset: step={scheduler.step_count}, value={scheduler.current_value}\")\n        ```\n    \"\"\"\n    self.current_value = self.start_value\n    self.step_count = 0\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.get_value","title":"get_value","text":"<pre><code>get_value() -&gt; float\n</code></pre> <p>Get the current parameter value without advancing the scheduler.</p> <p>This method returns the current parameter value without modifying the scheduler's internal state. Use this when you need to query the current value without stepping.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The current parameter value.</p> <p>Query Current Value</p> <pre><code>scheduler = ConstantScheduler(start_value=0.5)\nprint(scheduler.get_value())  # 0.5\nscheduler.step()\nprint(scheduler.get_value())  # 0.5 (still constant)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def get_value(self) -&gt; float:\n    r\"\"\"\n    Get the current parameter value without advancing the scheduler.\n\n    This method returns the current parameter value without modifying\n    the scheduler's internal state. Use this when you need to query\n    the current value without stepping.\n\n    Returns:\n        float: The current parameter value.\n\n    !!! example \"Query Current Value\"\n        ```python\n        scheduler = ConstantScheduler(start_value=0.5)\n        print(scheduler.get_value())  # 0.5\n        scheduler.step()\n        print(scheduler.get_value())  # 0.5 (still constant)\n        ```\n    \"\"\"\n    return self.current_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.state_dict","title":"state_dict","text":"<pre><code>state_dict() -&gt; Dict[str, Any]\n</code></pre> <p>Return the state of the scheduler as a dictionary.</p> <p>This method returns a dictionary containing all the scheduler's internal state, which can be used to save and restore the scheduler's state.</p> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: Dictionary containing the scheduler's state.</p> <p>State Management</p> <pre><code>scheduler = CosineScheduler(start_value=1.0, end_value=0.0, n_steps=100)\nfor _ in range(50):\n    scheduler.step()\nstate = scheduler.state_dict()\nprint(state['step_count'])  # 50\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def state_dict(self) -&gt; Dict[str, Any]:\n    r\"\"\"\n    Return the state of the scheduler as a dictionary.\n\n    This method returns a dictionary containing all the scheduler's internal\n    state, which can be used to save and restore the scheduler's state.\n\n    Returns:\n        Dict[str, Any]: Dictionary containing the scheduler's state.\n\n    !!! example \"State Management\"\n        ```python\n        scheduler = CosineScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n        for _ in range(50):\n            scheduler.step()\n        state = scheduler.state_dict()\n        print(state['step_count'])  # 50\n        ```\n    \"\"\"\n    return {key: value for key, value in self.__dict__.items()}\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/BaseScheduler/#torchebm.core.base_scheduler.BaseScheduler.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict: Dict[str, Any]) -&gt; None\n</code></pre> <p>Load the scheduler's state from a dictionary.</p> <p>This method restores the scheduler's internal state from a dictionary previously created by <code>state_dict()</code>. This is useful for resuming training or sampling from a checkpoint.</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <code>Dict[str, Any]</code> <p>Dictionary containing the scheduler state. Should be an object returned from a call to <code>state_dict()</code>.</p> required <p>State Restoration</p> <pre><code>scheduler1 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\nfor _ in range(25):\n    scheduler1.step()\nstate = scheduler1.state_dict()\n\nscheduler2 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\nscheduler2.load_state_dict(state)\nprint(scheduler2.step_count)  # 25\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\n    r\"\"\"\n    Load the scheduler's state from a dictionary.\n\n    This method restores the scheduler's internal state from a dictionary\n    previously created by `state_dict()`. This is useful for resuming\n    training or sampling from a checkpoint.\n\n    Args:\n        state_dict (Dict[str, Any]): Dictionary containing the scheduler state.\n            Should be an object returned from a call to `state_dict()`.\n\n    !!! example \"State Restoration\"\n        ```python\n        scheduler1 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n        for _ in range(25):\n            scheduler1.step()\n        state = scheduler1.state_dict()\n\n        scheduler2 = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=100)\n        scheduler2.load_state_dict(state)\n        print(scheduler2.step_count)  # 25\n        ```\n    \"\"\"\n    self.__dict__.update(state_dict)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ConstantScheduler/","title":"ConstantScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/ConstantScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler that maintains a constant parameter value.</p> <p>This scheduler returns the same value at every step, effectively providing no scheduling. It's useful as a baseline or when you want to disable scheduling for certain parameters while keeping the scheduler interface.</p> <p>Mathematical Formula</p> \\[v(t) = v_0 \\text{ for all } t \\geq 0\\] <p>where \\(v_0\\) is the start_value.</p> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>The constant value to maintain.</p> required <p>Basic Usage</p> <pre><code>scheduler = ConstantScheduler(start_value=0.01)\nfor i in range(5):\n    value = scheduler.step()\n    print(f\"Step {i+1}: {value}\")  # Always prints 0.01\n</code></pre> <p>Using with Samplers</p> <pre><code>from torchebm.samplers import LangevinDynamics\nconstant_step = ConstantScheduler(start_value=0.05)\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=constant_step,\n    noise_scale=0.1\n)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class ConstantScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler that maintains a constant parameter value.\n\n    This scheduler returns the same value at every step, effectively providing\n    no scheduling. It's useful as a baseline or when you want to disable\n    scheduling for certain parameters while keeping the scheduler interface.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = v_0 \\text{ for all } t \\geq 0$$\n\n        where \\(v_0\\) is the start_value.\n\n    Args:\n        start_value (float): The constant value to maintain.\n\n    !!! example \"Basic Usage\"\n        ```python\n        scheduler = ConstantScheduler(start_value=0.01)\n        for i in range(5):\n            value = scheduler.step()\n            print(f\"Step {i+1}: {value}\")  # Always prints 0.01\n        ```\n\n    !!! tip \"Using with Samplers\"\n        ```python\n        from torchebm.samplers import LangevinDynamics\n        constant_step = ConstantScheduler(start_value=0.05)\n        sampler = LangevinDynamics(\n            energy_function=energy_fn,\n            step_size=constant_step,\n            noise_scale=0.1\n        )\n        ```\n    \"\"\"\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Return the constant value.\n\n        Returns:\n            float: The constant start_value.\n        \"\"\"\n        return self.start_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ConstantScheduler/#torchebm.core.base_scheduler.ConstantScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Return the constant value.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The constant start_value.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Return the constant value.\n\n    Returns:\n        float: The constant start_value.\n    \"\"\"\n    return self.start_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/CosineScheduler/","title":"CosineScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/CosineScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler with cosine annealing.</p> <p>This scheduler implements cosine annealing, which provides a smooth transition from the start value to the end value following a cosine curve. Cosine annealing is popular in deep learning as it provides fast initial decay followed by slower decay, which can help with convergence.</p> <p>Mathematical Formula</p> \\[v(t) = \\begin{cases} v_{end} + (v_0 - v_{end}) \\times \\frac{1 + \\cos(\\pi t/T)}{2}, &amp; \\text{if } t &lt; T \\\\ v_{end}, &amp; \\text{if } t \\geq T \\end{cases}\\] <p>where:</p> <ul> <li>\\(v_0\\) is the start_value</li> <li>\\(v_{end}\\) is the end_value  </li> <li>\\(T\\) is n_steps</li> <li>\\(t\\) is the current step count</li> </ul> <p>Cosine Curve Properties</p> <p>The cosine function creates a smooth S-shaped curve that starts with rapid decay and gradually slows down as it approaches the end value.</p> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>Starting parameter value.</p> required <code>end_value</code> <code>float</code> <p>Target parameter value.</p> required <code>n_steps</code> <code>int</code> <p>Number of steps to reach the final value.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_steps is not positive.</p> <p>Step Size Annealing</p> <pre><code>scheduler = CosineScheduler(start_value=0.1, end_value=0.001, n_steps=100)\nvalues = []\nfor i in range(10):\n    value = scheduler.step()\n    values.append(value)\n    if i &lt; 3:  # Show first few values\n        print(f\"Step {i+1}: {value:.6f}\")\n# Shows smooth decay: 0.099951, 0.099606, 0.098866, ...\n</code></pre> <p>Learning Rate Scheduling</p> <pre><code>lr_scheduler = CosineScheduler(\n    start_value=0.01, end_value=0.0001, n_steps=1000\n)\n# In training loop\nfor epoch in range(1000):\n    lr = lr_scheduler.step()\n    # Update optimizer learning rate\n</code></pre> <p>Noise Scale Annealing</p> <pre><code>noise_scheduler = CosineScheduler(\n    start_value=1.0, end_value=0.01, n_steps=500\n)\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.01,\n    noise_scale=noise_scheduler\n)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class CosineScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler with cosine annealing.\n\n    This scheduler implements cosine annealing, which provides a smooth transition\n    from the start value to the end value following a cosine curve. Cosine annealing\n    is popular in deep learning as it provides fast initial decay followed by\n    slower decay, which can help with convergence.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = \\begin{cases}\n        v_{end} + (v_0 - v_{end}) \\times \\frac{1 + \\cos(\\pi t/T)}{2}, &amp; \\text{if } t &lt; T \\\\\n        v_{end}, &amp; \\text{if } t \\geq T\n        \\end{cases}$$\n\n        where:\n\n        - \\(v_0\\) is the start_value\n        - \\(v_{end}\\) is the end_value  \n        - \\(T\\) is n_steps\n        - \\(t\\) is the current step count\n\n    !!! note \"Cosine Curve Properties\"\n        The cosine function creates a smooth S-shaped curve that starts with rapid\n        decay and gradually slows down as it approaches the end value.\n\n    Args:\n        start_value (float): Starting parameter value.\n        end_value (float): Target parameter value.\n        n_steps (int): Number of steps to reach the final value.\n\n    Raises:\n        ValueError: If n_steps is not positive.\n\n    !!! example \"Step Size Annealing\"\n        ```python\n        scheduler = CosineScheduler(start_value=0.1, end_value=0.001, n_steps=100)\n        values = []\n        for i in range(10):\n            value = scheduler.step()\n            values.append(value)\n            if i &lt; 3:  # Show first few values\n                print(f\"Step {i+1}: {value:.6f}\")\n        # Shows smooth decay: 0.099951, 0.099606, 0.098866, ...\n        ```\n\n    !!! tip \"Learning Rate Scheduling\"\n        ```python\n        lr_scheduler = CosineScheduler(\n            start_value=0.01, end_value=0.0001, n_steps=1000\n        )\n        # In training loop\n        for epoch in range(1000):\n            lr = lr_scheduler.step()\n            # Update optimizer learning rate\n        ```\n\n    !!! example \"Noise Scale Annealing\"\n        ```python\n        noise_scheduler = CosineScheduler(\n            start_value=1.0, end_value=0.01, n_steps=500\n        )\n        sampler = LangevinDynamics(\n            energy_function=energy_fn,\n            step_size=0.01,\n            noise_scale=noise_scheduler\n        )\n        ```\n    \"\"\"\n\n    def __init__(self, start_value: float, end_value: float, n_steps: int):\n        r\"\"\"\n        Initialize the cosine scheduler.\n\n        Args:\n            start_value (float): Starting parameter value.\n            end_value (float): Target parameter value.\n            n_steps (int): Number of steps to reach the final value.\n\n        Raises:\n            ValueError: If n_steps is not positive.\n        \"\"\"\n        super().__init__(start_value)\n        if n_steps &lt;= 0:\n            raise ValueError(f\"n_steps must be a positive integer, got {n_steps}\")\n\n        self.end_value = end_value\n        self.n_steps = n_steps\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the cosine annealed value.\n\n        Returns:\n            float: The annealed value following cosine schedule.\n        \"\"\"\n        if self.step_count &gt;= self.n_steps:\n            return self.end_value\n        else:\n            # Cosine schedule from start_value to end_value\n            progress = self.step_count / self.n_steps\n            cosine_factor = 0.5 * (1 + math.cos(math.pi * progress))\n            return self.end_value + (self.start_value - self.end_value) * cosine_factor\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/CosineScheduler/#torchebm.core.base_scheduler.CosineScheduler.end_value","title":"end_value  <code>instance-attribute</code>","text":"<pre><code>end_value = end_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/CosineScheduler/#torchebm.core.base_scheduler.CosineScheduler.n_steps","title":"n_steps  <code>instance-attribute</code>","text":"<pre><code>n_steps = n_steps\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/CosineScheduler/#torchebm.core.base_scheduler.CosineScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the cosine annealed value.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The annealed value following cosine schedule.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the cosine annealed value.\n\n    Returns:\n        float: The annealed value following cosine schedule.\n    \"\"\"\n    if self.step_count &gt;= self.n_steps:\n        return self.end_value\n    else:\n        # Cosine schedule from start_value to end_value\n        progress = self.step_count / self.n_steps\n        cosine_factor = 0.5 * (1 + math.cos(math.pi * progress))\n        return self.end_value + (self.start_value - self.end_value) * cosine_factor\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ExponentialDecayScheduler/","title":"ExponentialDecayScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/ExponentialDecayScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler with exponential decay.</p> <p>This scheduler implements exponential decay of the parameter value according to: \\(v(t) = \\max(v_{min}, v_0 \\times \\gamma^t)\\)</p> <p>Exponential decay is commonly used for step sizes in optimization and sampling algorithms, as it provides rapid initial decay that slows down over time, allowing for both exploration and convergence.</p> <p>Mathematical Formula</p> \\[v(t) = \\max(v_{min}, v_0 \\times \\gamma^t)\\] <p>where:</p> <ul> <li>\\(v_0\\) is the start_value</li> <li>\\(\\gamma\\) is the decay_rate \\((0 &lt; \\gamma \\leq 1)\\)</li> <li>\\(t\\) is the step count</li> <li>\\(v_{min}\\) is the min_value (lower bound)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>Initial parameter value.</p> required <code>decay_rate</code> <code>float</code> <p>Decay factor applied at each step. Must be in (0, 1].</p> required <code>min_value</code> <code>float</code> <p>Minimum value to clamp the result. Defaults to 0.0.</p> <code>0.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If decay_rate is not in (0, 1] or min_value is negative.</p> <p>Basic Exponential Decay</p> <pre><code>scheduler = ExponentialDecayScheduler(\n    start_value=1.0, decay_rate=0.9, min_value=0.01\n)\nfor i in range(5):\n    value = scheduler.step()\n    print(f\"Step {i+1}: {value:.4f}\")\n# Output: 0.9000, 0.8100, 0.7290, 0.6561, 0.5905\n</code></pre> <p>Training Loop Integration</p> <pre><code>step_scheduler = ExponentialDecayScheduler(\n    start_value=0.1, decay_rate=0.995, min_value=0.001\n)\n# In training loop\nfor epoch in range(1000):\n    current_step_size = step_scheduler.step()\n    # Use current_step_size in your algorithm\n</code></pre> <p>Decay Rate Selection</p> <ul> <li>Aggressive decay: Use smaller decay_rate (e.g., 0.5)</li> <li>Gentle decay: Use larger decay_rate (e.g., 0.99)</li> </ul> <pre><code># Aggressive decay\naggressive = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.5)\n# Gentle decay\ngentle = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.99)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class ExponentialDecayScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler with exponential decay.\n\n    This scheduler implements exponential decay of the parameter value according to:\n    \\(v(t) = \\max(v_{min}, v_0 \\times \\gamma^t)\\)\n\n    Exponential decay is commonly used for step sizes in optimization and sampling\n    algorithms, as it provides rapid initial decay that slows down over time,\n    allowing for both exploration and convergence.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = \\max(v_{min}, v_0 \\times \\gamma^t)$$\n\n        where:\n\n        - \\(v_0\\) is the start_value\n        - \\(\\gamma\\) is the decay_rate \\((0 &lt; \\gamma \\leq 1)\\)\n        - \\(t\\) is the step count\n        - \\(v_{min}\\) is the min_value (lower bound)\n\n    Args:\n        start_value (float): Initial parameter value.\n        decay_rate (float): Decay factor applied at each step. Must be in (0, 1].\n        min_value (float, optional): Minimum value to clamp the result. Defaults to 0.0.\n\n    Raises:\n        ValueError: If decay_rate is not in (0, 1] or min_value is negative.\n\n    !!! example \"Basic Exponential Decay\"\n        ```python\n        scheduler = ExponentialDecayScheduler(\n            start_value=1.0, decay_rate=0.9, min_value=0.01\n        )\n        for i in range(5):\n            value = scheduler.step()\n            print(f\"Step {i+1}: {value:.4f}\")\n        # Output: 0.9000, 0.8100, 0.7290, 0.6561, 0.5905\n        ```\n\n    !!! tip \"Training Loop Integration\"\n        ```python\n        step_scheduler = ExponentialDecayScheduler(\n            start_value=0.1, decay_rate=0.995, min_value=0.001\n        )\n        # In training loop\n        for epoch in range(1000):\n            current_step_size = step_scheduler.step()\n            # Use current_step_size in your algorithm\n        ```\n\n    !!! note \"Decay Rate Selection\"\n        - **Aggressive decay**: Use smaller decay_rate (e.g., 0.5)\n        - **Gentle decay**: Use larger decay_rate (e.g., 0.99)\n\n        ```python\n        # Aggressive decay\n        aggressive = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.5)\n        # Gentle decay\n        gentle = ExponentialDecayScheduler(start_value=1.0, decay_rate=0.99)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        start_value: float,\n        decay_rate: float,\n        min_value: float = 0.0,\n    ):\n        r\"\"\"\n        Initialize the exponential decay scheduler.\n\n        Args:\n            start_value (float): Initial parameter value.\n            decay_rate (float): Decay factor applied at each step. Must be in (0, 1].\n            min_value (float, optional): Minimum value to clamp the result. Defaults to 0.0.\n\n        Raises:\n            ValueError: If decay_rate is not in (0, 1] or min_value is negative.\n        \"\"\"\n        super().__init__(start_value)\n        if not 0.0 &lt; decay_rate &lt;= 1.0:\n            raise ValueError(f\"decay_rate must be in (0, 1], got {decay_rate}\")\n        if min_value &lt; 0:\n            raise ValueError(f\"min_value must be non-negative, got {min_value}\")\n        self.decay_rate: float = decay_rate\n        self.min_value: float = min_value\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the exponentially decayed value.\n\n        Returns:\n            float: The decayed value, clamped to min_value.\n        \"\"\"\n        val = self.start_value * (self.decay_rate**self.step_count)\n        return max(self.min_value, val)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ExponentialDecayScheduler/#torchebm.core.base_scheduler.ExponentialDecayScheduler.decay_rate","title":"decay_rate  <code>instance-attribute</code>","text":"<pre><code>decay_rate: float = decay_rate\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ExponentialDecayScheduler/#torchebm.core.base_scheduler.ExponentialDecayScheduler.min_value","title":"min_value  <code>instance-attribute</code>","text":"<pre><code>min_value: float = min_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/ExponentialDecayScheduler/#torchebm.core.base_scheduler.ExponentialDecayScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the exponentially decayed value.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The decayed value, clamped to min_value.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the exponentially decayed value.\n\n    Returns:\n        float: The decayed value, clamped to min_value.\n    \"\"\"\n    val = self.start_value * (self.decay_rate**self.step_count)\n    return max(self.min_value, val)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/","title":"LinearScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler with linear interpolation between start and end values.</p> <p>This scheduler linearly interpolates between a start value and an end value over a specified number of steps. After reaching the end value, it remains constant. Linear scheduling is useful when you want predictable, uniform changes in parameter values.</p> <p>Mathematical Formula</p> \\[v(t) = \\begin{cases} v_0 + (v_{end} - v_0) \\times \\frac{t}{T}, &amp; \\text{if } t &lt; T \\\\ v_{end}, &amp; \\text{if } t \\geq T \\end{cases}\\] <p>where:</p> <ul> <li>\\(v_0\\) is the start_value</li> <li>\\(v_{end}\\) is the end_value</li> <li>\\(T\\) is n_steps</li> <li>\\(t\\) is the current step count</li> </ul> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>Starting parameter value.</p> required <code>end_value</code> <code>float</code> <p>Target parameter value.</p> required <code>n_steps</code> <code>int</code> <p>Number of steps to reach the final value.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If n_steps is not positive.</p> <p>Linear Decay</p> <pre><code>scheduler = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=5)\nfor i in range(7):  # Go beyond n_steps to see clamping\n    value = scheduler.step()\n    print(f\"Step {i+1}: {value:.2f}\")\n# Output: 0.80, 0.60, 0.40, 0.20, 0.00, 0.00, 0.00\n</code></pre> <p>Warmup Strategy</p> <pre><code>warmup_scheduler = LinearScheduler(\n    start_value=0.0, end_value=0.1, n_steps=100\n)\n# Use for learning rate warmup\nfor epoch in range(100):\n    lr = warmup_scheduler.step()\n    # Set learning rate in optimizer\n</code></pre> <p>MCMC Integration</p> <pre><code>step_scheduler = LinearScheduler(\n    start_value=0.1, end_value=0.001, n_steps=1000\n)\n# Use in MCMC sampler\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=step_scheduler\n)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class LinearScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler with linear interpolation between start and end values.\n\n    This scheduler linearly interpolates between a start value and an end value\n    over a specified number of steps. After reaching the end value, it remains\n    constant. Linear scheduling is useful when you want predictable, uniform\n    changes in parameter values.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = \\begin{cases}\n        v_0 + (v_{end} - v_0) \\times \\frac{t}{T}, &amp; \\text{if } t &lt; T \\\\\n        v_{end}, &amp; \\text{if } t \\geq T\n        \\end{cases}$$\n\n        where:\n\n        - \\(v_0\\) is the start_value\n        - \\(v_{end}\\) is the end_value\n        - \\(T\\) is n_steps\n        - \\(t\\) is the current step count\n\n    Args:\n        start_value (float): Starting parameter value.\n        end_value (float): Target parameter value.\n        n_steps (int): Number of steps to reach the final value.\n\n    Raises:\n        ValueError: If n_steps is not positive.\n\n    !!! example \"Linear Decay\"\n        ```python\n        scheduler = LinearScheduler(start_value=1.0, end_value=0.0, n_steps=5)\n        for i in range(7):  # Go beyond n_steps to see clamping\n            value = scheduler.step()\n            print(f\"Step {i+1}: {value:.2f}\")\n        # Output: 0.80, 0.60, 0.40, 0.20, 0.00, 0.00, 0.00\n        ```\n\n    !!! tip \"Warmup Strategy\"\n        ```python\n        warmup_scheduler = LinearScheduler(\n            start_value=0.0, end_value=0.1, n_steps=100\n        )\n        # Use for learning rate warmup\n        for epoch in range(100):\n            lr = warmup_scheduler.step()\n            # Set learning rate in optimizer\n        ```\n\n    !!! example \"MCMC Integration\"\n        ```python\n        step_scheduler = LinearScheduler(\n            start_value=0.1, end_value=0.001, n_steps=1000\n        )\n        # Use in MCMC sampler\n        sampler = LangevinDynamics(\n            energy_function=energy_fn,\n            step_size=step_scheduler\n        )\n        ```\n    \"\"\"\n\n    def __init__(self, start_value: float, end_value: float, n_steps: int):\n        r\"\"\"\n        Initialize the linear scheduler.\n\n        Args:\n            start_value (float): Starting parameter value.\n            end_value (float): Target parameter value.\n            n_steps (int): Number of steps to reach the final value.\n\n        Raises:\n            ValueError: If n_steps is not positive.\n        \"\"\"\n        super().__init__(start_value)\n        if n_steps &lt;= 0:\n            raise ValueError(f\"n_steps must be positive, got {n_steps}\")\n\n        self.end_value = end_value\n        self.n_steps = n_steps\n        self.step_size: float = (end_value - start_value) / n_steps\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the linearly interpolated value.\n\n        Returns:\n            float: The interpolated value, clamped to end_value after n_steps.\n        \"\"\"\n        if self.step_count &gt;= self.n_steps:\n            return self.end_value\n        else:\n            return self.start_value + self.step_size * self.step_count\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/#torchebm.core.base_scheduler.LinearScheduler.end_value","title":"end_value  <code>instance-attribute</code>","text":"<pre><code>end_value = end_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/#torchebm.core.base_scheduler.LinearScheduler.n_steps","title":"n_steps  <code>instance-attribute</code>","text":"<pre><code>n_steps = n_steps\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/#torchebm.core.base_scheduler.LinearScheduler.step_size","title":"step_size  <code>instance-attribute</code>","text":"<pre><code>step_size: float = (end_value - start_value) / n_steps\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/LinearScheduler/#torchebm.core.base_scheduler.LinearScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the linearly interpolated value.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The interpolated value, clamped to end_value after n_steps.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the linearly interpolated value.\n\n    Returns:\n        float: The interpolated value, clamped to end_value after n_steps.\n    \"\"\"\n    if self.step_count &gt;= self.n_steps:\n        return self.end_value\n    else:\n        return self.start_value + self.step_size * self.step_count\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/MultiStepScheduler/","title":"MultiStepScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/MultiStepScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler that reduces the parameter value at specific milestone steps.</p> <p>This scheduler maintains the current value until reaching predefined milestone steps, at which point it multiplies the value by a decay factor (gamma). This creates a step-wise decay pattern commonly used in learning rate scheduling.</p> <p>Mathematical Formula</p> \\[v(t) = v_0 \\times \\gamma^k\\] <p>where:</p> <ul> <li>\\(v_0\\) is the start_value</li> <li>\\(\\gamma\\) is the gamma decay factor</li> <li>\\(k\\) is the number of milestones that have been reached by step \\(t\\)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>start_value</code> <code>float</code> <p>Initial parameter value.</p> required <code>milestones</code> <code>List[int]</code> <p>List of step numbers at which to apply decay. Must be positive and strictly increasing.</p> required <code>gamma</code> <code>float</code> <p>Multiplicative factor for decay. Defaults to 0.1.</p> <code>0.1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If milestones are not positive or not strictly increasing.</p> <p>Step-wise Learning Rate Decay</p> <pre><code>scheduler = MultiStepScheduler(\n    start_value=0.1,\n    milestones=[30, 60, 90],\n    gamma=0.1\n)\n# Simulate training steps\nfor step in [0, 29, 30, 31, 59, 60, 61, 89, 90, 91]:\n    if step &gt; 0:\n        scheduler.step_count = step\n        value = scheduler._compute_value()\n    else:\n        value = scheduler.get_value()\n    print(f\"Step {step}: {value:.4f}\")\n# Output shows: 0.1 until step 30, then 0.01, then 0.001 at step 60, etc.\n</code></pre> <p>Different Decay Strategies</p> <pre><code># Gentle decay\ngentle_scheduler = MultiStepScheduler(\n    start_value=1.0, milestones=[100, 200], gamma=0.5\n)\n\n# Aggressive decay\naggressive_scheduler = MultiStepScheduler(\n    start_value=1.0, milestones=[50, 100], gamma=0.01\n)\n</code></pre> <p>Training Loop Integration</p> <pre><code>step_scheduler = MultiStepScheduler(\n    start_value=0.01,\n    milestones=[500, 1000, 1500],\n    gamma=0.2\n)\n# In training loop\nfor epoch in range(2000):\n    current_step_size = step_scheduler.step()\n    # Use current_step_size in your algorithm\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class MultiStepScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler that reduces the parameter value at specific milestone steps.\n\n    This scheduler maintains the current value until reaching predefined milestone\n    steps, at which point it multiplies the value by a decay factor (gamma).\n    This creates a step-wise decay pattern commonly used in learning rate scheduling.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = v_0 \\times \\gamma^k$$\n\n        where:\n\n        - \\(v_0\\) is the start_value\n        - \\(\\gamma\\) is the gamma decay factor\n        - \\(k\\) is the number of milestones that have been reached by step \\(t\\)\n\n    Args:\n        start_value (float): Initial parameter value.\n        milestones (List[int]): List of step numbers at which to apply decay.\n            Must be positive and strictly increasing.\n        gamma (float, optional): Multiplicative factor for decay. Defaults to 0.1.\n\n    Raises:\n        ValueError: If milestones are not positive or not strictly increasing.\n\n    !!! example \"Step-wise Learning Rate Decay\"\n        ```python\n        scheduler = MultiStepScheduler(\n            start_value=0.1,\n            milestones=[30, 60, 90],\n            gamma=0.1\n        )\n        # Simulate training steps\n        for step in [0, 29, 30, 31, 59, 60, 61, 89, 90, 91]:\n            if step &gt; 0:\n                scheduler.step_count = step\n                value = scheduler._compute_value()\n            else:\n                value = scheduler.get_value()\n            print(f\"Step {step}: {value:.4f}\")\n        # Output shows: 0.1 until step 30, then 0.01, then 0.001 at step 60, etc.\n        ```\n\n    !!! tip \"Different Decay Strategies\"\n        ```python\n        # Gentle decay\n        gentle_scheduler = MultiStepScheduler(\n            start_value=1.0, milestones=[100, 200], gamma=0.5\n        )\n\n        # Aggressive decay\n        aggressive_scheduler = MultiStepScheduler(\n            start_value=1.0, milestones=[50, 100], gamma=0.01\n        )\n        ```\n\n    !!! example \"Training Loop Integration\"\n        ```python\n        step_scheduler = MultiStepScheduler(\n            start_value=0.01,\n            milestones=[500, 1000, 1500],\n            gamma=0.2\n        )\n        # In training loop\n        for epoch in range(2000):\n            current_step_size = step_scheduler.step()\n            # Use current_step_size in your algorithm\n        ```\n    \"\"\"\n\n    def __init__(self, start_value: float, milestones: List[int], gamma: float = 0.1):\n        r\"\"\"\n        Initialize the multi-step scheduler.\n\n        Args:\n            start_value (float): Initial parameter value.\n            milestones (List[int]): List of step numbers at which to apply decay.\n                Must be positive and strictly increasing.\n            gamma (float, optional): Multiplicative factor for decay. Defaults to 0.1.\n\n        Raises:\n            ValueError: If milestones are not positive or not strictly increasing.\n        \"\"\"\n        super().__init__(start_value)\n        if not all(m &gt; 0 for m in milestones):\n            raise ValueError(\"Milestone steps must be positive integers.\")\n        if not all(\n            milestones[i] &lt; milestones[i + 1] for i in range(len(milestones) - 1)\n        ):\n            raise ValueError(\"Milestones must be strictly increasing.\")\n        self.milestones = sorted(milestones)\n        self.gamma = gamma\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the value based on reached milestones.\n\n        Returns:\n            float: The parameter value after applying decay for reached milestones.\n        \"\"\"\n        power = sum(1 for m in self.milestones if self.step_count &gt;= m)\n        return self.start_value * (self.gamma**power)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/MultiStepScheduler/#torchebm.core.base_scheduler.MultiStepScheduler.milestones","title":"milestones  <code>instance-attribute</code>","text":"<pre><code>milestones = sorted(milestones)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/MultiStepScheduler/#torchebm.core.base_scheduler.MultiStepScheduler.gamma","title":"gamma  <code>instance-attribute</code>","text":"<pre><code>gamma = gamma\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/MultiStepScheduler/#torchebm.core.base_scheduler.MultiStepScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the value based on reached milestones.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The parameter value after applying decay for reached milestones.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the value based on reached milestones.\n\n    Returns:\n        float: The parameter value after applying decay for reached milestones.\n    \"\"\"\n    power = sum(1 for m in self.milestones if self.step_count &gt;= m)\n    return self.start_value * (self.gamma**power)\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/","title":"WarmupScheduler","text":""},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScheduler</code></p> <p>Scheduler that combines linear warmup with another scheduler.</p> <p>This scheduler implements a two-phase approach: first, it linearly increases the parameter value from a small initial value to the target value over a warmup period, then it follows the schedule defined by the main scheduler. Warmup is commonly used in deep learning to stabilize training in the initial phases.</p> <p>Mathematical Formula</p> \\[v(t) = \\begin{cases} v_{init} + (v_{target} - v_{init}) \\times \\frac{t}{T_{warmup}}, &amp; \\text{if } t &lt; T_{warmup} \\\\ \\text{main\\_scheduler}(t - T_{warmup}), &amp; \\text{if } t \\geq T_{warmup} \\end{cases}\\] <p>where:</p> <ul> <li>\\(v_{init} = v_{target} \\times \\text{warmup\\_init\\_factor}\\)</li> <li>\\(v_{target}\\) is the main scheduler's start_value</li> <li>\\(T_{warmup}\\) is warmup_steps</li> <li>\\(t\\) is the current step count</li> </ul> <p>Parameters:</p> Name Type Description Default <code>main_scheduler</code> <code>BaseScheduler</code> <p>The scheduler to use after warmup.</p> required <code>warmup_steps</code> <code>int</code> <p>Number of warmup steps.</p> required <code>warmup_init_factor</code> <code>float</code> <p>Factor to determine initial warmup value. Defaults to 0.01.</p> <code>0.01</code> <p>Learning Rate Warmup + Cosine Annealing</p> <pre><code>main_scheduler = CosineScheduler(\n    start_value=0.1, end_value=0.001, n_steps=1000\n)\nwarmup_scheduler = WarmupScheduler(\n    main_scheduler=main_scheduler,\n    warmup_steps=100,\n    warmup_init_factor=0.01\n)\n\n# First 100 steps: linear warmup from 0.001 to 0.1\n# Next 1000 steps: cosine annealing from 0.1 to 0.001\nfor i in range(10):\n    value = warmup_scheduler.step()\n    print(f\"Warmup step {i+1}: {value:.6f}\")\n</code></pre> <p>MCMC Sampling with Warmup</p> <pre><code>decay_scheduler = ExponentialDecayScheduler(\n    start_value=0.05, decay_rate=0.999, min_value=0.001\n)\nstep_scheduler = WarmupScheduler(\n    main_scheduler=decay_scheduler,\n    warmup_steps=50,\n    warmup_init_factor=0.1\n)\n\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=step_scheduler\n)\n</code></pre> <p>Noise Scale Warmup</p> <pre><code>linear_scheduler = LinearScheduler(\n    start_value=1.0, end_value=0.01, n_steps=500\n)\nnoise_scheduler = WarmupScheduler(\n    main_scheduler=linear_scheduler,\n    warmup_steps=25,\n    warmup_init_factor=0.05\n)\n</code></pre> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>class WarmupScheduler(BaseScheduler):\n    r\"\"\"\n    Scheduler that combines linear warmup with another scheduler.\n\n    This scheduler implements a two-phase approach: first, it linearly increases\n    the parameter value from a small initial value to the target value over a\n    warmup period, then it follows the schedule defined by the main scheduler.\n    Warmup is commonly used in deep learning to stabilize training in the\n    initial phases.\n\n    !!! info \"Mathematical Formula\"\n        $$v(t) = \\begin{cases}\n        v_{init} + (v_{target} - v_{init}) \\times \\frac{t}{T_{warmup}}, &amp; \\text{if } t &lt; T_{warmup} \\\\\n        \\text{main\\_scheduler}(t - T_{warmup}), &amp; \\text{if } t \\geq T_{warmup}\n        \\end{cases}$$\n\n        where:\n\n        - \\(v_{init} = v_{target} \\times \\text{warmup\\_init\\_factor}\\)\n        - \\(v_{target}\\) is the main scheduler's start_value\n        - \\(T_{warmup}\\) is warmup_steps\n        - \\(t\\) is the current step count\n\n    Args:\n        main_scheduler (BaseScheduler): The scheduler to use after warmup.\n        warmup_steps (int): Number of warmup steps.\n        warmup_init_factor (float, optional): Factor to determine initial warmup value.\n            Defaults to 0.01.\n\n    !!! example \"Learning Rate Warmup + Cosine Annealing\"\n        ```python\n        main_scheduler = CosineScheduler(\n            start_value=0.1, end_value=0.001, n_steps=1000\n        )\n        warmup_scheduler = WarmupScheduler(\n            main_scheduler=main_scheduler,\n            warmup_steps=100,\n            warmup_init_factor=0.01\n        )\n\n        # First 100 steps: linear warmup from 0.001 to 0.1\n        # Next 1000 steps: cosine annealing from 0.1 to 0.001\n        for i in range(10):\n            value = warmup_scheduler.step()\n            print(f\"Warmup step {i+1}: {value:.6f}\")\n        ```\n\n    !!! tip \"MCMC Sampling with Warmup\"\n        ```python\n        decay_scheduler = ExponentialDecayScheduler(\n            start_value=0.05, decay_rate=0.999, min_value=0.001\n        )\n        step_scheduler = WarmupScheduler(\n            main_scheduler=decay_scheduler,\n            warmup_steps=50,\n            warmup_init_factor=0.1\n        )\n\n        sampler = LangevinDynamics(\n            energy_function=energy_fn,\n            step_size=step_scheduler\n        )\n        ```\n\n    !!! example \"Noise Scale Warmup\"\n        ```python\n        linear_scheduler = LinearScheduler(\n            start_value=1.0, end_value=0.01, n_steps=500\n        )\n        noise_scheduler = WarmupScheduler(\n            main_scheduler=linear_scheduler,\n            warmup_steps=25,\n            warmup_init_factor=0.05\n        )\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        main_scheduler: BaseScheduler,\n        warmup_steps: int,\n        warmup_init_factor: float = 0.01,\n    ):\n        r\"\"\"\n        Initialize the warmup scheduler.\n\n        Args:\n            main_scheduler (BaseScheduler): The scheduler to use after warmup.\n            warmup_steps (int): Number of warmup steps.\n            warmup_init_factor (float, optional): Factor to determine initial warmup value.\n                The initial value will be main_scheduler.start_value * warmup_init_factor.\n                Defaults to 0.01.\n        \"\"\"\n        # Initialize based on the main scheduler's initial value\n        super().__init__(main_scheduler.start_value * warmup_init_factor)\n        self.main_scheduler = main_scheduler\n        self.warmup_steps = warmup_steps\n        self.warmup_init_factor = warmup_init_factor\n        self.target_value = main_scheduler.start_value  # Store the target after warmup\n\n        # Reset main scheduler as warmup controls the initial phase\n        self.main_scheduler.reset()\n\n    def _compute_value(self) -&gt; float:\n        r\"\"\"\n        Compute the value based on warmup phase or main scheduler.\n\n        Returns:\n            float: The parameter value from warmup or main scheduler.\n        \"\"\"\n        if self.step_count &lt; self.warmup_steps:\n            # Linear warmup phase\n            progress = self.step_count / self.warmup_steps\n            return self.start_value + progress * (self.target_value - self.start_value)\n        else:\n            # Main scheduler phase\n            # We need its value based on steps *after* warmup\n            main_scheduler_step = self.step_count - self.warmup_steps\n            # Temporarily set main scheduler state, get value, restore state\n            original_step = self.main_scheduler.step_count\n            original_value = self.main_scheduler.current_value\n            self.main_scheduler.step_count = main_scheduler_step\n            computed_main_value = self.main_scheduler._compute_value()\n            # Restore state\n            self.main_scheduler.step_count = original_step\n            self.main_scheduler.current_value = original_value\n            return computed_main_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#torchebm.core.base_scheduler.WarmupScheduler.main_scheduler","title":"main_scheduler  <code>instance-attribute</code>","text":"<pre><code>main_scheduler = main_scheduler\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#torchebm.core.base_scheduler.WarmupScheduler.warmup_steps","title":"warmup_steps  <code>instance-attribute</code>","text":"<pre><code>warmup_steps = warmup_steps\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#torchebm.core.base_scheduler.WarmupScheduler.warmup_init_factor","title":"warmup_init_factor  <code>instance-attribute</code>","text":"<pre><code>warmup_init_factor = warmup_init_factor\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#torchebm.core.base_scheduler.WarmupScheduler.target_value","title":"target_value  <code>instance-attribute</code>","text":"<pre><code>target_value = start_value\n</code></pre>"},{"location":"api/torchebm/core/base_scheduler/classes/WarmupScheduler/#torchebm.core.base_scheduler.WarmupScheduler._compute_value","title":"_compute_value","text":"<pre><code>_compute_value() -&gt; float\n</code></pre> <p>Compute the value based on warmup phase or main scheduler.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The parameter value from warmup or main scheduler.</p> Source code in <code>torchebm/core/base_scheduler.py</code> <pre><code>def _compute_value(self) -&gt; float:\n    r\"\"\"\n    Compute the value based on warmup phase or main scheduler.\n\n    Returns:\n        float: The parameter value from warmup or main scheduler.\n    \"\"\"\n    if self.step_count &lt; self.warmup_steps:\n        # Linear warmup phase\n        progress = self.step_count / self.warmup_steps\n        return self.start_value + progress * (self.target_value - self.start_value)\n    else:\n        # Main scheduler phase\n        # We need its value based on steps *after* warmup\n        main_scheduler_step = self.step_count - self.warmup_steps\n        # Temporarily set main scheduler state, get value, restore state\n        original_step = self.main_scheduler.step_count\n        original_value = self.main_scheduler.current_value\n        self.main_scheduler.step_count = main_scheduler_step\n        computed_main_value = self.main_scheduler._compute_value()\n        # Restore state\n        self.main_scheduler.step_count = original_step\n        self.main_scheduler.current_value = original_value\n        return computed_main_value\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/","title":"Torchebm &gt; Core &gt; Base_trainer","text":""},{"location":"api/torchebm/core/base_trainer/#torchebm-core-base_trainer","title":"Torchebm &gt; Core &gt; Base_trainer","text":""},{"location":"api/torchebm/core/base_trainer/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/base_trainer/#classes","title":"Classes","text":"<ul> <li><code>BaseTrainer</code> - Base class for training energy-based models.</li> <li><code>ContrastiveDivergenceTrainer</code> - Specialized trainer for contrastive divergence training of EBMs.</li> </ul>"},{"location":"api/torchebm/core/base_trainer/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/base_trainer/#torchebm.core.base_trainer","title":"torchebm.core.base_trainer","text":""},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/","title":"BaseTrainer","text":""},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#methods-and-attributes","title":"Methods and Attributes","text":"<p>Base class for training energy-based models.</p> <p>This class provides a generic interface for training EBMs, supporting various training methods and mixed precision training.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy function to train</p> required <code>optimizer</code> <code>Optimizer</code> <p>PyTorch optimizer to use</p> required <code>loss_fn</code> <code>BaseLoss</code> <p>Loss function for training</p> required <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device to run training on</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations</p> <code>float32</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision training</p> <code>False</code> <code>callbacks</code> <code>Optional[List[Callable]]</code> <p>List of callback functions for training events</p> <code>None</code> <p>Methods:</p> Name Description <code>train_step</code> <p>Perform a single training step</p> <code>train_epoch</code> <p>Train for a full epoch</p> <code>train</code> <p>Train for multiple epochs</p> <code>validate</code> <p>Validate the model</p> <code>save_checkpoint</code> <p>Save model checkpoint</p> <code>load_checkpoint</code> <p>Load model from checkpoint</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>class BaseTrainer:\n    \"\"\"\n    Base class for training energy-based models.\n\n    This class provides a generic interface for training EBMs, supporting various\n    training methods and mixed precision training.\n\n    Args:\n        model: Energy function to train\n        optimizer: PyTorch optimizer to use\n        loss_fn: Loss function for training\n        device: Device to run training on\n        dtype: Data type for computations\n        use_mixed_precision: Whether to use mixed precision training\n        callbacks: List of callback functions for training events\n\n    Methods:\n        train_step: Perform a single training step\n        train_epoch: Train for a full epoch\n        train: Train for multiple epochs\n        validate: Validate the model\n        save_checkpoint: Save model checkpoint\n        load_checkpoint: Load model from checkpoint\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        optimizer: torch.optim.Optimizer,\n        loss_fn: BaseLoss,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        use_mixed_precision: bool = False,\n        callbacks: Optional[List[Callable]] = None,\n    ):\n        self.model = model\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n\n        # Set up device\n        if isinstance(device, str):\n            device = torch.device(device)\n        self.device = device or torch.device(\n            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        )\n\n        # Set up dtype and mixed precision\n        self.dtype = dtype\n        self.use_mixed_precision = use_mixed_precision\n\n        # Initialize callbacks\n        self.callbacks = callbacks or []\n\n        # Configure mixed precision\n        if self.use_mixed_precision:\n            try:\n                from torch.cuda.amp import GradScaler\n                self.autocast_available = self.device.type.startswith(\"cuda\")\n                if self.autocast_available:\n                    self.grad_scaler = GradScaler()\n                else:\n                    warnings.warn(\n                        f\"Mixed precision requested but device is {self.device}. Mixed precision requires CUDA. Falling back to full precision.\",\n                        UserWarning,\n                    )\n                    self.use_mixed_precision = False\n                    self.autocast_available = False\n            except ImportError:\n                warnings.warn(\n                    \"Mixed precision requested but torch.cuda.amp not available. Falling back to full precision. Requires PyTorch 1.6+.\",\n                    UserWarning,\n                )\n                self.use_mixed_precision = False\n                self.autocast_available = False\n\n        # Move model and loss function to appropriate device/dtype\n        self.model = self.model.to(\n            device=self.device, dtype=self.dtype\n        )\n\n        # Propagate mixed precision settings to components\n        if hasattr(self.loss_fn, \"use_mixed_precision\"):\n            self.loss_fn.use_mixed_precision = self.use_mixed_precision\n        if hasattr(self.model, \"use_mixed_precision\"):\n            self.model.use_mixed_precision = self.use_mixed_precision\n\n        # Move loss function to appropriate device\n        if hasattr(self.loss_fn, \"to\"):\n            self.loss_fn = self.loss_fn.to(device=self.device, dtype=self.dtype)\n\n        # Create metrics dictionary for tracking\n        self.metrics: Dict[str, Any] = {\"loss\": []}\n\n    def autocast_context(self):\n        \"\"\"Return autocast context if enabled, else no-op.\"\"\"\n        if self.use_mixed_precision and self.autocast_available:\n            from torch.cuda.amp import autocast\n            return autocast()\n        return nullcontext()\n\n    def train_step(self, batch: torch.Tensor) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform a single training step.\n\n        Args:\n            batch: Batch of training data\n\n        Returns:\n            Dictionary containing metrics from this step\n        \"\"\"\n        # Ensure batch is on the correct device and dtype\n        batch = batch.to(device=self.device, dtype=self.dtype)\n\n        # Zero gradients\n        self.optimizer.zero_grad()\n\n        # Forward pass with mixed precision if enabled\n        if self.use_mixed_precision and self.autocast_available:\n            with self.autocast_context():\n                loss = self.loss_fn(batch)\n\n            # Backward pass with gradient scaling\n            self.grad_scaler.scale(loss).backward()\n            self.grad_scaler.step(self.optimizer)\n            self.grad_scaler.update()\n        else:\n            # Standard training step\n            loss = self.loss_fn(batch)\n            loss.backward()\n            self.optimizer.step()\n\n        # Return metrics\n        return {\"loss\": loss.item()}\n\n    def train_epoch(self, dataloader: DataLoader) -&gt; Dict[str, float]:\n        \"\"\"\n        Train for one epoch.\n\n        Args:\n            dataloader: DataLoader containing training data\n\n        Returns:\n            Dictionary with average metrics for the epoch\n        \"\"\"\n        # Set model to training mode\n        self.model.train()\n\n        # Initialize metrics for this epoch\n        epoch_metrics: Dict[str, List[float]] = {\"loss\": []}\n\n        # Iterate through batches\n        for batch in dataloader:\n            # Call any batch start callbacks\n            for callback in self.callbacks:\n                if hasattr(callback, \"on_batch_start\"):\n                    callback.on_batch_start(self, batch)\n\n            # Perform training step\n            step_metrics = self.train_step(batch)\n\n            # Update epoch metrics\n            for key, value in step_metrics.items():\n                if key not in epoch_metrics:\n                    epoch_metrics[key] = []\n                epoch_metrics[key].append(value)\n\n            # Call any batch end callbacks\n            for callback in self.callbacks:\n                if hasattr(callback, \"on_batch_end\"):\n                    callback.on_batch_end(self, batch, step_metrics)\n\n        # Calculate average metrics\n        avg_metrics = {\n            key: sum(values) / len(values) for key, values in epoch_metrics.items()\n        }\n\n        return avg_metrics\n\n    def train(\n        self,\n        dataloader: DataLoader,\n        num_epochs: int,\n        validate_fn: Optional[Callable] = None,\n    ) -&gt; Dict[str, List[float]]:\n        \"\"\"\n        Train the model for multiple epochs.\n\n        Args:\n            dataloader: DataLoader containing training data\n            num_epochs: Number of epochs to train for\n            validate_fn: Optional function for validation after each epoch\n\n        Returns:\n            Dictionary with metrics over all epochs\n        \"\"\"\n        # Initialize training history\n        history: Dict[str, List[float]] = {\"loss\": []}\n\n        # Call any training start callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_train_start\"):\n                callback.on_train_start(self)\n\n        # Train for specified number of epochs\n        for epoch in range(num_epochs):\n            # Call any epoch start callbacks\n            for callback in self.callbacks:\n                if hasattr(callback, \"on_epoch_start\"):\n                    callback.on_epoch_start(self, epoch)\n\n            # Train for one epoch\n            epoch_metrics = self.train_epoch(dataloader)\n\n            # Update training history\n            for key, value in epoch_metrics.items():\n                if key not in history:\n                    history[key] = []\n                history[key].append(value)\n\n            # Print progress\n            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_metrics['loss']:.6f}\")\n\n            # Validate if function provided\n            if validate_fn is not None:\n                val_metrics = validate_fn(self.model)\n                print(f\"Validation: {val_metrics}\")\n\n                # Update validation metrics in history\n                for key, value in val_metrics.items():\n                    val_key = f\"val_{key}\"\n                    if val_key not in history:\n                        history[val_key] = []\n                    history[val_key].append(value)\n\n            # Call any epoch end callbacks\n            for callback in self.callbacks:\n                if hasattr(callback, \"on_epoch_end\"):\n                    callback.on_epoch_end(self, epoch, epoch_metrics)\n\n        # Call any training end callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_train_end\"):\n                callback.on_train_end(self, history)\n\n        return history\n\n    def save_checkpoint(self, path: str) -&gt; None:\n        \"\"\"\n        Save a checkpoint of the current training state.\n\n        Args:\n            path: Path to save the checkpoint to\n        \"\"\"\n        checkpoint = {\n            \"model_state_dict\": self.model.state_dict(),\n            \"optimizer_state_dict\": self.optimizer.state_dict(),\n            \"metrics\": self.metrics,\n        }\n\n        if self.use_mixed_precision and hasattr(self, \"grad_scaler\"):\n            checkpoint[\"grad_scaler_state_dict\"] = self.grad_scaler.state_dict()\n\n        torch.save(checkpoint, path)\n\n    def load_checkpoint(self, path: str) -&gt; None:\n        \"\"\"\n        Load a checkpoint to resume training.\n\n        Args:\n            path: Path to the checkpoint file\n        \"\"\"\n        checkpoint = torch.load(path, map_location=self.device)\n\n        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n        if \"metrics\" in checkpoint:\n            self.metrics = checkpoint[\"metrics\"]\n\n        if (\n            self.use_mixed_precision\n            and \"grad_scaler_state_dict\" in checkpoint\n            and hasattr(self, \"grad_scaler\")\n        ):\n            self.grad_scaler.load_state_dict(checkpoint[\"grad_scaler_state_dict\"])\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.optimizer","title":"optimizer  <code>instance-attribute</code>","text":"<pre><code>optimizer = optimizer\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.loss_fn","title":"loss_fn  <code>instance-attribute</code>","text":"<pre><code>loss_fn = loss_fn\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.device","title":"device  <code>instance-attribute</code>","text":"<pre><code>device = device or device('cuda' if is_available() else 'cpu')\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype = dtype\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.use_mixed_precision","title":"use_mixed_precision  <code>instance-attribute</code>","text":"<pre><code>use_mixed_precision = use_mixed_precision\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.callbacks","title":"callbacks  <code>instance-attribute</code>","text":"<pre><code>callbacks = callbacks or []\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.autocast_available","title":"autocast_available  <code>instance-attribute</code>","text":"<pre><code>autocast_available = startswith('cuda')\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.grad_scaler","title":"grad_scaler  <code>instance-attribute</code>","text":"<pre><code>grad_scaler = GradScaler()\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = to(device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.metrics","title":"metrics  <code>instance-attribute</code>","text":"<pre><code>metrics: Dict[str, Any] = {'loss': []}\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.autocast_context","title":"autocast_context","text":"<pre><code>autocast_context()\n</code></pre> <p>Return autocast context if enabled, else no-op.</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def autocast_context(self):\n    \"\"\"Return autocast context if enabled, else no-op.\"\"\"\n    if self.use_mixed_precision and self.autocast_available:\n        from torch.cuda.amp import autocast\n        return autocast()\n    return nullcontext()\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.train_step","title":"train_step","text":"<pre><code>train_step(batch: Tensor) -&gt; Dict[str, Any]\n</code></pre> <p>Perform a single training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Batch of training data</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing metrics from this step</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def train_step(self, batch: torch.Tensor) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform a single training step.\n\n    Args:\n        batch: Batch of training data\n\n    Returns:\n        Dictionary containing metrics from this step\n    \"\"\"\n    # Ensure batch is on the correct device and dtype\n    batch = batch.to(device=self.device, dtype=self.dtype)\n\n    # Zero gradients\n    self.optimizer.zero_grad()\n\n    # Forward pass with mixed precision if enabled\n    if self.use_mixed_precision and self.autocast_available:\n        with self.autocast_context():\n            loss = self.loss_fn(batch)\n\n        # Backward pass with gradient scaling\n        self.grad_scaler.scale(loss).backward()\n        self.grad_scaler.step(self.optimizer)\n        self.grad_scaler.update()\n    else:\n        # Standard training step\n        loss = self.loss_fn(batch)\n        loss.backward()\n        self.optimizer.step()\n\n    # Return metrics\n    return {\"loss\": loss.item()}\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.train_epoch","title":"train_epoch","text":"<pre><code>train_epoch(dataloader: DataLoader) -&gt; Dict[str, float]\n</code></pre> <p>Train for one epoch.</p> <p>Parameters:</p> Name Type Description Default <code>dataloader</code> <code>DataLoader</code> <p>DataLoader containing training data</p> required <p>Returns:</p> Type Description <code>Dict[str, float]</code> <p>Dictionary with average metrics for the epoch</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def train_epoch(self, dataloader: DataLoader) -&gt; Dict[str, float]:\n    \"\"\"\n    Train for one epoch.\n\n    Args:\n        dataloader: DataLoader containing training data\n\n    Returns:\n        Dictionary with average metrics for the epoch\n    \"\"\"\n    # Set model to training mode\n    self.model.train()\n\n    # Initialize metrics for this epoch\n    epoch_metrics: Dict[str, List[float]] = {\"loss\": []}\n\n    # Iterate through batches\n    for batch in dataloader:\n        # Call any batch start callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_batch_start\"):\n                callback.on_batch_start(self, batch)\n\n        # Perform training step\n        step_metrics = self.train_step(batch)\n\n        # Update epoch metrics\n        for key, value in step_metrics.items():\n            if key not in epoch_metrics:\n                epoch_metrics[key] = []\n            epoch_metrics[key].append(value)\n\n        # Call any batch end callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_batch_end\"):\n                callback.on_batch_end(self, batch, step_metrics)\n\n    # Calculate average metrics\n    avg_metrics = {\n        key: sum(values) / len(values) for key, values in epoch_metrics.items()\n    }\n\n    return avg_metrics\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.train","title":"train","text":"<pre><code>train(dataloader: DataLoader, num_epochs: int, validate_fn: Optional[Callable] = None) -&gt; Dict[str, List[float]]\n</code></pre> <p>Train the model for multiple epochs.</p> <p>Parameters:</p> Name Type Description Default <code>dataloader</code> <code>DataLoader</code> <p>DataLoader containing training data</p> required <code>num_epochs</code> <code>int</code> <p>Number of epochs to train for</p> required <code>validate_fn</code> <code>Optional[Callable]</code> <p>Optional function for validation after each epoch</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, List[float]]</code> <p>Dictionary with metrics over all epochs</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def train(\n    self,\n    dataloader: DataLoader,\n    num_epochs: int,\n    validate_fn: Optional[Callable] = None,\n) -&gt; Dict[str, List[float]]:\n    \"\"\"\n    Train the model for multiple epochs.\n\n    Args:\n        dataloader: DataLoader containing training data\n        num_epochs: Number of epochs to train for\n        validate_fn: Optional function for validation after each epoch\n\n    Returns:\n        Dictionary with metrics over all epochs\n    \"\"\"\n    # Initialize training history\n    history: Dict[str, List[float]] = {\"loss\": []}\n\n    # Call any training start callbacks\n    for callback in self.callbacks:\n        if hasattr(callback, \"on_train_start\"):\n            callback.on_train_start(self)\n\n    # Train for specified number of epochs\n    for epoch in range(num_epochs):\n        # Call any epoch start callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_epoch_start\"):\n                callback.on_epoch_start(self, epoch)\n\n        # Train for one epoch\n        epoch_metrics = self.train_epoch(dataloader)\n\n        # Update training history\n        for key, value in epoch_metrics.items():\n            if key not in history:\n                history[key] = []\n            history[key].append(value)\n\n        # Print progress\n        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_metrics['loss']:.6f}\")\n\n        # Validate if function provided\n        if validate_fn is not None:\n            val_metrics = validate_fn(self.model)\n            print(f\"Validation: {val_metrics}\")\n\n            # Update validation metrics in history\n            for key, value in val_metrics.items():\n                val_key = f\"val_{key}\"\n                if val_key not in history:\n                    history[val_key] = []\n                history[val_key].append(value)\n\n        # Call any epoch end callbacks\n        for callback in self.callbacks:\n            if hasattr(callback, \"on_epoch_end\"):\n                callback.on_epoch_end(self, epoch, epoch_metrics)\n\n    # Call any training end callbacks\n    for callback in self.callbacks:\n        if hasattr(callback, \"on_train_end\"):\n            callback.on_train_end(self, history)\n\n    return history\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.save_checkpoint","title":"save_checkpoint","text":"<pre><code>save_checkpoint(path: str) -&gt; None\n</code></pre> <p>Save a checkpoint of the current training state.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to save the checkpoint to</p> required Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def save_checkpoint(self, path: str) -&gt; None:\n    \"\"\"\n    Save a checkpoint of the current training state.\n\n    Args:\n        path: Path to save the checkpoint to\n    \"\"\"\n    checkpoint = {\n        \"model_state_dict\": self.model.state_dict(),\n        \"optimizer_state_dict\": self.optimizer.state_dict(),\n        \"metrics\": self.metrics,\n    }\n\n    if self.use_mixed_precision and hasattr(self, \"grad_scaler\"):\n        checkpoint[\"grad_scaler_state_dict\"] = self.grad_scaler.state_dict()\n\n    torch.save(checkpoint, path)\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/BaseTrainer/#torchebm.core.base_trainer.BaseTrainer.load_checkpoint","title":"load_checkpoint","text":"<pre><code>load_checkpoint(path: str) -&gt; None\n</code></pre> <p>Load a checkpoint to resume training.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the checkpoint file</p> required Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def load_checkpoint(self, path: str) -&gt; None:\n    \"\"\"\n    Load a checkpoint to resume training.\n\n    Args:\n        path: Path to the checkpoint file\n    \"\"\"\n    checkpoint = torch.load(path, map_location=self.device)\n\n    self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n    self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n    if \"metrics\" in checkpoint:\n        self.metrics = checkpoint[\"metrics\"]\n\n    if (\n        self.use_mixed_precision\n        and \"grad_scaler_state_dict\" in checkpoint\n        and hasattr(self, \"grad_scaler\")\n    ):\n        self.grad_scaler.load_state_dict(checkpoint[\"grad_scaler_state_dict\"])\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/ContrastiveDivergenceTrainer/","title":"ContrastiveDivergenceTrainer","text":""},{"location":"api/torchebm/core/base_trainer/classes/ContrastiveDivergenceTrainer/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseTrainer</code></p> <p>Specialized trainer for contrastive divergence training of EBMs.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy function to train</p> required <code>sampler</code> <code>BaseSampler</code> <p>MCMC sampler for generating negative samples</p> required <code>optimizer</code> <code>Optional[Optimizer]</code> <p>PyTorch optimizer</p> <code>None</code> <code>learning_rate</code> <code>float</code> <p>Learning rate (if optimizer not provided)</p> <code>0.01</code> <code>k_steps</code> <code>int</code> <p>Number of MCMC steps for generating samples</p> <code>10</code> <code>persistent</code> <code>bool</code> <p>Whether to use persistent contrastive divergence (PCD)</p> <code>False</code> <code>buffer_size</code> <code>int</code> <p>Replay buffer size for PCD</p> <code>1000</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device to run training on</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations</p> <code>float32</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision training</p> <code>False</code> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>class ContrastiveDivergenceTrainer(BaseTrainer):\n    \"\"\"\n    Specialized trainer for contrastive divergence training of EBMs.\n\n    Args:\n        model: Energy function to train\n        sampler: MCMC sampler for generating negative samples\n        optimizer: PyTorch optimizer\n        learning_rate: Learning rate (if optimizer not provided)\n        k_steps: Number of MCMC steps for generating samples\n        persistent: Whether to use persistent contrastive divergence (PCD)\n        buffer_size: Replay buffer size for PCD\n        device: Device to run training on\n        dtype: Data type for computations\n        use_mixed_precision: Whether to use mixed precision training\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        sampler: BaseSampler,\n        optimizer: Optional[torch.optim.Optimizer] = None,\n        learning_rate: float = 0.01,\n        k_steps: int = 10,\n        persistent: bool = False,\n        buffer_size: int = 1000,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        use_mixed_precision: bool = False,\n    ):\n        # Create optimizer if not provided\n        if optimizer is None:\n            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n        # Import here to avoid circular import\n        from torchebm.losses.contrastive_divergence import ContrastiveDivergence\n\n        # Create loss function\n        loss_fn = ContrastiveDivergence(\n            model=model,\n            sampler=sampler,\n            k_steps=k_steps,\n            persistent=persistent,\n            buffer_size=buffer_size,\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n        )\n\n        # Initialize base trainer\n        super().__init__(\n            model=model,\n            optimizer=optimizer,\n            loss_fn=loss_fn,\n            device=device,\n            dtype=dtype,\n            use_mixed_precision=use_mixed_precision,\n        )\n\n        self.sampler = sampler\n\n    def train_step(self, batch: torch.Tensor) -&gt; Dict[str, Any]:\n        \"\"\"\n        Perform a single contrastive divergence training step.\n\n        Args:\n            batch: Batch of real data samples\n\n        Returns:\n            Dictionary containing metrics from this step\n        \"\"\"\n        # Ensure batch is on the correct device and dtype\n        batch = batch.to(device=self.device, dtype=self.dtype)\n\n        # Zero gradients\n        self.optimizer.zero_grad()\n\n        # Forward pass with mixed precision if enabled\n        if self.use_mixed_precision and self.autocast_available:\n            with self.autocast_context():\n                # ContrastiveDivergence returns (loss, neg_samples)\n                loss, neg_samples = self.loss_fn(batch)\n\n            # Backward pass with gradient scaling\n            self.grad_scaler.scale(loss).backward()\n            self.grad_scaler.step(self.optimizer)\n            self.grad_scaler.update()\n        else:\n            # Standard training step\n            loss, neg_samples = self.loss_fn(batch)\n            loss.backward()\n            self.optimizer.step()\n\n        # Return metrics\n        return {\n            \"loss\": loss.item(),\n            \"pos_energy\": self.model(batch).mean().item(),\n            \"neg_energy\": self.model(neg_samples).mean().item(),\n        }\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/ContrastiveDivergenceTrainer/#torchebm.core.base_trainer.ContrastiveDivergenceTrainer.sampler","title":"sampler  <code>instance-attribute</code>","text":"<pre><code>sampler = sampler\n</code></pre>"},{"location":"api/torchebm/core/base_trainer/classes/ContrastiveDivergenceTrainer/#torchebm.core.base_trainer.ContrastiveDivergenceTrainer.train_step","title":"train_step","text":"<pre><code>train_step(batch: Tensor) -&gt; Dict[str, Any]\n</code></pre> <p>Perform a single contrastive divergence training step.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Tensor</code> <p>Batch of real data samples</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dictionary containing metrics from this step</p> Source code in <code>torchebm/core/base_trainer.py</code> <pre><code>def train_step(self, batch: torch.Tensor) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform a single contrastive divergence training step.\n\n    Args:\n        batch: Batch of real data samples\n\n    Returns:\n        Dictionary containing metrics from this step\n    \"\"\"\n    # Ensure batch is on the correct device and dtype\n    batch = batch.to(device=self.device, dtype=self.dtype)\n\n    # Zero gradients\n    self.optimizer.zero_grad()\n\n    # Forward pass with mixed precision if enabled\n    if self.use_mixed_precision and self.autocast_available:\n        with self.autocast_context():\n            # ContrastiveDivergence returns (loss, neg_samples)\n            loss, neg_samples = self.loss_fn(batch)\n\n        # Backward pass with gradient scaling\n        self.grad_scaler.scale(loss).backward()\n        self.grad_scaler.step(self.optimizer)\n        self.grad_scaler.update()\n    else:\n        # Standard training step\n        loss, neg_samples = self.loss_fn(batch)\n        loss.backward()\n        self.optimizer.step()\n\n    # Return metrics\n    return {\n        \"loss\": loss.item(),\n        \"pos_energy\": self.model(batch).mean().item(),\n        \"neg_energy\": self.model(neg_samples).mean().item(),\n    }\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/","title":"Torchebm &gt; Core &gt; Device_mixin","text":""},{"location":"api/torchebm/core/device_mixin/#torchebm-core-device_mixin","title":"Torchebm &gt; Core &gt; Device_mixin","text":""},{"location":"api/torchebm/core/device_mixin/#contents","title":"Contents","text":""},{"location":"api/torchebm/core/device_mixin/#classes","title":"Classes","text":"<ul> <li><code>DeviceMixin</code> - A mixin for consistent device and dtype management across all modules.</li> </ul>"},{"location":"api/torchebm/core/device_mixin/#functions","title":"Functions","text":"<ul> <li><code>normalize_device()</code> - Normalizes the device identifier for consistent usage.</li> </ul>"},{"location":"api/torchebm/core/device_mixin/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/core/device_mixin/#torchebm.core.device_mixin","title":"torchebm.core.device_mixin","text":"<p>This module handles the device management or TorchEBM modules</p>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/","title":"DeviceMixin","text":""},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#methods-and-attributes","title":"Methods and Attributes","text":"<p>A mixin for consistent device and dtype management across all modules.</p> <p>This should be inherited by all classes that are sensitive to device or dtype.</p> Source code in <code>torchebm/core/device_mixin.py</code> <pre><code>class DeviceMixin:\n    \"\"\"\n    A mixin for consistent device and dtype management across all modules.\n\n    This should be inherited by all classes that are sensitive to device or dtype.\n    \"\"\"\n\n    def __init__(self, device: Union[str, torch.device, None] = None, dtype: Optional[torch.dtype] = None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._device = normalize_device(device)\n        self._dtype: Optional[torch.dtype] = dtype\n\n    @property\n    def device(self) -&gt; torch.device:\n        if self._device is not None:\n            return normalize_device(self._device)\n        if self._device is None:\n            if hasattr(self, \"parameters\") and callable(getattr(self, \"parameters\")):\n                try:\n                    param_device = next(self.parameters()).device\n                    return normalize_device(param_device)\n                except StopIteration:\n                    pass\n\n            if hasattr(self, \"buffers\") and callable(getattr(self, \"buffers\")):\n                try:\n                    buffer_device = next(self.buffers()).device\n                    return normalize_device(buffer_device)\n                except StopIteration:\n                    pass\n\n        return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    @property\n    def dtype(self) -&gt; torch.dtype:\n        if self._dtype is not None:\n            return self._dtype\n        # Try infer from parameters/buffers if available\n        if hasattr(self, \"parameters\") and callable(getattr(self, \"parameters\")):\n            try:\n                param_dtype = next(self.parameters()).dtype\n                return param_dtype\n            except StopIteration:\n                pass\n        if hasattr(self, \"buffers\") and callable(getattr(self, \"buffers\")):\n            try:\n                buffer_dtype = next(self.buffers()).dtype\n                return buffer_dtype\n            except StopIteration:\n                pass\n        return torch.float32\n\n    @dtype.setter\n    def dtype(self, value: torch.dtype):\n        self._dtype = value\n\n    def to(self, *args, **kwargs):\n        \"\"\"Override to() to update internal device tracking.\"\"\"\n        # Call parent's to() if it exists (e.g., nn.Module); otherwise, operate in-place\n        parent_to = getattr(super(), \"to\", None)\n        result = self\n        if callable(parent_to):\n            result = parent_to(*args, **kwargs)\n\n        # Update internal device tracking based on provided args/kwargs\n        target_device = None\n        target_dtype = None\n        if args and isinstance(args[0], (str, torch.device)):\n            target_device = normalize_device(args[0])\n        elif args and isinstance(args[0], torch.dtype):\n            target_dtype = args[0]\n        if \"device\" in kwargs:\n            target_device = normalize_device(kwargs[\"device\"])\n        if \"dtype\" in kwargs and isinstance(kwargs[\"dtype\"], torch.dtype):\n            target_dtype = kwargs[\"dtype\"]\n        if target_device is not None:\n            self._device = target_device\n        if target_dtype is not None:\n            self._dtype = target_dtype\n\n        return result\n\n    @staticmethod\n    def safe_to(obj, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None):\n        \"\"\"\n        Safely moves an object to a device and/or dtype, if it supports the `.to()` method.\n        \"\"\"\n        if not hasattr(obj, \"to\") or not callable(getattr(obj, \"to\")):\n            return obj\n        try:\n            if device is not None or dtype is not None:\n                return obj.to(device=device, dtype=dtype)\n            return obj\n        except TypeError:\n            # Fallbacks for custom signatures\n            if device is not None:\n                try:\n                    return obj.to(device)\n                except Exception:\n                    pass\n            if dtype is not None:\n                try:\n                    return obj.to(dtype)\n                except Exception:\n                    pass\n            return obj\n\n    # Mixed precision helpers\n    def setup_mixed_precision(self, use_mixed_precision: bool) -&gt; None:\n        \"\"\"Configures mixed precision settings.\"\"\"\n        self.use_mixed_precision = bool(use_mixed_precision)\n        if self.use_mixed_precision:\n            try:\n                # Import lazily to avoid hard dependency when not used\n                from torch.cuda.amp import autocast as _autocast  # noqa: F401\n                self.autocast_available = True\n                if not self.device.type.startswith(\"cuda\"):\n                    warnings.warn(\n                        f\"Mixed precision requested but device is {self.device}. Mixed precision requires CUDA. Falling back to full precision.\",\n                        UserWarning,\n                    )\n                    self.use_mixed_precision = False\n                    self.autocast_available = False\n            except ImportError:\n                warnings.warn(\n                    \"Mixed precision requested but torch.cuda.amp not available. Falling back to full precision. Requires PyTorch 1.6+.\",\n                    UserWarning,\n                )\n                self.use_mixed_precision = False\n                self.autocast_available = False\n        else:\n            self.autocast_available = False\n\n    def autocast_context(self):\n        \"\"\"\n        Returns a `torch.cuda.amp.autocast` context manager if mixed precision is enabled,\n        otherwise a `nullcontext`.\n        \"\"\"\n        if getattr(self, \"use_mixed_precision\", False) and getattr(self, \"autocast_available\", False):\n            from torch.cuda.amp import autocast\n            return autocast()\n        return nullcontext()\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin._device","title":"_device  <code>instance-attribute</code>","text":"<pre><code>_device = normalize_device(device)\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin._dtype","title":"_dtype  <code>instance-attribute</code>","text":"<pre><code>_dtype: Optional[dtype] = dtype\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.device","title":"device  <code>property</code>","text":"<pre><code>device: device\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.dtype","title":"dtype  <code>property</code> <code>writable</code>","text":"<pre><code>dtype: dtype\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.to","title":"to","text":"<pre><code>to(*args, **kwargs)\n</code></pre> <p>Override to() to update internal device tracking.</p> Source code in <code>torchebm/core/device_mixin.py</code> <pre><code>def to(self, *args, **kwargs):\n    \"\"\"Override to() to update internal device tracking.\"\"\"\n    # Call parent's to() if it exists (e.g., nn.Module); otherwise, operate in-place\n    parent_to = getattr(super(), \"to\", None)\n    result = self\n    if callable(parent_to):\n        result = parent_to(*args, **kwargs)\n\n    # Update internal device tracking based on provided args/kwargs\n    target_device = None\n    target_dtype = None\n    if args and isinstance(args[0], (str, torch.device)):\n        target_device = normalize_device(args[0])\n    elif args and isinstance(args[0], torch.dtype):\n        target_dtype = args[0]\n    if \"device\" in kwargs:\n        target_device = normalize_device(kwargs[\"device\"])\n    if \"dtype\" in kwargs and isinstance(kwargs[\"dtype\"], torch.dtype):\n        target_dtype = kwargs[\"dtype\"]\n    if target_device is not None:\n        self._device = target_device\n    if target_dtype is not None:\n        self._dtype = target_dtype\n\n    return result\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.safe_to","title":"safe_to  <code>staticmethod</code>","text":"<pre><code>safe_to(obj, device: Optional[device] = None, dtype: Optional[dtype] = None)\n</code></pre> <p>Safely moves an object to a device and/or dtype, if it supports the <code>.to()</code> method.</p> Source code in <code>torchebm/core/device_mixin.py</code> <pre><code>@staticmethod\ndef safe_to(obj, device: Optional[torch.device] = None, dtype: Optional[torch.dtype] = None):\n    \"\"\"\n    Safely moves an object to a device and/or dtype, if it supports the `.to()` method.\n    \"\"\"\n    if not hasattr(obj, \"to\") or not callable(getattr(obj, \"to\")):\n        return obj\n    try:\n        if device is not None or dtype is not None:\n            return obj.to(device=device, dtype=dtype)\n        return obj\n    except TypeError:\n        # Fallbacks for custom signatures\n        if device is not None:\n            try:\n                return obj.to(device)\n            except Exception:\n                pass\n        if dtype is not None:\n            try:\n                return obj.to(dtype)\n            except Exception:\n                pass\n        return obj\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.setup_mixed_precision","title":"setup_mixed_precision","text":"<pre><code>setup_mixed_precision(use_mixed_precision: bool) -&gt; None\n</code></pre> <p>Configures mixed precision settings.</p> Source code in <code>torchebm/core/device_mixin.py</code> <pre><code>def setup_mixed_precision(self, use_mixed_precision: bool) -&gt; None:\n    \"\"\"Configures mixed precision settings.\"\"\"\n    self.use_mixed_precision = bool(use_mixed_precision)\n    if self.use_mixed_precision:\n        try:\n            # Import lazily to avoid hard dependency when not used\n            from torch.cuda.amp import autocast as _autocast  # noqa: F401\n            self.autocast_available = True\n            if not self.device.type.startswith(\"cuda\"):\n                warnings.warn(\n                    f\"Mixed precision requested but device is {self.device}. Mixed precision requires CUDA. Falling back to full precision.\",\n                    UserWarning,\n                )\n                self.use_mixed_precision = False\n                self.autocast_available = False\n        except ImportError:\n            warnings.warn(\n                \"Mixed precision requested but torch.cuda.amp not available. Falling back to full precision. Requires PyTorch 1.6+.\",\n                UserWarning,\n            )\n            self.use_mixed_precision = False\n            self.autocast_available = False\n    else:\n        self.autocast_available = False\n</code></pre>"},{"location":"api/torchebm/core/device_mixin/classes/DeviceMixin/#torchebm.core.device_mixin.DeviceMixin.autocast_context","title":"autocast_context","text":"<pre><code>autocast_context()\n</code></pre> <p>Returns a <code>torch.cuda.amp.autocast</code> context manager if mixed precision is enabled, otherwise a <code>nullcontext</code>.</p> Source code in <code>torchebm/core/device_mixin.py</code> <pre><code>def autocast_context(self):\n    \"\"\"\n    Returns a `torch.cuda.amp.autocast` context manager if mixed precision is enabled,\n    otherwise a `nullcontext`.\n    \"\"\"\n    if getattr(self, \"use_mixed_precision\", False) and getattr(self, \"autocast_available\", False):\n        from torch.cuda.amp import autocast\n        return autocast()\n    return nullcontext()\n</code></pre>"},{"location":"api/torchebm/cuda/","title":"Cuda","text":""},{"location":"api/torchebm/cuda/#torchebm-cuda","title":"Torchebm &gt; Cuda","text":""},{"location":"api/torchebm/cuda/#contents","title":"Contents","text":""},{"location":"api/torchebm/cuda/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/cuda/#torchebm.cuda","title":"torchebm.cuda","text":"<p>CUDA-accelerated implementations of key operations for improved performance.</p>"},{"location":"api/torchebm/datasets/","title":"Torchebm &gt; Datasets","text":""},{"location":"api/torchebm/datasets/#torchebm-datasets","title":"Torchebm &gt; Datasets","text":""},{"location":"api/torchebm/datasets/#contents","title":"Contents","text":""},{"location":"api/torchebm/datasets/#modules","title":"Modules","text":"<ul> <li>Generators</li> </ul>"},{"location":"api/torchebm/datasets/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/datasets/#torchebm.datasets","title":"torchebm.datasets","text":""},{"location":"api/torchebm/datasets/generators/","title":"Torchebm &gt; Datasets &gt; Generators","text":""},{"location":"api/torchebm/datasets/generators/#torchebm-datasets-generators","title":"Torchebm &gt; Datasets &gt; Generators","text":""},{"location":"api/torchebm/datasets/generators/#contents","title":"Contents","text":""},{"location":"api/torchebm/datasets/generators/#classes","title":"Classes","text":"<ul> <li><code>BaseSyntheticDataset</code> - Abstract base class for generating 2D synthetic datasets.</li> <li><code>CheckerboardDataset</code> - Generates points in a 2D checkerboard pattern using rejection sampling.</li> <li><code>CircleDataset</code> - Generates points sampled uniformly on a circle with noise.</li> <li><code>EightGaussiansDataset</code> - Generates samples from the '8 Gaussians' mixture distribution.</li> <li><code>GaussianMixtureDataset</code> - Generates a 2D Gaussian mixture dataset with components arranged in a circle.</li> <li><code>GridDataset</code> - Generates points on a 2D grid.</li> <li><code>PinwheelDataset</code> - Generates the pinwheel dataset with curved blades.</li> <li><code>SwissRollDataset</code> - Generates a 2D Swiss roll dataset.</li> <li><code>TwoMoonsDataset</code> - Generates the 'two moons' dataset.</li> </ul>"},{"location":"api/torchebm/datasets/generators/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/datasets/generators/#torchebm.datasets.generators","title":"torchebm.datasets.generators","text":"<p>Dataset Generators Module.</p>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/","title":"BaseSyntheticDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Dataset</code>, <code>ABC</code></p> <p>Abstract base class for generating 2D synthetic datasets.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The total number of samples to generate.</p> required <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device to place the tensor on.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the output tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class BaseSyntheticDataset(Dataset, ABC):\n    \"\"\"\n    Abstract base class for generating 2D synthetic datasets.\n\n    Args:\n        n_samples (int): The total number of samples to generate.\n        device (Optional[Union[str, torch.device]]): The device to place the tensor on.\n        dtype (torch.dtype): The data type for the output tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        if n_samples &lt;= 0:\n            raise ValueError(\"n_samples must be positive\")\n\n        self.n_samples = n_samples\n        self.device = device\n        self.dtype = dtype\n        self.seed = seed\n        self.data: Optional[torch.Tensor] = None  # Data will be stored here\n        self._generate()  # Generate data upon initialization\n\n    def _seed_generators(self):\n        \"\"\"Sets the random seeds for numpy and torch if a seed is provided.\"\"\"\n        if self.seed is not None:\n            np.random.seed(self.seed)\n            torch.manual_seed(self.seed)\n            # If using CUDA, also seed the CUDA generator\n            if torch.cuda.is_available() and (\n                isinstance(self.device, torch.device)\n                and self.device.type == \"cuda\"\n                or self.device == \"cuda\"\n            ):\n                torch.cuda.manual_seed_all(self.seed)  # Seed all GPUs\n\n    @abstractmethod\n    def _generate_data(self) -&gt; torch.Tensor:\n        \"\"\"\n        Core data generation logic to be implemented by subclasses.\n        \"\"\"\n        pass\n\n    def _generate(self):\n        \"\"\"Internal method to handle seeding and call the generation logic.\"\"\"\n        self._seed_generators()\n        # Generate data using the subclass implementation\n        generated_output = self._generate_data()\n\n        # Ensure it's a tensor and on the correct device/dtype\n        if isinstance(generated_output, np.ndarray):\n            self.data = _to_tensor(\n                generated_output, dtype=self.dtype, device=self.device\n            )\n        elif isinstance(generated_output, torch.Tensor):\n            self.data = generated_output.to(dtype=self.dtype, device=self.device)\n        else:\n            raise TypeError(\n                f\"_generate_data must return a NumPy array or PyTorch Tensor, got {type(generated_output)}\"\n            )\n\n        # Verify batch_shape\n        if self.data.shape[0] != self.n_samples:\n            warnings.warn(\n                f\"Generated data has {self.data.shape[0]} samples, but {self.n_samples} were requested. Check generation logic.\",\n                RuntimeWarning,\n            )\n            # Optional: adjust self.n_samples or raise error depending on desired strictness\n            # self.n_samples = self.data.batch_shape[0]\n\n    def regenerate(self, seed: Optional[int] = None):\n        \"\"\"\n        Re-generates the dataset, optionally with a new seed.\n\n        Args:\n            seed (Optional[int]): A new random seed. If `None`, the original seed is used.\n        \"\"\"\n        if seed is not None:\n            self.seed = seed  # Update the seed if a new one is provided\n        self._generate()\n\n    def get_data(self) -&gt; torch.Tensor:\n        \"\"\"\n        Returns the entire generated dataset as a single tensor.\n        \"\"\"\n        if self.data is None:\n            # Should not happen if _generate() is called in __init__\n            self._generate()\n        return self.data\n\n    def __len__(self) -&gt; int:\n        \"\"\"Returns the number of samples in the dataset.\"\"\"\n        return self.n_samples\n\n    def __getitem__(self, idx: int) -&gt; torch.Tensor:\n        \"\"\"\n        Returns the sample at the specified index.\n        \"\"\"\n        if self.data is None:\n            self._generate()  # Ensure data exists\n\n        if not 0 &lt;= idx &lt; self.n_samples:\n            raise IndexError(\n                f\"Index {idx} out of bounds for dataset with size {self.n_samples}\"\n            )\n        return self.data[idx]\n\n    def __repr__(self) -&gt; str:\n        \"\"\"String representation of the dataset object.\"\"\"\n        params = [f\"n_samples={self.n_samples}\"]\n        # Add specific params from subclasses if desired, e.g. by inspecting self.__dict__\n        # Or define __repr__ in subclasses\n        return f\"{self.__class__.__name__}({', '.join(params)}, device={self.device}, dtype={self.dtype})\"\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.n_samples","title":"n_samples  <code>instance-attribute</code>","text":"<pre><code>n_samples = n_samples\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.device","title":"device  <code>instance-attribute</code>","text":"<pre><code>device = device\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.dtype","title":"dtype  <code>instance-attribute</code>","text":"<pre><code>dtype = dtype\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.seed","title":"seed  <code>instance-attribute</code>","text":"<pre><code>seed = seed\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.data","title":"data  <code>instance-attribute</code>","text":"<pre><code>data: Optional[Tensor] = None\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset._seed_generators","title":"_seed_generators","text":"<pre><code>_seed_generators()\n</code></pre> <p>Sets the random seeds for numpy and torch if a seed is provided.</p> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _seed_generators(self):\n    \"\"\"Sets the random seeds for numpy and torch if a seed is provided.\"\"\"\n    if self.seed is not None:\n        np.random.seed(self.seed)\n        torch.manual_seed(self.seed)\n        # If using CUDA, also seed the CUDA generator\n        if torch.cuda.is_available() and (\n            isinstance(self.device, torch.device)\n            and self.device.type == \"cuda\"\n            or self.device == \"cuda\"\n        ):\n            torch.cuda.manual_seed_all(self.seed)  # Seed all GPUs\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset._generate_data","title":"_generate_data  <code>abstractmethod</code>","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> <p>Core data generation logic to be implemented by subclasses.</p> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>@abstractmethod\ndef _generate_data(self) -&gt; torch.Tensor:\n    \"\"\"\n    Core data generation logic to be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset._generate","title":"_generate","text":"<pre><code>_generate()\n</code></pre> <p>Internal method to handle seeding and call the generation logic.</p> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate(self):\n    \"\"\"Internal method to handle seeding and call the generation logic.\"\"\"\n    self._seed_generators()\n    # Generate data using the subclass implementation\n    generated_output = self._generate_data()\n\n    # Ensure it's a tensor and on the correct device/dtype\n    if isinstance(generated_output, np.ndarray):\n        self.data = _to_tensor(\n            generated_output, dtype=self.dtype, device=self.device\n        )\n    elif isinstance(generated_output, torch.Tensor):\n        self.data = generated_output.to(dtype=self.dtype, device=self.device)\n    else:\n        raise TypeError(\n            f\"_generate_data must return a NumPy array or PyTorch Tensor, got {type(generated_output)}\"\n        )\n\n    # Verify batch_shape\n    if self.data.shape[0] != self.n_samples:\n        warnings.warn(\n            f\"Generated data has {self.data.shape[0]} samples, but {self.n_samples} were requested. Check generation logic.\",\n            RuntimeWarning,\n        )\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.regenerate","title":"regenerate","text":"<pre><code>regenerate(seed: Optional[int] = None)\n</code></pre> <p>Re-generates the dataset, optionally with a new seed.</p> <p>Parameters:</p> Name Type Description Default <code>seed</code> <code>Optional[int]</code> <p>A new random seed. If <code>None</code>, the original seed is used.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def regenerate(self, seed: Optional[int] = None):\n    \"\"\"\n    Re-generates the dataset, optionally with a new seed.\n\n    Args:\n        seed (Optional[int]): A new random seed. If `None`, the original seed is used.\n    \"\"\"\n    if seed is not None:\n        self.seed = seed  # Update the seed if a new one is provided\n    self._generate()\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/BaseSyntheticDataset/#torchebm.datasets.generators.BaseSyntheticDataset.get_data","title":"get_data","text":"<pre><code>get_data() -&gt; torch.Tensor\n</code></pre> <p>Returns the entire generated dataset as a single tensor.</p> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def get_data(self) -&gt; torch.Tensor:\n    \"\"\"\n    Returns the entire generated dataset as a single tensor.\n    \"\"\"\n    if self.data is None:\n        # Should not happen if _generate() is called in __init__\n        self._generate()\n    return self.data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CheckerboardDataset/","title":"CheckerboardDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/CheckerboardDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates points in a 2D checkerboard pattern using rejection sampling.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The target number of samples.</p> <code>2000</code> <code>range_limit</code> <code>float</code> <p>Defines the square region <code>[-lim, lim] x [-lim, lim]</code>.</p> <code>4.0</code> <code>noise</code> <code>float</code> <p>Small Gaussian noise added to the points.</p> <code>0.01</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class CheckerboardDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates points in a 2D checkerboard pattern using rejection sampling.\n\n    Args:\n        n_samples (int): The target number of samples.\n        range_limit (float): Defines the square region `[-lim, lim] x [-lim, lim]`.\n        noise (float): Small Gaussian noise added to the points.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        range_limit: float = 4.0,\n        noise: float = 0.01,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        self.range_limit = range_limit\n        self.noise = noise\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Logic from make_checkerboard\n        collected_samples = []\n        target = self.n_samples\n        # Estimate batch size needed (density is ~0.5)\n        batch_size = max(1000, int(target * 2.5))  # Generate more than needed per batch\n\n        while len(collected_samples) &lt; target:\n            x = np.random.uniform(-self.range_limit, self.range_limit, size=batch_size)\n            y = np.random.uniform(-self.range_limit, self.range_limit, size=batch_size)\n\n            keep = (np.floor(x) + np.floor(y)) % 2 != 0\n            valid_points = np.vstack((x[keep], y[keep])).T.astype(np.float32)\n\n            needed = target - len(collected_samples)\n            collected_samples.extend(valid_points[:needed])  # Add only needed points\n\n        X = np.array(\n            collected_samples[:target], dtype=np.float32\n        )  # Ensure exact n_samples\n        tensor_data = torch.from_numpy(X)\n        tensor_data += torch.randn_like(tensor_data) * self.noise\n\n        return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CheckerboardDataset/#torchebm.datasets.generators.CheckerboardDataset.range_limit","title":"range_limit  <code>instance-attribute</code>","text":"<pre><code>range_limit = range_limit\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CheckerboardDataset/#torchebm.datasets.generators.CheckerboardDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CheckerboardDataset/#torchebm.datasets.generators.CheckerboardDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Logic from make_checkerboard\n    collected_samples = []\n    target = self.n_samples\n    # Estimate batch size needed (density is ~0.5)\n    batch_size = max(1000, int(target * 2.5))  # Generate more than needed per batch\n\n    while len(collected_samples) &lt; target:\n        x = np.random.uniform(-self.range_limit, self.range_limit, size=batch_size)\n        y = np.random.uniform(-self.range_limit, self.range_limit, size=batch_size)\n\n        keep = (np.floor(x) + np.floor(y)) % 2 != 0\n        valid_points = np.vstack((x[keep], y[keep])).T.astype(np.float32)\n\n        needed = target - len(collected_samples)\n        collected_samples.extend(valid_points[:needed])  # Add only needed points\n\n    X = np.array(\n        collected_samples[:target], dtype=np.float32\n    )  # Ensure exact n_samples\n    tensor_data = torch.from_numpy(X)\n    tensor_data += torch.randn_like(tensor_data) * self.noise\n\n    return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CircleDataset/","title":"CircleDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/CircleDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates points sampled uniformly on a circle with noise.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The number of samples.</p> <code>2000</code> <code>noise</code> <code>float</code> <p>The standard deviation of the Gaussian noise to add.</p> <code>0.05</code> <code>radius</code> <code>float</code> <p>The radius of the circle.</p> <code>1.0</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class CircleDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates points sampled uniformly on a circle with noise.\n\n    Args:\n        n_samples (int): The number of samples.\n        noise (float): The standard deviation of the Gaussian noise to add.\n        radius (float): The radius of the circle.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        noise: float = 0.05,\n        radius: float = 1.0,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        self.noise = noise\n        self.radius = radius\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Logic from make_circle\n        angles = 2 * np.pi * np.random.rand(self.n_samples)\n        x = self.radius * np.cos(angles)\n        y = self.radius * np.sin(angles)\n        X = np.vstack((x, y)).T.astype(np.float32)\n\n        tensor_data = torch.from_numpy(X)\n        tensor_data += torch.randn_like(tensor_data) * self.noise\n\n        return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CircleDataset/#torchebm.datasets.generators.CircleDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CircleDataset/#torchebm.datasets.generators.CircleDataset.radius","title":"radius  <code>instance-attribute</code>","text":"<pre><code>radius = radius\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/CircleDataset/#torchebm.datasets.generators.CircleDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Logic from make_circle\n    angles = 2 * np.pi * np.random.rand(self.n_samples)\n    x = self.radius * np.cos(angles)\n    y = self.radius * np.sin(angles)\n    X = np.vstack((x, y)).T.astype(np.float32)\n\n    tensor_data = torch.from_numpy(X)\n    tensor_data += torch.randn_like(tensor_data) * self.noise\n\n    return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/","title":"EightGaussiansDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates samples from the '8 Gaussians' mixture distribution.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The total number of samples.</p> <code>2000</code> <code>std</code> <code>float</code> <p>The standard deviation of each component.</p> <code>0.02</code> <code>scale</code> <code>float</code> <p>A scaling factor for the centers of the Gaussians.</p> <code>2.0</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class EightGaussiansDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates samples from the '8 Gaussians' mixture distribution.\n\n    Args:\n        n_samples (int): The total number of samples.\n        std (float): The standard deviation of each component.\n        scale (float): A scaling factor for the centers of the Gaussians.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        std: float = 0.02,\n        scale: float = 2.0,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        self.std = std\n        self.scale = scale\n        # Define the specific 8 centers\n        centers_np = (\n            np.array(\n                [\n                    (1, 0),\n                    (-1, 0),\n                    (0, 1),\n                    (0, -1),\n                    (1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n                    (1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n                    (-1.0 / np.sqrt(2), 1.0 / np.sqrt(2)),\n                    (-1.0 / np.sqrt(2), -1.0 / np.sqrt(2)),\n                ],\n                dtype=np.float32,\n            )\n            * self.scale\n        )\n        self.centers_torch = torch.from_numpy(centers_np)\n        self.n_components = 8\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Similar logic to GaussianMixtureDataset but with fixed centers\n        centers_dev = self.centers_torch.to(device=self.device, dtype=self.dtype)\n\n        data = torch.empty(self.n_samples, 2, device=self.device, dtype=self.dtype)\n        samples_per_component = self.n_samples // self.n_components\n        remainder = self.n_samples % self.n_components\n\n        current_idx = 0\n        for i in range(self.n_components):\n            num = samples_per_component + (1 if i &lt; remainder else 0)\n            if num == 0:\n                continue\n            end_idx = current_idx + num\n            noise = torch.randn(num, 2, device=self.device, dtype=self.dtype) * self.std\n            data[current_idx:end_idx] = centers_dev[i] + noise\n            current_idx = end_idx\n\n        data = data[torch.randperm(self.n_samples, device=self.device)]\n        return data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#torchebm.datasets.generators.EightGaussiansDataset.std","title":"std  <code>instance-attribute</code>","text":"<pre><code>std = std\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#torchebm.datasets.generators.EightGaussiansDataset.scale","title":"scale  <code>instance-attribute</code>","text":"<pre><code>scale = scale\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#torchebm.datasets.generators.EightGaussiansDataset.centers_torch","title":"centers_torch  <code>instance-attribute</code>","text":"<pre><code>centers_torch = from_numpy(centers_np)\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#torchebm.datasets.generators.EightGaussiansDataset.n_components","title":"n_components  <code>instance-attribute</code>","text":"<pre><code>n_components = 8\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/EightGaussiansDataset/#torchebm.datasets.generators.EightGaussiansDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Similar logic to GaussianMixtureDataset but with fixed centers\n    centers_dev = self.centers_torch.to(device=self.device, dtype=self.dtype)\n\n    data = torch.empty(self.n_samples, 2, device=self.device, dtype=self.dtype)\n    samples_per_component = self.n_samples // self.n_components\n    remainder = self.n_samples % self.n_components\n\n    current_idx = 0\n    for i in range(self.n_components):\n        num = samples_per_component + (1 if i &lt; remainder else 0)\n        if num == 0:\n            continue\n        end_idx = current_idx + num\n        noise = torch.randn(num, 2, device=self.device, dtype=self.dtype) * self.std\n        data[current_idx:end_idx] = centers_dev[i] + noise\n        current_idx = end_idx\n\n    data = data[torch.randperm(self.n_samples, device=self.device)]\n    return data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/","title":"GaussianMixtureDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates a 2D Gaussian mixture dataset with components arranged in a circle.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The total number of samples.</p> <code>2000</code> <code>n_components</code> <code>int</code> <p>The number of Gaussian components (modes).</p> <code>8</code> <code>std</code> <code>float</code> <p>The standard deviation of each Gaussian component.</p> <code>0.05</code> <code>radius</code> <code>float</code> <p>The radius of the circle on which the centers lie.</p> <code>1.0</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class GaussianMixtureDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates a 2D Gaussian mixture dataset with components arranged in a circle.\n\n    Args:\n        n_samples (int): The total number of samples.\n        n_components (int): The number of Gaussian components (modes).\n        std (float): The standard deviation of each Gaussian component.\n        radius (float): The radius of the circle on which the centers lie.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        n_components: int = 8,\n        std: float = 0.05,\n        radius: float = 1.0,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        if n_components &lt;= 0:\n            raise ValueError(\"n_components must be positive\")\n        if std &lt; 0:\n            raise ValueError(\"std must be non-negative\")\n        self.n_components = n_components\n        self.std = std\n        self.radius = radius\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Logic from make_gaussian_mixture\n        thetas = np.linspace(0, 2 * np.pi, self.n_components, endpoint=False)\n        centers = np.array(\n            [(self.radius * np.cos(t), self.radius * np.sin(t)) for t in thetas],\n            dtype=np.float32,\n        )\n        # Use torch directly for efficiency and device handling\n        centers_torch = torch.from_numpy(centers)  # Keep on CPU for indexing efficiency\n\n        data = torch.empty(self.n_samples, 2, device=self.device, dtype=self.dtype)\n        samples_per_component = self.n_samples // self.n_components\n        remainder = self.n_samples % self.n_components\n\n        current_idx = 0\n        for i in range(self.n_components):\n            num = samples_per_component + (1 if i &lt; remainder else 0)\n            if num == 0:\n                continue\n            end_idx = current_idx + num\n            # Generate noise directly on target device if possible\n            noise = torch.randn(num, 2, device=self.device, dtype=self.dtype) * self.std\n            component_center = centers_torch[i].to(device=self.device, dtype=self.dtype)\n            data[current_idx:end_idx] = component_center + noise\n            current_idx = end_idx\n\n        # Shuffle the data to mix components\n        data = data[\n            torch.randperm(self.n_samples, device=self.device)\n        ]  # Use device-aware permutation\n        return data  # Return tensor directly\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/#torchebm.datasets.generators.GaussianMixtureDataset.n_components","title":"n_components  <code>instance-attribute</code>","text":"<pre><code>n_components = n_components\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/#torchebm.datasets.generators.GaussianMixtureDataset.std","title":"std  <code>instance-attribute</code>","text":"<pre><code>std = std\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/#torchebm.datasets.generators.GaussianMixtureDataset.radius","title":"radius  <code>instance-attribute</code>","text":"<pre><code>radius = radius\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GaussianMixtureDataset/#torchebm.datasets.generators.GaussianMixtureDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Logic from make_gaussian_mixture\n    thetas = np.linspace(0, 2 * np.pi, self.n_components, endpoint=False)\n    centers = np.array(\n        [(self.radius * np.cos(t), self.radius * np.sin(t)) for t in thetas],\n        dtype=np.float32,\n    )\n    # Use torch directly for efficiency and device handling\n    centers_torch = torch.from_numpy(centers)  # Keep on CPU for indexing efficiency\n\n    data = torch.empty(self.n_samples, 2, device=self.device, dtype=self.dtype)\n    samples_per_component = self.n_samples // self.n_components\n    remainder = self.n_samples % self.n_components\n\n    current_idx = 0\n    for i in range(self.n_components):\n        num = samples_per_component + (1 if i &lt; remainder else 0)\n        if num == 0:\n            continue\n        end_idx = current_idx + num\n        # Generate noise directly on target device if possible\n        noise = torch.randn(num, 2, device=self.device, dtype=self.dtype) * self.std\n        component_center = centers_torch[i].to(device=self.device, dtype=self.dtype)\n        data[current_idx:end_idx] = component_center + noise\n        current_idx = end_idx\n\n    # Shuffle the data to mix components\n    data = data[\n        torch.randperm(self.n_samples, device=self.device)\n    ]  # Use device-aware permutation\n    return data  # Return tensor directly\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GridDataset/","title":"GridDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/GridDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates points on a 2D grid.</p> <p>Note: The total number of samples will be <code>n_samples_per_dim</code> ** 2.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples_per_dim</code> <code>int</code> <p>The number of points along each dimension.</p> <code>10</code> <code>range_limit</code> <code>float</code> <p>Defines the square region <code>[-lim, lim] x [-lim, lim]</code>.</p> <code>1.0</code> <code>noise</code> <code>float</code> <p>The standard deviation of the Gaussian noise to add.</p> <code>0.01</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility (primarily affects noise).</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class GridDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates points on a 2D grid.\n\n    Note: The total number of samples will be `n_samples_per_dim` ** 2.\n\n    Args:\n        n_samples_per_dim (int): The number of points along each dimension.\n        range_limit (float): Defines the square region `[-lim, lim] x [-lim, lim]`.\n        noise (float): The standard deviation of the Gaussian noise to add.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility (primarily affects noise).\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples_per_dim: int = 10,\n        range_limit: float = 1.0,\n        noise: float = 0.01,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,  # Seed mainly affects noise here\n    ):\n        if n_samples_per_dim &lt;= 0:\n            raise ValueError(\"n_samples_per_dim must be positive\")\n        self.n_samples_per_dim = n_samples_per_dim\n        self.range_limit = range_limit\n        self.noise = noise\n        # Override n_samples for the base class\n        total_samples = n_samples_per_dim * n_samples_per_dim\n        super().__init__(n_samples=total_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Create a more uniform grid spacing\n        x_coords = torch.linspace(\n            -self.range_limit, self.range_limit, self.n_samples_per_dim\n        )\n        y_coords = torch.linspace(\n            -self.range_limit, self.range_limit, self.n_samples_per_dim\n        )\n\n        # Create the grid points\n        grid_x, grid_y = torch.meshgrid(x_coords, y_coords, indexing=\"ij\")\n\n        # Stack the coordinates to form the 2D points\n        points = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=1)\n\n        # Apply noise if specified\n        if self.noise &gt; 0:\n            # Set the random seed if provided\n            if hasattr(self, \"rng\"):\n                # Use the RNG from the base class\n                noise = torch.tensor(\n                    self.rng.normal(0, self.noise, size=points.shape),\n                    dtype=points.dtype,\n                    device=points.device,\n                )\n            else:\n                # Fall back to torch's random generator\n                noise = torch.randn_like(points) * self.noise\n\n            points = points + noise\n\n        return points\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GridDataset/#torchebm.datasets.generators.GridDataset.n_samples_per_dim","title":"n_samples_per_dim  <code>instance-attribute</code>","text":"<pre><code>n_samples_per_dim = n_samples_per_dim\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GridDataset/#torchebm.datasets.generators.GridDataset.range_limit","title":"range_limit  <code>instance-attribute</code>","text":"<pre><code>range_limit = range_limit\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GridDataset/#torchebm.datasets.generators.GridDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/GridDataset/#torchebm.datasets.generators.GridDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Create a more uniform grid spacing\n    x_coords = torch.linspace(\n        -self.range_limit, self.range_limit, self.n_samples_per_dim\n    )\n    y_coords = torch.linspace(\n        -self.range_limit, self.range_limit, self.n_samples_per_dim\n    )\n\n    # Create the grid points\n    grid_x, grid_y = torch.meshgrid(x_coords, y_coords, indexing=\"ij\")\n\n    # Stack the coordinates to form the 2D points\n    points = torch.stack([grid_x.flatten(), grid_y.flatten()], dim=1)\n\n    # Apply noise if specified\n    if self.noise &gt; 0:\n        # Set the random seed if provided\n        if hasattr(self, \"rng\"):\n            # Use the RNG from the base class\n            noise = torch.tensor(\n                self.rng.normal(0, self.noise, size=points.shape),\n                dtype=points.dtype,\n                device=points.device,\n            )\n        else:\n            # Fall back to torch's random generator\n            noise = torch.randn_like(points) * self.noise\n\n        points = points + noise\n\n    return points\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/","title":"PinwheelDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates the pinwheel dataset with curved blades.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The total number of samples.</p> <code>2000</code> <code>n_classes</code> <code>int</code> <p>The number of 'blades' in the pinwheel.</p> <code>5</code> <code>noise</code> <code>float</code> <p>The standard deviation of the final additive Cartesian noise.</p> <code>0.05</code> <code>radial_scale</code> <code>float</code> <p>Controls the maximum radius/length of the blades.</p> <code>2.0</code> <code>angular_scale</code> <code>float</code> <p>Controls the standard deviation of the angle noise (thickness).</p> <code>0.1</code> <code>spiral_scale</code> <code>float</code> <p>Controls the tightness of the spiral.</p> <code>5.0</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class PinwheelDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates the pinwheel dataset with curved blades.\n\n    Args:\n        n_samples (int): The total number of samples.\n        n_classes (int): The number of 'blades' in the pinwheel.\n        noise (float): The standard deviation of the final additive Cartesian noise.\n        radial_scale (float): Controls the maximum radius/length of the blades.\n        angular_scale (float): Controls the standard deviation of the angle noise (thickness).\n        spiral_scale (float): Controls the tightness of the spiral.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        n_classes: int = 5,\n        noise: float = 0.05,\n        radial_scale: float = 2.0,\n        angular_scale: float = 0.1,\n        spiral_scale: float = 5.0,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        if n_classes &lt;= 0:\n            raise ValueError(\"n_classes must be positive\")\n        self.n_classes = n_classes\n        self.noise = noise\n        self.radial_scale = radial_scale\n        self.angular_scale = angular_scale\n        self.spiral_scale = spiral_scale\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Logic from make_pinwheel\n        all_points_np = []\n        samples_per_class = self.n_samples // self.n_classes\n        remainder = self.n_samples % self.n_classes\n\n        for class_idx in range(self.n_classes):\n            n_class_samples = samples_per_class + (1 if class_idx &lt; remainder else 0)\n            if n_class_samples == 0:\n                continue\n\n            t = np.sqrt(np.random.rand(n_class_samples))  # Radial density control\n            radii = t * self.radial_scale\n            base_angle = class_idx * (2 * np.pi / self.n_classes)\n            spiral_angle = self.spiral_scale * t\n            angle_noise = np.random.randn(n_class_samples) * self.angular_scale\n            thetas = base_angle + spiral_angle + angle_noise\n\n            x = radii * np.cos(thetas)\n            y = radii * np.sin(thetas)\n            all_points_np.append(np.stack([x, y], axis=1))\n\n        data_np = np.concatenate(all_points_np, axis=0).astype(np.float32)\n        np.random.shuffle(data_np)  # Shuffle before converting to tensor\n\n        tensor_data = torch.from_numpy(data_np)\n\n        if self.noise &gt; 0:\n            tensor_data += torch.randn_like(tensor_data) * self.noise\n\n        return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset.n_classes","title":"n_classes  <code>instance-attribute</code>","text":"<pre><code>n_classes = n_classes\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset.radial_scale","title":"radial_scale  <code>instance-attribute</code>","text":"<pre><code>radial_scale = radial_scale\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset.angular_scale","title":"angular_scale  <code>instance-attribute</code>","text":"<pre><code>angular_scale = angular_scale\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset.spiral_scale","title":"spiral_scale  <code>instance-attribute</code>","text":"<pre><code>spiral_scale = spiral_scale\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/PinwheelDataset/#torchebm.datasets.generators.PinwheelDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Logic from make_pinwheel\n    all_points_np = []\n    samples_per_class = self.n_samples // self.n_classes\n    remainder = self.n_samples % self.n_classes\n\n    for class_idx in range(self.n_classes):\n        n_class_samples = samples_per_class + (1 if class_idx &lt; remainder else 0)\n        if n_class_samples == 0:\n            continue\n\n        t = np.sqrt(np.random.rand(n_class_samples))  # Radial density control\n        radii = t * self.radial_scale\n        base_angle = class_idx * (2 * np.pi / self.n_classes)\n        spiral_angle = self.spiral_scale * t\n        angle_noise = np.random.randn(n_class_samples) * self.angular_scale\n        thetas = base_angle + spiral_angle + angle_noise\n\n        x = radii * np.cos(thetas)\n        y = radii * np.sin(thetas)\n        all_points_np.append(np.stack([x, y], axis=1))\n\n    data_np = np.concatenate(all_points_np, axis=0).astype(np.float32)\n    np.random.shuffle(data_np)  # Shuffle before converting to tensor\n\n    tensor_data = torch.from_numpy(data_np)\n\n    if self.noise &gt; 0:\n        tensor_data += torch.randn_like(tensor_data) * self.noise\n\n    return tensor_data\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/SwissRollDataset/","title":"SwissRollDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/SwissRollDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates a 2D Swiss roll dataset.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The number of samples.</p> <code>2000</code> <code>noise</code> <code>float</code> <p>The standard deviation of the Gaussian noise to add.</p> <code>0.05</code> <code>arclength</code> <code>float</code> <p>A factor controlling how many rolls the spiral has.</p> <code>3.0</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class SwissRollDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates a 2D Swiss roll dataset.\n\n    Args:\n        n_samples (int): The number of samples.\n        noise (float): The standard deviation of the Gaussian noise to add.\n        arclength (float): A factor controlling how many rolls the spiral has.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        noise: float = 0.05,\n        arclength: float = 3.0,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        self.noise = noise\n        self.arclength = arclength\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; torch.Tensor:\n        # Logic from make_swiss_roll\n        t = self.arclength * np.pi * (1 + 2 * np.random.rand(self.n_samples))\n        x = t * np.cos(t)\n        y = t * np.sin(t)\n        X = np.vstack((x, y)).T.astype(np.float32)\n\n        tensor_data = torch.from_numpy(X)  # CPU tensor initially\n        tensor_data += torch.randn_like(tensor_data) * self.noise\n\n        # Center and scale slightly (optional, can be done outside)\n        tensor_data = (tensor_data - tensor_data.mean(dim=0)) / (\n            tensor_data.std(dim=0).mean()\n            * 2.0  # Be careful with division by zero if std is ~0\n        )\n\n        return tensor_data  # Return tensor, base class handles device/dtype\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/SwissRollDataset/#torchebm.datasets.generators.SwissRollDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/SwissRollDataset/#torchebm.datasets.generators.SwissRollDataset.arclength","title":"arclength  <code>instance-attribute</code>","text":"<pre><code>arclength = arclength\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/SwissRollDataset/#torchebm.datasets.generators.SwissRollDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; torch.Tensor:\n    # Logic from make_swiss_roll\n    t = self.arclength * np.pi * (1 + 2 * np.random.rand(self.n_samples))\n    x = t * np.cos(t)\n    y = t * np.sin(t)\n    X = np.vstack((x, y)).T.astype(np.float32)\n\n    tensor_data = torch.from_numpy(X)  # CPU tensor initially\n    tensor_data += torch.randn_like(tensor_data) * self.noise\n\n    # Center and scale slightly (optional, can be done outside)\n    tensor_data = (tensor_data - tensor_data.mean(dim=0)) / (\n        tensor_data.std(dim=0).mean()\n        * 2.0  # Be careful with division by zero if std is ~0\n    )\n\n    return tensor_data  # Return tensor, base class handles device/dtype\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/TwoMoonsDataset/","title":"TwoMoonsDataset","text":""},{"location":"api/torchebm/datasets/generators/classes/TwoMoonsDataset/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSyntheticDataset</code></p> <p>Generates the 'two moons' dataset.</p> <p>Parameters:</p> Name Type Description Default <code>n_samples</code> <code>int</code> <p>The total number of samples.</p> <code>2000</code> <code>noise</code> <code>float</code> <p>The standard deviation of the Gaussian noise to add.</p> <code>0.05</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>The device for the tensor.</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>The data type for the tensor.</p> <code>float32</code> <code>seed</code> <code>Optional[int]</code> <p>A random seed for reproducibility.</p> <code>None</code> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>class TwoMoonsDataset(BaseSyntheticDataset):\n    \"\"\"\n    Generates the 'two moons' dataset.\n\n    Args:\n        n_samples (int): The total number of samples.\n        noise (float): The standard deviation of the Gaussian noise to add.\n        device (Optional[Union[str, torch.device]]): The device for the tensor.\n        dtype (torch.dtype): The data type for the tensor.\n        seed (Optional[int]): A random seed for reproducibility.\n    \"\"\"\n\n    def __init__(\n        self,\n        n_samples: int = 2000,\n        noise: float = 0.05,\n        device: Optional[Union[str, torch.device]] = None,\n        dtype: torch.dtype = torch.float32,\n        seed: Optional[int] = None,\n    ):\n        self.noise = noise\n        super().__init__(n_samples=n_samples, device=device, dtype=dtype, seed=seed)\n\n    def _generate_data(self) -&gt; np.ndarray:\n        # Logic from make_two_moons (using numpy initially is fine here)\n        n_samples_out = self.n_samples // 2\n        n_samples_in = self.n_samples - n_samples_out\n\n        outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n        outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n        inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n        inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n\n        X = np.vstack(\n            [\n                np.append(outer_circ_x, inner_circ_x),\n                np.append(outer_circ_y, inner_circ_y),\n            ]\n        ).T.astype(np.float32)\n\n        # Add noise using torch AFTER converting base batch_shape to tensor\n        tensor_data = torch.from_numpy(X)  # Keep on CPU initially for noise addition\n        noise_val = torch.randn_like(tensor_data) * self.noise\n        tensor_data += noise_val\n\n        # Base class __init__ will handle final _to_tensor conversion for device/dtype\n        # Alternatively, add noise directly on the target device:\n        # tensor_data = torch.from_numpy(X).to(device=self.device, dtype=self.dtype)\n        # tensor_data += torch.randn_like(tensor_data) * self.noise\n        # return tensor_data # Return tensor directly if handled here\n\n        return tensor_data  # Return tensor, base class handles device/dtype\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/TwoMoonsDataset/#torchebm.datasets.generators.TwoMoonsDataset.noise","title":"noise  <code>instance-attribute</code>","text":"<pre><code>noise = noise\n</code></pre>"},{"location":"api/torchebm/datasets/generators/classes/TwoMoonsDataset/#torchebm.datasets.generators.TwoMoonsDataset._generate_data","title":"_generate_data","text":"<pre><code>_generate_data() -&gt; np.ndarray\n</code></pre> Source code in <code>torchebm/datasets/generators.py</code> <pre><code>def _generate_data(self) -&gt; np.ndarray:\n    # Logic from make_two_moons (using numpy initially is fine here)\n    n_samples_out = self.n_samples // 2\n    n_samples_in = self.n_samples - n_samples_out\n\n    outer_circ_x = np.cos(np.linspace(0, np.pi, n_samples_out))\n    outer_circ_y = np.sin(np.linspace(0, np.pi, n_samples_out))\n    inner_circ_x = 1 - np.cos(np.linspace(0, np.pi, n_samples_in))\n    inner_circ_y = 1 - np.sin(np.linspace(0, np.pi, n_samples_in)) - 0.5\n\n    X = np.vstack(\n        [\n            np.append(outer_circ_x, inner_circ_x),\n            np.append(outer_circ_y, inner_circ_y),\n        ]\n    ).T.astype(np.float32)\n\n    # Add noise using torch AFTER converting base batch_shape to tensor\n    tensor_data = torch.from_numpy(X)  # Keep on CPU initially for noise addition\n    noise_val = torch.randn_like(tensor_data) * self.noise\n    tensor_data += noise_val\n\n    # Base class __init__ will handle final _to_tensor conversion for device/dtype\n    # Alternatively, add noise directly on the target device:\n    # tensor_data = torch.from_numpy(X).to(device=self.device, dtype=self.dtype)\n    # tensor_data += torch.randn_like(tensor_data) * self.noise\n    # return tensor_data # Return tensor directly if handled here\n\n    return tensor_data  # Return tensor, base class handles device/dtype\n</code></pre>"},{"location":"api/torchebm/integrators/","title":"Torchebm &gt; Integrators","text":""},{"location":"api/torchebm/integrators/#torchebm-integrators","title":"Torchebm &gt; Integrators","text":""},{"location":"api/torchebm/integrators/#contents","title":"Contents","text":""},{"location":"api/torchebm/integrators/#modules","title":"Modules","text":"<ul> <li>Euler_maruyama</li> <li>Heun</li> <li>Integrator_utils</li> <li>Leapfrog</li> </ul>"},{"location":"api/torchebm/integrators/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/integrators/#torchebm.integrators","title":"torchebm.integrators","text":"<p>Integrators for solving differential equations in energy-based models.</p>"},{"location":"api/torchebm/integrators/euler_maruyama/","title":"Torchebm &gt; Integrators &gt; Euler_maruyama","text":""},{"location":"api/torchebm/integrators/euler_maruyama/#torchebm-integrators-euler_maruyama","title":"Torchebm &gt; Integrators &gt; Euler_maruyama","text":""},{"location":"api/torchebm/integrators/euler_maruyama/#contents","title":"Contents","text":""},{"location":"api/torchebm/integrators/euler_maruyama/#classes","title":"Classes","text":"<ul> <li><code>EulerMaruyamaIntegrator</code> - Euler-Maruyama integrator for It\u00f4 SDEs and ODEs.</li> </ul>"},{"location":"api/torchebm/integrators/euler_maruyama/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/integrators/euler_maruyama/#torchebm.integrators.euler_maruyama","title":"torchebm.integrators.euler_maruyama","text":"<p>Euler-Maruyama integrator.</p>"},{"location":"api/torchebm/integrators/euler_maruyama/classes/EulerMaruyamaIntegrator/","title":"EulerMaruyamaIntegrator","text":""},{"location":"api/torchebm/integrators/euler_maruyama/classes/EulerMaruyamaIntegrator/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseIntegrator</code></p> <p>Euler-Maruyama integrator for It\u00f4 SDEs and ODEs.</p> <p>The SDE form is:</p> \\[ \\mathrm{d}x = f(x,t)\\,\\mathrm{d}t + \\sqrt{2D(x,t)}\\,\\mathrm{d}W_t \\] <p>When <code>diffusion</code> is omitted, this reduces to the Euler method for ODEs.</p> <p>Update rule:</p> \\[ x_{n+1} = x_n + f(x_n, t_n)\\Delta t + \\sqrt{2D(x_n,t_n)}\\,\\Delta W_n \\] <p>Parameters:</p> Name Type Description Default <code>device</code> <code>Optional[device]</code> <p>Device for computations.</p> <code>None</code> <code>dtype</code> <code>Optional[dtype]</code> <p>Data type for computations.</p> <code>None</code> Example <pre><code>from torchebm.integrators import EulerMaruyamaIntegrator\nimport torch\n\nintegrator = EulerMaruyamaIntegrator()\nstate = {\"x\": torch.randn(100, 2)}\ndrift = lambda x, t: -x  # simple mean-reverting drift\nresult = integrator.step(\n    state, model=None, step_size=0.01, drift=drift, noise_scale=1.0\n)\n</code></pre> Source code in <code>torchebm/integrators/euler_maruyama.py</code> <pre><code>class EulerMaruyamaIntegrator(BaseIntegrator):\n    r\"\"\"\n    Euler-Maruyama integrator for It\u00f4 SDEs and ODEs.\n\n    The SDE form is:\n\n    \\[\n    \\mathrm{d}x = f(x,t)\\,\\mathrm{d}t + \\sqrt{2D(x,t)}\\,\\mathrm{d}W_t\n    \\]\n\n    When `diffusion` is omitted, this reduces to the Euler method for ODEs.\n\n    Update rule:\n\n    \\[\n    x_{n+1} = x_n + f(x_n, t_n)\\Delta t + \\sqrt{2D(x_n,t_n)}\\,\\Delta W_n\n    \\]\n\n    Args:\n        device: Device for computations.\n        dtype: Data type for computations.\n\n    Example:\n        ```python\n        from torchebm.integrators import EulerMaruyamaIntegrator\n        import torch\n\n        integrator = EulerMaruyamaIntegrator()\n        state = {\"x\": torch.randn(100, 2)}\n        drift = lambda x, t: -x  # simple mean-reverting drift\n        result = integrator.step(\n            state, model=None, step_size=0.01, drift=drift, noise_scale=1.0\n        )\n        ```\n    \"\"\"\n\n    def step(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        *,\n        drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n        diffusion: Optional[torch.Tensor] = None,\n        noise: Optional[torch.Tensor] = None,\n        noise_scale: Optional[torch.Tensor] = None,\n        t: Optional[torch.Tensor] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        x = state[\"x\"]\n        if not torch.is_tensor(step_size):\n            step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n        if t is None:\n            t = torch.zeros(x.size(0), device=x.device, dtype=x.dtype)\n\n        if drift is None:\n            if model is None:\n                raise ValueError(\n                    \"Either `model` must be provided or `drift` must be set.\"\n                )\n            drift = lambda x_, t_: -model.gradient(x_)\n\n        if diffusion is None and noise_scale is not None:\n            if not torch.is_tensor(noise_scale):\n                noise_scale = torch.tensor(noise_scale, device=x.device, dtype=x.dtype)\n            diffusion = noise_scale**2\n\n        drift_term = drift(x, t) * step_size\n\n        if diffusion is None:\n            return {\"x\": x + drift_term}\n\n        if noise is None:\n            noise = torch.randn_like(x, device=self.device, dtype=self.dtype)\n\n        dw = noise * torch.sqrt(step_size)\n        return {\"x\": x + drift_term + torch.sqrt(2.0 * diffusion) * dw}\n\n    def integrate(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        n_steps: int,\n        *,\n        drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n        diffusion: Optional[\n            Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n        ] = None,\n        noise_scale: Optional[torch.Tensor] = None,\n        t: Optional[torch.Tensor] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        if n_steps &lt;= 0:\n            raise ValueError(\"n_steps must be positive\")\n        if t is None:\n            if not torch.is_tensor(step_size):\n                step_size = torch.tensor(\n                    step_size, device=state[\"x\"].device, dtype=state[\"x\"].dtype\n                )\n            t = (\n                torch.arange(n_steps, device=state[\"x\"].device, dtype=state[\"x\"].dtype)\n                * step_size\n            )\n        if t.ndim != 1 or t.numel() != n_steps:\n            raise ValueError(\"t must be a 1D tensor with length n_steps\")\n\n        x0 = state[\"x\"]\n\n        def _step_fn(x, t_batch, dt):\n            diffusion_t = diffusion(x, t_batch) if diffusion is not None else None\n            return self.step(\n                state={\"x\": x},\n                model=model,\n                step_size=dt,\n                drift=drift,\n                diffusion=diffusion_t,\n                noise_scale=noise_scale,\n                t=t_batch,\n            )[\"x\"]\n\n        return {\"x\": _integrate_time_grid(x0, t, _step_fn)}\n</code></pre>"},{"location":"api/torchebm/integrators/euler_maruyama/classes/EulerMaruyamaIntegrator/#torchebm.integrators.euler_maruyama.EulerMaruyamaIntegrator.step","title":"step","text":"<pre><code>step(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, *, drift: Optional[Callable[[Tensor, Tensor], Tensor]] = None, diffusion: Optional[Tensor] = None, noise: Optional[Tensor] = None, noise_scale: Optional[Tensor] = None, t: Optional[Tensor] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/euler_maruyama.py</code> <pre><code>def step(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    *,\n    drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n    diffusion: Optional[torch.Tensor] = None,\n    noise: Optional[torch.Tensor] = None,\n    noise_scale: Optional[torch.Tensor] = None,\n    t: Optional[torch.Tensor] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    x = state[\"x\"]\n    if not torch.is_tensor(step_size):\n        step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n    if t is None:\n        t = torch.zeros(x.size(0), device=x.device, dtype=x.dtype)\n\n    if drift is None:\n        if model is None:\n            raise ValueError(\n                \"Either `model` must be provided or `drift` must be set.\"\n            )\n        drift = lambda x_, t_: -model.gradient(x_)\n\n    if diffusion is None and noise_scale is not None:\n        if not torch.is_tensor(noise_scale):\n            noise_scale = torch.tensor(noise_scale, device=x.device, dtype=x.dtype)\n        diffusion = noise_scale**2\n\n    drift_term = drift(x, t) * step_size\n\n    if diffusion is None:\n        return {\"x\": x + drift_term}\n\n    if noise is None:\n        noise = torch.randn_like(x, device=self.device, dtype=self.dtype)\n\n    dw = noise * torch.sqrt(step_size)\n    return {\"x\": x + drift_term + torch.sqrt(2.0 * diffusion) * dw}\n</code></pre>"},{"location":"api/torchebm/integrators/euler_maruyama/classes/EulerMaruyamaIntegrator/#torchebm.integrators.euler_maruyama.EulerMaruyamaIntegrator.integrate","title":"integrate","text":"<pre><code>integrate(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, n_steps: int, *, drift: Optional[Callable[[Tensor, Tensor], Tensor]] = None, diffusion: Optional[Callable[[Tensor, Tensor], Tensor]] = None, noise_scale: Optional[Tensor] = None, t: Optional[Tensor] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/euler_maruyama.py</code> <pre><code>def integrate(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    n_steps: int,\n    *,\n    drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n    diffusion: Optional[\n        Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n    ] = None,\n    noise_scale: Optional[torch.Tensor] = None,\n    t: Optional[torch.Tensor] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    if n_steps &lt;= 0:\n        raise ValueError(\"n_steps must be positive\")\n    if t is None:\n        if not torch.is_tensor(step_size):\n            step_size = torch.tensor(\n                step_size, device=state[\"x\"].device, dtype=state[\"x\"].dtype\n            )\n        t = (\n            torch.arange(n_steps, device=state[\"x\"].device, dtype=state[\"x\"].dtype)\n            * step_size\n        )\n    if t.ndim != 1 or t.numel() != n_steps:\n        raise ValueError(\"t must be a 1D tensor with length n_steps\")\n\n    x0 = state[\"x\"]\n\n    def _step_fn(x, t_batch, dt):\n        diffusion_t = diffusion(x, t_batch) if diffusion is not None else None\n        return self.step(\n            state={\"x\": x},\n            model=model,\n            step_size=dt,\n            drift=drift,\n            diffusion=diffusion_t,\n            noise_scale=noise_scale,\n            t=t_batch,\n        )[\"x\"]\n\n    return {\"x\": _integrate_time_grid(x0, t, _step_fn)}\n</code></pre>"},{"location":"api/torchebm/integrators/heun/","title":"Torchebm &gt; Integrators &gt; Heun","text":""},{"location":"api/torchebm/integrators/heun/#torchebm-integrators-heun","title":"Torchebm &gt; Integrators &gt; Heun","text":""},{"location":"api/torchebm/integrators/heun/#contents","title":"Contents","text":""},{"location":"api/torchebm/integrators/heun/#classes","title":"Classes","text":"<ul> <li><code>HeunIntegrator</code> - Heun integrator (predictor-corrector) for It\u00f4 SDEs and ODEs.</li> </ul>"},{"location":"api/torchebm/integrators/heun/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/integrators/heun/#torchebm.integrators.heun","title":"torchebm.integrators.heun","text":""},{"location":"api/torchebm/integrators/heun/classes/HeunIntegrator/","title":"HeunIntegrator","text":""},{"location":"api/torchebm/integrators/heun/classes/HeunIntegrator/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseIntegrator</code></p> <p>Heun integrator (predictor-corrector) for It\u00f4 SDEs and ODEs.</p> <p>A second-order method that uses a predictor step followed by a corrector:</p> \\[ \\mathrm{d}x = f(x,t)\\,\\mathrm{d}t + \\sqrt{2D(x,t)}\\,\\mathrm{d}W_t \\] <p>Parameters:</p> Name Type Description Default <code>device</code> <code>Optional[device]</code> <p>Device for computations.</p> <code>None</code> <code>dtype</code> <code>Optional[dtype]</code> <p>Data type for computations.</p> <code>None</code> Example <pre><code>from torchebm.integrators import HeunIntegrator\nimport torch\n\nintegrator = HeunIntegrator()\nstate = {\"x\": torch.randn(100, 2)}\nt = torch.linspace(0, 1, 50)\ndrift = lambda x, t: -x\nresult = integrator.integrate(\n    state, model=None, step_size=0.02, n_steps=50, drift=drift, t=t\n)\n</code></pre> Source code in <code>torchebm/integrators/heun.py</code> <pre><code>class HeunIntegrator(BaseIntegrator):\n    r\"\"\"\n    Heun integrator (predictor-corrector) for It\u00f4 SDEs and ODEs.\n\n    A second-order method that uses a predictor step followed by a corrector:\n\n    \\[\n    \\mathrm{d}x = f(x,t)\\,\\mathrm{d}t + \\sqrt{2D(x,t)}\\,\\mathrm{d}W_t\n    \\]\n\n    Args:\n        device: Device for computations.\n        dtype: Data type for computations.\n\n    Example:\n        ```python\n        from torchebm.integrators import HeunIntegrator\n        import torch\n\n        integrator = HeunIntegrator()\n        state = {\"x\": torch.randn(100, 2)}\n        t = torch.linspace(0, 1, 50)\n        drift = lambda x, t: -x\n        result = integrator.integrate(\n            state, model=None, step_size=0.02, n_steps=50, drift=drift, t=t\n        )\n        ```\n    \"\"\"\n\n    def step(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        *,\n        drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n        diffusion: Optional[torch.Tensor] = None,\n        t: torch.Tensor,\n        noise: Optional[torch.Tensor] = None,\n        noise_scale: Optional[torch.Tensor] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        x = state[\"x\"]\n        if not torch.is_tensor(step_size):\n            step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n        if drift is None:\n            if model is None:\n                raise ValueError(\n                    \"Either `model` must be provided or `drift` must be set.\"\n                )\n            drift = lambda x_, t_: -model.gradient(x_)\n\n        if diffusion is None and noise_scale is not None:\n            if not torch.is_tensor(noise_scale):\n                noise_scale = torch.tensor(noise_scale, device=x.device, dtype=x.dtype)\n            diffusion = noise_scale**2\n\n        # Heun predictor-corrector for drift term\n        k1 = drift(x, t)\n        x_pred = x + step_size * k1\n        k2 = drift(x_pred, t + step_size)\n        x_new = x + 0.5 * step_size * (k1 + k2)\n\n        # Add stochastic term after deterministic update\n        if diffusion is not None:\n            if noise is None:\n                noise = torch.randn_like(x, device=self.device, dtype=self.dtype)\n            dw = noise * torch.sqrt(step_size)\n            x_new = x_new + torch.sqrt(2.0 * diffusion) * dw\n\n        return {\"x\": x_new}\n\n\n    def integrate(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        n_steps: int,\n        *,\n        drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n        diffusion: Optional[\n            Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n        ] = None,\n        noise_scale: Optional[torch.Tensor] = None,\n        t: torch.Tensor,\n    ) -&gt; Dict[str, torch.Tensor]:\n        if n_steps &lt;= 0:\n            raise ValueError(\"n_steps must be positive\")\n        if t.ndim != 1 or t.numel() != n_steps:\n            raise ValueError(\"t must be a 1D tensor with length n_steps\")\n\n        x0 = state[\"x\"]\n\n        def _step_fn(x, t_batch, dt):\n            diffusion_t = diffusion(x, t_batch) if diffusion is not None else None\n            return self.step(\n                state={\"x\": x},\n                model=model,\n                step_size=dt,\n                drift=drift,\n                diffusion=diffusion_t,\n                t=t_batch,\n                noise_scale=noise_scale,\n            )[\"x\"]\n\n        return {\"x\": _integrate_time_grid(x0, t, _step_fn)}\n</code></pre>"},{"location":"api/torchebm/integrators/heun/classes/HeunIntegrator/#torchebm.integrators.heun.HeunIntegrator.step","title":"step","text":"<pre><code>step(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, *, drift: Optional[Callable[[Tensor, Tensor], Tensor]] = None, diffusion: Optional[Tensor] = None, t: Tensor, noise: Optional[Tensor] = None, noise_scale: Optional[Tensor] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/heun.py</code> <pre><code>def step(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    *,\n    drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n    diffusion: Optional[torch.Tensor] = None,\n    t: torch.Tensor,\n    noise: Optional[torch.Tensor] = None,\n    noise_scale: Optional[torch.Tensor] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    x = state[\"x\"]\n    if not torch.is_tensor(step_size):\n        step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n    if drift is None:\n        if model is None:\n            raise ValueError(\n                \"Either `model` must be provided or `drift` must be set.\"\n            )\n        drift = lambda x_, t_: -model.gradient(x_)\n\n    if diffusion is None and noise_scale is not None:\n        if not torch.is_tensor(noise_scale):\n            noise_scale = torch.tensor(noise_scale, device=x.device, dtype=x.dtype)\n        diffusion = noise_scale**2\n\n    # Heun predictor-corrector for drift term\n    k1 = drift(x, t)\n    x_pred = x + step_size * k1\n    k2 = drift(x_pred, t + step_size)\n    x_new = x + 0.5 * step_size * (k1 + k2)\n\n    # Add stochastic term after deterministic update\n    if diffusion is not None:\n        if noise is None:\n            noise = torch.randn_like(x, device=self.device, dtype=self.dtype)\n        dw = noise * torch.sqrt(step_size)\n        x_new = x_new + torch.sqrt(2.0 * diffusion) * dw\n\n    return {\"x\": x_new}\n</code></pre>"},{"location":"api/torchebm/integrators/heun/classes/HeunIntegrator/#torchebm.integrators.heun.HeunIntegrator.integrate","title":"integrate","text":"<pre><code>integrate(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, n_steps: int, *, drift: Optional[Callable[[Tensor, Tensor], Tensor]] = None, diffusion: Optional[Callable[[Tensor, Tensor], Tensor]] = None, noise_scale: Optional[Tensor] = None, t: Tensor) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/heun.py</code> <pre><code>def integrate(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    n_steps: int,\n    *,\n    drift: Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,\n    diffusion: Optional[\n        Callable[[torch.Tensor, torch.Tensor], torch.Tensor]\n    ] = None,\n    noise_scale: Optional[torch.Tensor] = None,\n    t: torch.Tensor,\n) -&gt; Dict[str, torch.Tensor]:\n    if n_steps &lt;= 0:\n        raise ValueError(\"n_steps must be positive\")\n    if t.ndim != 1 or t.numel() != n_steps:\n        raise ValueError(\"t must be a 1D tensor with length n_steps\")\n\n    x0 = state[\"x\"]\n\n    def _step_fn(x, t_batch, dt):\n        diffusion_t = diffusion(x, t_batch) if diffusion is not None else None\n        return self.step(\n            state={\"x\": x},\n            model=model,\n            step_size=dt,\n            drift=drift,\n            diffusion=diffusion_t,\n            t=t_batch,\n            noise_scale=noise_scale,\n        )[\"x\"]\n\n    return {\"x\": _integrate_time_grid(x0, t, _step_fn)}\n</code></pre>"},{"location":"api/torchebm/integrators/integrator_utils/","title":"Integrator_utils","text":""},{"location":"api/torchebm/integrators/integrator_utils/#torchebm-integrators-integrator_utils","title":"Torchebm &gt; Integrators &gt; Integrator_utils","text":""},{"location":"api/torchebm/integrators/integrator_utils/#contents","title":"Contents","text":""},{"location":"api/torchebm/integrators/integrator_utils/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/integrators/integrator_utils/#torchebm.integrators.integrator_utils","title":"torchebm.integrators.integrator_utils","text":""},{"location":"api/torchebm/integrators/leapfrog/","title":"Torchebm &gt; Integrators &gt; Leapfrog","text":""},{"location":"api/torchebm/integrators/leapfrog/#torchebm-integrators-leapfrog","title":"Torchebm &gt; Integrators &gt; Leapfrog","text":""},{"location":"api/torchebm/integrators/leapfrog/#contents","title":"Contents","text":""},{"location":"api/torchebm/integrators/leapfrog/#classes","title":"Classes","text":"<ul> <li><code>LeapfrogIntegrator</code> - Symplectic leapfrog (St\u00f6rmer\u2013Verlet) integrator for Hamiltonian dynamics.</li> </ul>"},{"location":"api/torchebm/integrators/leapfrog/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/integrators/leapfrog/#torchebm.integrators.leapfrog","title":"torchebm.integrators.leapfrog","text":""},{"location":"api/torchebm/integrators/leapfrog/classes/LeapfrogIntegrator/","title":"LeapfrogIntegrator","text":""},{"location":"api/torchebm/integrators/leapfrog/classes/LeapfrogIntegrator/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseIntegrator</code></p> <p>Symplectic leapfrog (St\u00f6rmer\u2013Verlet) integrator for Hamiltonian dynamics.</p> <p>Update rule:</p> \\[ p_{t+1/2} = p_t - \\frac{\\epsilon}{2} \\nabla_x U(x_t) \\] \\[ x_{t+1} = x_t + \\epsilon p_{t+1/2} \\] \\[ p_{t+1} = p_{t+1/2} - \\frac{\\epsilon}{2} \\nabla_x U(x_{t+1}) \\] <p>Parameters:</p> Name Type Description Default <code>device</code> <code>Optional[device]</code> <p>Device for computations.</p> <code>None</code> <code>dtype</code> <code>Optional[dtype]</code> <p>Data type for computations.</p> <code>None</code> Example <pre><code>from torchebm.integrators import LeapfrogIntegrator\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nintegrator = LeapfrogIntegrator()\nstate = {\"x\": torch.randn(100, 2), \"p\": torch.randn(100, 2)}\nresult = integrator.integrate(state, energy, step_size=0.01, n_steps=10)\n</code></pre> Source code in <code>torchebm/integrators/leapfrog.py</code> <pre><code>class LeapfrogIntegrator(BaseIntegrator):\n    r\"\"\"\n    Symplectic leapfrog (St\u00f6rmer\u2013Verlet) integrator for Hamiltonian dynamics.\n\n    Update rule:\n\n    \\[\n    p_{t+1/2} = p_t - \\frac{\\epsilon}{2} \\nabla_x U(x_t)\n    \\]\n\n    \\[\n    x_{t+1} = x_t + \\epsilon p_{t+1/2}\n    \\]\n\n    \\[\n    p_{t+1} = p_{t+1/2} - \\frac{\\epsilon}{2} \\nabla_x U(x_{t+1})\n    \\]\n\n    Args:\n        device: Device for computations.\n        dtype: Data type for computations.\n\n    Example:\n        ```python\n        from torchebm.integrators import LeapfrogIntegrator\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        integrator = LeapfrogIntegrator()\n        state = {\"x\": torch.randn(100, 2), \"p\": torch.randn(100, 2)}\n        result = integrator.integrate(state, energy, step_size=0.01, n_steps=10)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        device: Optional[torch.device] = None,\n        dtype: Optional[torch.dtype] = None,\n    ):\n        super().__init__(device=device, dtype=dtype)\n\n    def step(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        mass: Optional[Union[float, torch.Tensor]] = None,\n        *,\n        potential_grad: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        x = state[\"x\"]\n        p = state[\"p\"]\n\n        if not torch.is_tensor(step_size):\n            step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n        if potential_grad is None:\n            if model is None:\n                raise ValueError(\n                    \"Either `model` must be provided or `potential_grad` must be set.\"\n                )\n            potential_grad = model.gradient\n\n        grad = potential_grad(x)\n        grad = torch.clamp(grad, min=-1e6, max=1e6)\n\n        # half-step momentum\n        p_half = p - 0.5 * step_size * grad\n\n        # full-step position update\n        if mass is None:\n            x_new = x + step_size * p_half\n        else:\n            if isinstance(mass, float):\n                safe_mass = max(mass, 1e-10)\n                x_new = x + step_size * p_half / safe_mass\n            else:\n                safe_mass = torch.clamp(mass, min=1e-10)\n                x_new = x + step_size * p_half / safe_mass.view(\n                    *([1] * (len(x.shape) - 1)), -1\n                )\n\n        # half-step momentum update at new position\n        grad_new = potential_grad(x_new)\n        grad_new = torch.clamp(grad_new, min=-1e6, max=1e6)\n        p_new = p_half - 0.5 * step_size * grad_new\n\n        # handling NaNs\n        if torch.isnan(x_new).any() or torch.isnan(p_new).any():\n            x_new = torch.nan_to_num(x_new, nan=0.0)\n            p_new = torch.nan_to_num(p_new, nan=0.0)\n        return {\"x\": x_new, \"p\": p_new}\n\n    def integrate(\n        self,\n        state: Dict[str, torch.Tensor],\n        model: Optional[BaseModel],\n        step_size: torch.Tensor,\n        n_steps: int,\n        mass: Optional[Union[float, torch.Tensor]] = None,\n        *,\n        potential_grad: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        if n_steps &lt;= 0:\n            raise ValueError(\"n_steps must be positive\")\n\n        x = state[\"x\"]\n        p = state[\"p\"]\n\n        for _ in range(n_steps):\n            state = self.step(\n                state={\"x\": x, \"p\": p},\n                model=model,\n                step_size=step_size,\n                mass=mass,\n                potential_grad=potential_grad,\n            )\n            x, p = state[\"x\"], state[\"p\"]\n\n        return {\"x\": x, \"p\": p}\n</code></pre>"},{"location":"api/torchebm/integrators/leapfrog/classes/LeapfrogIntegrator/#torchebm.integrators.leapfrog.LeapfrogIntegrator.step","title":"step","text":"<pre><code>step(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, mass: Optional[Union[float, Tensor]] = None, *, potential_grad: Optional[Callable[[Tensor], Tensor]] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/leapfrog.py</code> <pre><code>def step(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    mass: Optional[Union[float, torch.Tensor]] = None,\n    *,\n    potential_grad: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    x = state[\"x\"]\n    p = state[\"p\"]\n\n    if not torch.is_tensor(step_size):\n        step_size = torch.tensor(step_size, device=x.device, dtype=x.dtype)\n\n    if potential_grad is None:\n        if model is None:\n            raise ValueError(\n                \"Either `model` must be provided or `potential_grad` must be set.\"\n            )\n        potential_grad = model.gradient\n\n    grad = potential_grad(x)\n    grad = torch.clamp(grad, min=-1e6, max=1e6)\n\n    # half-step momentum\n    p_half = p - 0.5 * step_size * grad\n\n    # full-step position update\n    if mass is None:\n        x_new = x + step_size * p_half\n    else:\n        if isinstance(mass, float):\n            safe_mass = max(mass, 1e-10)\n            x_new = x + step_size * p_half / safe_mass\n        else:\n            safe_mass = torch.clamp(mass, min=1e-10)\n            x_new = x + step_size * p_half / safe_mass.view(\n                *([1] * (len(x.shape) - 1)), -1\n            )\n\n    # half-step momentum update at new position\n    grad_new = potential_grad(x_new)\n    grad_new = torch.clamp(grad_new, min=-1e6, max=1e6)\n    p_new = p_half - 0.5 * step_size * grad_new\n\n    # handling NaNs\n    if torch.isnan(x_new).any() or torch.isnan(p_new).any():\n        x_new = torch.nan_to_num(x_new, nan=0.0)\n        p_new = torch.nan_to_num(p_new, nan=0.0)\n    return {\"x\": x_new, \"p\": p_new}\n</code></pre>"},{"location":"api/torchebm/integrators/leapfrog/classes/LeapfrogIntegrator/#torchebm.integrators.leapfrog.LeapfrogIntegrator.integrate","title":"integrate","text":"<pre><code>integrate(state: Dict[str, Tensor], model: Optional[BaseModel], step_size: Tensor, n_steps: int, mass: Optional[Union[float, Tensor]] = None, *, potential_grad: Optional[Callable[[Tensor], Tensor]] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> Source code in <code>torchebm/integrators/leapfrog.py</code> <pre><code>def integrate(\n    self,\n    state: Dict[str, torch.Tensor],\n    model: Optional[BaseModel],\n    step_size: torch.Tensor,\n    n_steps: int,\n    mass: Optional[Union[float, torch.Tensor]] = None,\n    *,\n    potential_grad: Optional[Callable[[torch.Tensor], torch.Tensor]] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    if n_steps &lt;= 0:\n        raise ValueError(\"n_steps must be positive\")\n\n    x = state[\"x\"]\n    p = state[\"p\"]\n\n    for _ in range(n_steps):\n        state = self.step(\n            state={\"x\": x, \"p\": p},\n            model=model,\n            step_size=step_size,\n            mass=mass,\n            potential_grad=potential_grad,\n        )\n        x, p = state[\"x\"], state[\"p\"]\n\n    return {\"x\": x, \"p\": p}\n</code></pre>"},{"location":"api/torchebm/interpolants/","title":"Torchebm &gt; Interpolants","text":""},{"location":"api/torchebm/interpolants/#torchebm-interpolants","title":"Torchebm &gt; Interpolants","text":""},{"location":"api/torchebm/interpolants/#contents","title":"Contents","text":""},{"location":"api/torchebm/interpolants/#modules","title":"Modules","text":"<ul> <li>Cosine</li> <li>Linear</li> <li>Variance_preserving</li> </ul>"},{"location":"api/torchebm/interpolants/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/interpolants/#torchebm.interpolants","title":"torchebm.interpolants","text":"<p>Stochastic interpolants for generative modeling.</p> <p>Interpolants define conditional probability paths between source (noise) and target (data) distributions, parameterized by schedules \u03b1(t) and \u03c3(t).</p>"},{"location":"api/torchebm/interpolants/cosine/","title":"Torchebm &gt; Interpolants &gt; Cosine","text":""},{"location":"api/torchebm/interpolants/cosine/#torchebm-interpolants-cosine","title":"Torchebm &gt; Interpolants &gt; Cosine","text":""},{"location":"api/torchebm/interpolants/cosine/#contents","title":"Contents","text":""},{"location":"api/torchebm/interpolants/cosine/#classes","title":"Classes","text":"<ul> <li><code>CosineInterpolant</code> - Cosine (geodesic variance preserving) interpolant.</li> </ul>"},{"location":"api/torchebm/interpolants/cosine/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/interpolants/cosine/#torchebm.interpolants.cosine","title":"torchebm.interpolants.cosine","text":"<p>Cosine interpolant (geodesic variance preserving).</p>"},{"location":"api/torchebm/interpolants/cosine/classes/CosineInterpolant/","title":"CosineInterpolant","text":""},{"location":"api/torchebm/interpolants/cosine/classes/CosineInterpolant/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Cosine (geodesic variance preserving) interpolant.</p> <p>Also known as the GVP interpolant. Uses trigonometric functions to maintain unit variance throughout the interpolation path.</p> <p>The interpolation is defined as:</p> \\[ x_t = \\sin\\left(\\frac{\\pi t}{2}\\right) x_1 + \\cos\\left(\\frac{\\pi t}{2}\\right) x_0 \\] <p>This satisfies \\(\\alpha(t)^2 + \\sigma(t)^2 = 1\\).</p> Example <pre><code>from torchebm.interpolants import CosineInterpolant\nimport torch\n\ninterpolant = CosineInterpolant()\nx0 = torch.randn(32, 2)  # noise\nx1 = torch.randn(32, 2)  # data\nt = torch.rand(32)\nxt, ut = interpolant.interpolate(x0, x1, t)\n</code></pre> Source code in <code>torchebm/interpolants/cosine.py</code> <pre><code>class CosineInterpolant(BaseInterpolant):\n    r\"\"\"\n    Cosine (geodesic variance preserving) interpolant.\n\n    Also known as the GVP interpolant. Uses trigonometric functions to\n    maintain unit variance throughout the interpolation path.\n\n    The interpolation is defined as:\n\n    \\[\n    x_t = \\sin\\left(\\frac{\\pi t}{2}\\right) x_1 + \\cos\\left(\\frac{\\pi t}{2}\\right) x_0\n    \\]\n\n    This satisfies \\(\\alpha(t)^2 + \\sigma(t)^2 = 1\\).\n\n    Example:\n        ```python\n        from torchebm.interpolants import CosineInterpolant\n        import torch\n\n        interpolant = CosineInterpolant()\n        x0 = torch.randn(32, 2)  # noise\n        x1 = torch.randn(32, 2)  # data\n        t = torch.rand(32)\n        xt, ut = interpolant.interpolate(x0, x1, t)\n        ```\n    \"\"\"\n\n    def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\alpha(t) = \\sin(\\pi t / 2)\\) and its derivative.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03b1(t), \u03b1\u0307(t)).\n        \"\"\"\n        alpha = torch.sin(t * math.pi / 2)\n        d_alpha = (math.pi / 2) * torch.cos(t * math.pi / 2)\n        return alpha, d_alpha\n\n    def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\sigma(t) = \\cos(\\pi t / 2)\\) and its derivative.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03c3(t), \u03c3\u0307(t)).\n        \"\"\"\n        sigma = torch.cos(t * math.pi / 2)\n        d_sigma = -(math.pi / 2) * torch.sin(t * math.pi / 2)\n        return sigma, d_sigma\n\n    def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = (\\pi/2) \\cot(\\pi t / 2)\\).\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            The ratio with clamping for stability.\n        \"\"\"\n        return math.pi / (2 * torch.clamp(torch.tan(t * math.pi / 2), min=1e-8))\n</code></pre>"},{"location":"api/torchebm/interpolants/cosine/classes/CosineInterpolant/#torchebm.interpolants.cosine.CosineInterpolant.compute_alpha_t","title":"compute_alpha_t","text":"<pre><code>compute_alpha_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\alpha(t) = \\sin(\\pi t / 2)\\) and its derivative.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03b1(t), \u03b1\u0307(t)).</p> Source code in <code>torchebm/interpolants/cosine.py</code> <pre><code>def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\alpha(t) = \\sin(\\pi t / 2)\\) and its derivative.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03b1(t), \u03b1\u0307(t)).\n    \"\"\"\n    alpha = torch.sin(t * math.pi / 2)\n    d_alpha = (math.pi / 2) * torch.cos(t * math.pi / 2)\n    return alpha, d_alpha\n</code></pre>"},{"location":"api/torchebm/interpolants/cosine/classes/CosineInterpolant/#torchebm.interpolants.cosine.CosineInterpolant.compute_sigma_t","title":"compute_sigma_t","text":"<pre><code>compute_sigma_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\sigma(t) = \\cos(\\pi t / 2)\\) and its derivative.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03c3(t), \u03c3\u0307(t)).</p> Source code in <code>torchebm/interpolants/cosine.py</code> <pre><code>def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\sigma(t) = \\cos(\\pi t / 2)\\) and its derivative.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03c3(t), \u03c3\u0307(t)).\n    \"\"\"\n    sigma = torch.cos(t * math.pi / 2)\n    d_sigma = -(math.pi / 2) * torch.sin(t * math.pi / 2)\n    return sigma, d_sigma\n</code></pre>"},{"location":"api/torchebm/interpolants/cosine/classes/CosineInterpolant/#torchebm.interpolants.cosine.CosineInterpolant.compute_d_alpha_alpha_ratio_t","title":"compute_d_alpha_alpha_ratio_t","text":"<pre><code>compute_d_alpha_alpha_ratio_t(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = (\\pi/2) \\cot(\\pi t / 2)\\).</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The ratio with clamping for stability.</p> Source code in <code>torchebm/interpolants/cosine.py</code> <pre><code>def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = (\\pi/2) \\cot(\\pi t / 2)\\).\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        The ratio with clamping for stability.\n    \"\"\"\n    return math.pi / (2 * torch.clamp(torch.tan(t * math.pi / 2), min=1e-8))\n</code></pre>"},{"location":"api/torchebm/interpolants/linear/","title":"Torchebm &gt; Interpolants &gt; Linear","text":""},{"location":"api/torchebm/interpolants/linear/#torchebm-interpolants-linear","title":"Torchebm &gt; Interpolants &gt; Linear","text":""},{"location":"api/torchebm/interpolants/linear/#contents","title":"Contents","text":""},{"location":"api/torchebm/interpolants/linear/#classes","title":"Classes","text":"<ul> <li><code>LinearInterpolant</code> - Linear interpolant between noise and data distributions.</li> </ul>"},{"location":"api/torchebm/interpolants/linear/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/interpolants/linear/#torchebm.interpolants.linear","title":"torchebm.interpolants.linear","text":"<p>Linear interpolant (optimal transport interpolant).</p>"},{"location":"api/torchebm/interpolants/linear/classes/LinearInterpolant/","title":"LinearInterpolant","text":""},{"location":"api/torchebm/interpolants/linear/classes/LinearInterpolant/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Linear interpolant between noise and data distributions.</p> <p>Also known as the optimal transport (OT) or rectified flow interpolant.</p> <p>The interpolation is defined as:</p> \\[ x_t = t \\cdot x_1 + (1 - t) \\cdot x_0 \\] <p>with \\(\\alpha(t) = t\\) and \\(\\sigma(t) = 1 - t\\).</p> Example <pre><code>from torchebm.interpolants import LinearInterpolant\nimport torch\n\ninterpolant = LinearInterpolant()\nx0 = torch.randn(32, 2)  # noise\nx1 = torch.randn(32, 2)  # data\nt = torch.rand(32)\nxt, ut = interpolant.interpolate(x0, x1, t)\n</code></pre> Source code in <code>torchebm/interpolants/linear.py</code> <pre><code>class LinearInterpolant(BaseInterpolant):\n    r\"\"\"\n    Linear interpolant between noise and data distributions.\n\n    Also known as the optimal transport (OT) or rectified flow interpolant.\n\n    The interpolation is defined as:\n\n    \\[\n    x_t = t \\cdot x_1 + (1 - t) \\cdot x_0\n    \\]\n\n    with \\(\\alpha(t) = t\\) and \\(\\sigma(t) = 1 - t\\).\n\n    Example:\n        ```python\n        from torchebm.interpolants import LinearInterpolant\n        import torch\n\n        interpolant = LinearInterpolant()\n        x0 = torch.randn(32, 2)  # noise\n        x1 = torch.randn(32, 2)  # data\n        t = torch.rand(32)\n        xt, ut = interpolant.interpolate(x0, x1, t)\n        ```\n    \"\"\"\n\n    def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\alpha(t) = t\\) and \\(\\dot{\\alpha}(t) = 1\\).\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03b1(t), \u03b1\u0307(t)).\n        \"\"\"\n        alpha = t\n        d_alpha = torch.ones_like(t)\n        return alpha, d_alpha\n\n    def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\sigma(t) = 1 - t\\) and \\(\\dot{\\sigma}(t) = -1\\).\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03c3(t), \u03c3\u0307(t)).\n        \"\"\"\n        sigma = 1 - t\n        d_sigma = -torch.ones_like(t)\n        return sigma, d_sigma\n\n    def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = 1/t\\).\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            The ratio 1/t with clamping for stability.\n        \"\"\"\n        return 1 / torch.clamp(t, min=1e-8)\n</code></pre>"},{"location":"api/torchebm/interpolants/linear/classes/LinearInterpolant/#torchebm.interpolants.linear.LinearInterpolant.compute_alpha_t","title":"compute_alpha_t","text":"<pre><code>compute_alpha_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\alpha(t) = t\\) and \\(\\dot{\\alpha}(t) = 1\\).</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03b1(t), \u03b1\u0307(t)).</p> Source code in <code>torchebm/interpolants/linear.py</code> <pre><code>def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\alpha(t) = t\\) and \\(\\dot{\\alpha}(t) = 1\\).\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03b1(t), \u03b1\u0307(t)).\n    \"\"\"\n    alpha = t\n    d_alpha = torch.ones_like(t)\n    return alpha, d_alpha\n</code></pre>"},{"location":"api/torchebm/interpolants/linear/classes/LinearInterpolant/#torchebm.interpolants.linear.LinearInterpolant.compute_sigma_t","title":"compute_sigma_t","text":"<pre><code>compute_sigma_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\sigma(t) = 1 - t\\) and \\(\\dot{\\sigma}(t) = -1\\).</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03c3(t), \u03c3\u0307(t)).</p> Source code in <code>torchebm/interpolants/linear.py</code> <pre><code>def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\sigma(t) = 1 - t\\) and \\(\\dot{\\sigma}(t) = -1\\).\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03c3(t), \u03c3\u0307(t)).\n    \"\"\"\n    sigma = 1 - t\n    d_sigma = -torch.ones_like(t)\n    return sigma, d_sigma\n</code></pre>"},{"location":"api/torchebm/interpolants/linear/classes/LinearInterpolant/#torchebm.interpolants.linear.LinearInterpolant.compute_d_alpha_alpha_ratio_t","title":"compute_d_alpha_alpha_ratio_t","text":"<pre><code>compute_d_alpha_alpha_ratio_t(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = 1/t\\).</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The ratio 1/t with clamping for stability.</p> Source code in <code>torchebm/interpolants/linear.py</code> <pre><code>def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute \\(\\dot{\\alpha}(t) / \\alpha(t) = 1/t\\).\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        The ratio 1/t with clamping for stability.\n    \"\"\"\n    return 1 / torch.clamp(t, min=1e-8)\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/","title":"Torchebm &gt; Interpolants &gt; Variance_preserving","text":""},{"location":"api/torchebm/interpolants/variance_preserving/#torchebm-interpolants-variance_preserving","title":"Torchebm &gt; Interpolants &gt; Variance_preserving","text":""},{"location":"api/torchebm/interpolants/variance_preserving/#contents","title":"Contents","text":""},{"location":"api/torchebm/interpolants/variance_preserving/#classes","title":"Classes","text":"<ul> <li><code>VariancePreservingInterpolant</code> - Variance preserving (VP) interpolant with linear beta schedule.</li> </ul>"},{"location":"api/torchebm/interpolants/variance_preserving/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/interpolants/variance_preserving/#torchebm.interpolants.variance_preserving","title":"torchebm.interpolants.variance_preserving","text":"<p>Variance preserving interpolant (DDPM-style schedule).</p>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/","title":"VariancePreservingInterpolant","text":""},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseInterpolant</code></p> <p>Variance preserving (VP) interpolant with linear beta schedule.</p> <p>Corresponds to the noise schedule used in DDPM and score-based diffusion models.</p> <p>The forward process is defined via:</p> \\[ \\alpha(t) = \\exp\\left(-\\frac{1}{4}(1-t)^2(\\sigma_{\\max} - \\sigma_{\\min}) - \\frac{1}{2}(1-t)\\sigma_{\\min}\\right) \\] \\[ \\sigma(t) = \\sqrt{1 - \\alpha(t)^2} \\] <p>Parameters:</p> Name Type Description Default <code>sigma_min</code> <code>float</code> <p>Minimum noise level (default: 0.1).</p> <code>0.1</code> <code>sigma_max</code> <code>float</code> <p>Maximum noise level (default: 20.0).</p> <code>20.0</code> Example <pre><code>from torchebm.interpolants import VariancePreservingInterpolant\nimport torch\n\ninterpolant = VariancePreservingInterpolant(sigma_min=0.1, sigma_max=20.0)\nx0 = torch.randn(32, 2)  # noise\nx1 = torch.randn(32, 2)  # data\nt = torch.rand(32)\nxt, ut = interpolant.interpolate(x0, x1, t)\n</code></pre> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>class VariancePreservingInterpolant(BaseInterpolant):\n    r\"\"\"\n    Variance preserving (VP) interpolant with linear beta schedule.\n\n    Corresponds to the noise schedule used in DDPM and score-based diffusion models.\n\n    The forward process is defined via:\n\n    \\[\n    \\alpha(t) = \\exp\\left(-\\frac{1}{4}(1-t)^2(\\sigma_{\\max} - \\sigma_{\\min}) - \\frac{1}{2}(1-t)\\sigma_{\\min}\\right)\n    \\]\n\n    \\[\n    \\sigma(t) = \\sqrt{1 - \\alpha(t)^2}\n    \\]\n\n    Args:\n        sigma_min: Minimum noise level (default: 0.1).\n        sigma_max: Maximum noise level (default: 20.0).\n\n    Example:\n        ```python\n        from torchebm.interpolants import VariancePreservingInterpolant\n        import torch\n\n        interpolant = VariancePreservingInterpolant(sigma_min=0.1, sigma_max=20.0)\n        x0 = torch.randn(32, 2)  # noise\n        x1 = torch.randn(32, 2)  # data\n        t = torch.rand(32)\n        xt, ut = interpolant.interpolate(x0, x1, t)\n        ```\n    \"\"\"\n\n    def __init__(self, sigma_min: float = 0.1, sigma_max: float = 20.0):\n        self.sigma_min = sigma_min\n        self.sigma_max = sigma_max\n\n    def _log_mean_coeff(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Compute log of mean coefficient.\"\"\"\n        return (\n            -0.25 * ((1 - t) ** 2) * (self.sigma_max - self.sigma_min)\n            - 0.5 * (1 - t) * self.sigma_min\n        )\n\n    def _d_log_mean_coeff(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Compute derivative of log mean coefficient.\"\"\"\n        return 0.5 * (1 - t) * (self.sigma_max - self.sigma_min) + 0.5 * self.sigma_min\n\n    def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\alpha(t)\\) and its derivative for VP schedule.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03b1(t), \u03b1\u0307(t)).\n        \"\"\"\n        lmc = self._log_mean_coeff(t)\n        alpha = torch.exp(lmc)\n        d_alpha = alpha * self._d_log_mean_coeff(t)\n        return alpha, d_alpha\n\n    def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute \\(\\sigma(t)\\) and its derivative for VP schedule.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            Tuple of (\u03c3(t), \u03c3\u0307(t)).\n        \"\"\"\n        p_sigma = 2 * self._log_mean_coeff(t)\n        exp_p = torch.exp(p_sigma)\n        sigma = torch.sqrt(torch.clamp(1 - exp_p, min=1e-12))\n        d_sigma = exp_p * (2 * self._d_log_mean_coeff(t)) / (-2 * sigma)\n        return sigma, d_sigma\n\n    def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute \\(\\dot{\\alpha}(t) / \\alpha(t)\\) directly from log mean coefficient.\n\n        This is more numerically stable than dividing \u03b1\u0307 by \u03b1.\n\n        Args:\n            t: Time tensor.\n\n        Returns:\n            The ratio (which equals d_log_mean_coeff).\n        \"\"\"\n        return self._d_log_mean_coeff(t)\n\n    def compute_drift(\n        self, x: torch.Tensor, t: torch.Tensor\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        r\"\"\"\n        Compute drift for VP schedule using the beta parameterization.\n\n        Args:\n            x: Current state of shape (batch_size, ...).\n            t: Time values of shape (batch_size,).\n\n        Returns:\n            Tuple of (drift_mean, drift_var).\n        \"\"\"\n        t_expanded = expand_t_like_x(t, x)\n        beta_t = self.sigma_min + (1 - t_expanded) * (self.sigma_max - self.sigma_min)\n        return -0.5 * beta_t * x, beta_t / 2\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.sigma_min","title":"sigma_min  <code>instance-attribute</code>","text":"<pre><code>sigma_min = sigma_min\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.sigma_max","title":"sigma_max  <code>instance-attribute</code>","text":"<pre><code>sigma_max = sigma_max\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant._log_mean_coeff","title":"_log_mean_coeff","text":"<pre><code>_log_mean_coeff(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute log of mean coefficient.</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def _log_mean_coeff(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Compute log of mean coefficient.\"\"\"\n    return (\n        -0.25 * ((1 - t) ** 2) * (self.sigma_max - self.sigma_min)\n        - 0.5 * (1 - t) * self.sigma_min\n    )\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant._d_log_mean_coeff","title":"_d_log_mean_coeff","text":"<pre><code>_d_log_mean_coeff(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute derivative of log mean coefficient.</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def _d_log_mean_coeff(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Compute derivative of log mean coefficient.\"\"\"\n    return 0.5 * (1 - t) * (self.sigma_max - self.sigma_min) + 0.5 * self.sigma_min\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.compute_alpha_t","title":"compute_alpha_t","text":"<pre><code>compute_alpha_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\alpha(t)\\) and its derivative for VP schedule.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03b1(t), \u03b1\u0307(t)).</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def compute_alpha_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\alpha(t)\\) and its derivative for VP schedule.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03b1(t), \u03b1\u0307(t)).\n    \"\"\"\n    lmc = self._log_mean_coeff(t)\n    alpha = torch.exp(lmc)\n    d_alpha = alpha * self._d_log_mean_coeff(t)\n    return alpha, d_alpha\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.compute_sigma_t","title":"compute_sigma_t","text":"<pre><code>compute_sigma_t(t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute \\(\\sigma(t)\\) and its derivative for VP schedule.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (\u03c3(t), \u03c3\u0307(t)).</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def compute_sigma_t(self, t: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute \\(\\sigma(t)\\) and its derivative for VP schedule.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        Tuple of (\u03c3(t), \u03c3\u0307(t)).\n    \"\"\"\n    p_sigma = 2 * self._log_mean_coeff(t)\n    exp_p = torch.exp(p_sigma)\n    sigma = torch.sqrt(torch.clamp(1 - exp_p, min=1e-12))\n    d_sigma = exp_p * (2 * self._d_log_mean_coeff(t)) / (-2 * sigma)\n    return sigma, d_sigma\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.compute_d_alpha_alpha_ratio_t","title":"compute_d_alpha_alpha_ratio_t","text":"<pre><code>compute_d_alpha_alpha_ratio_t(t: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute \\(\\dot{\\alpha}(t) / \\alpha(t)\\) directly from log mean coefficient.</p> <p>This is more numerically stable than dividing \u03b1\u0307 by \u03b1.</p> <p>Parameters:</p> Name Type Description Default <code>t</code> <code>Tensor</code> <p>Time tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The ratio (which equals d_log_mean_coeff).</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def compute_d_alpha_alpha_ratio_t(self, t: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute \\(\\dot{\\alpha}(t) / \\alpha(t)\\) directly from log mean coefficient.\n\n    This is more numerically stable than dividing \u03b1\u0307 by \u03b1.\n\n    Args:\n        t: Time tensor.\n\n    Returns:\n        The ratio (which equals d_log_mean_coeff).\n    \"\"\"\n    return self._d_log_mean_coeff(t)\n</code></pre>"},{"location":"api/torchebm/interpolants/variance_preserving/classes/VariancePreservingInterpolant/#torchebm.interpolants.variance_preserving.VariancePreservingInterpolant.compute_drift","title":"compute_drift","text":"<pre><code>compute_drift(x: Tensor, t: Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Compute drift for VP schedule using the beta parameterization.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Current state of shape (batch_size, ...).</p> required <code>t</code> <code>Tensor</code> <p>Time values of shape (batch_size,).</p> required <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple of (drift_mean, drift_var).</p> Source code in <code>torchebm/interpolants/variance_preserving.py</code> <pre><code>def compute_drift(\n    self, x: torch.Tensor, t: torch.Tensor\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    r\"\"\"\n    Compute drift for VP schedule using the beta parameterization.\n\n    Args:\n        x: Current state of shape (batch_size, ...).\n        t: Time values of shape (batch_size,).\n\n    Returns:\n        Tuple of (drift_mean, drift_var).\n    \"\"\"\n    t_expanded = expand_t_like_x(t, x)\n    beta_t = self.sigma_min + (1 - t_expanded) * (self.sigma_max - self.sigma_min)\n    return -0.5 * beta_t * x, beta_t / 2\n</code></pre>"},{"location":"api/torchebm/losses/","title":"Torchebm &gt; Losses","text":""},{"location":"api/torchebm/losses/#torchebm-losses","title":"Torchebm &gt; Losses","text":""},{"location":"api/torchebm/losses/#contents","title":"Contents","text":""},{"location":"api/torchebm/losses/#modules","title":"Modules","text":"<ul> <li>Contrastive_divergence</li> <li>Equilibrium_matching</li> <li>Loss_utils</li> <li>Score_matching</li> </ul>"},{"location":"api/torchebm/losses/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/losses/#torchebm.losses","title":"torchebm.losses","text":"<p>Loss functions for training energy-based models and generative models.</p>"},{"location":"api/torchebm/losses/contrastive_divergence/","title":"Torchebm &gt; Losses &gt; Contrastive_divergence","text":""},{"location":"api/torchebm/losses/contrastive_divergence/#torchebm-losses-contrastive_divergence","title":"Torchebm &gt; Losses &gt; Contrastive_divergence","text":""},{"location":"api/torchebm/losses/contrastive_divergence/#contents","title":"Contents","text":""},{"location":"api/torchebm/losses/contrastive_divergence/#classes","title":"Classes","text":"<ul> <li><code>ContrastiveDivergence</code> - Standard Contrastive Divergence (CD-k) loss.</li> <li><code>ParallelTemperingCD</code> - No description available.</li> <li><code>PersistentContrastiveDivergence</code> - No description available.</li> </ul>"},{"location":"api/torchebm/losses/contrastive_divergence/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/losses/contrastive_divergence/#torchebm.losses.contrastive_divergence","title":"torchebm.losses.contrastive_divergence","text":"<p>Contrastive Divergence Loss Module.</p>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/","title":"ContrastiveDivergence","text":""},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseContrastiveDivergence</code></p> <p>Standard Contrastive Divergence (CD-k) loss.</p> <p>CD approximates the log-likelihood gradient by running an MCMC sampler for <code>k_steps</code> to generate negative samples.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <p>The energy-based model to train.</p> required <code>sampler</code> <p>The MCMC sampler for generating negative samples.</p> required <code>k_steps</code> <p>The number of MCMC steps (k in CD-k).</p> <code>10</code> <code>persistent</code> <p>If True, uses Persistent CD with a replay buffer.</p> <code>False</code> <code>buffer_size</code> <p>Size of the replay buffer for PCD.</p> <code>10000</code> <code>init_steps</code> <p>Number of MCMC steps to warm up the buffer.</p> <code>100</code> <code>new_sample_ratio</code> <p>Fraction of new random samples for PCD chains.</p> <code>0.05</code> <code>energy_reg_weight</code> <p>Weight for energy regularization term.</p> <code>0.001</code> <code>use_temperature_annealing</code> <p>Whether to use temperature annealing.</p> <code>False</code> <code>min_temp</code> <p>Minimum temperature for annealing.</p> <code>0.01</code> <code>max_temp</code> <p>Maximum temperature for annealing.</p> <code>2.0</code> <code>temp_decay</code> <p>Decay rate for temperature annealing.</p> <code>0.999</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <p>Device for computations.</p> <code>device('cpu')</code> Example <pre><code>from torchebm.losses import ContrastiveDivergence\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.core import DoubleWellEnergy\n\nenergy = DoubleWellEnergy()\nsampler = LangevinDynamics(energy, step_size=0.01)\ncd_loss = ContrastiveDivergence(model=energy, sampler=sampler, k_steps=10)\nx = torch.randn(32, 2)\nloss, neg_samples = cd_loss(x)\n</code></pre> Source code in <code>torchebm/losses/contrastive_divergence.py</code> <pre><code>class ContrastiveDivergence(BaseContrastiveDivergence):\n    r\"\"\"\n    Standard Contrastive Divergence (CD-k) loss.\n\n    CD approximates the log-likelihood gradient by running an MCMC sampler\n    for `k_steps` to generate negative samples.\n\n    Args:\n        model: The energy-based model to train.\n        sampler: The MCMC sampler for generating negative samples.\n        k_steps: The number of MCMC steps (k in CD-k).\n        persistent: If True, uses Persistent CD with a replay buffer.\n        buffer_size: Size of the replay buffer for PCD.\n        init_steps: Number of MCMC steps to warm up the buffer.\n        new_sample_ratio: Fraction of new random samples for PCD chains.\n        energy_reg_weight: Weight for energy regularization term.\n        use_temperature_annealing: Whether to use temperature annealing.\n        min_temp: Minimum temperature for annealing.\n        max_temp: Maximum temperature for annealing.\n        temp_decay: Decay rate for temperature annealing.\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.losses import ContrastiveDivergence\n        from torchebm.samplers import LangevinDynamics\n        from torchebm.core import DoubleWellEnergy\n\n        energy = DoubleWellEnergy()\n        sampler = LangevinDynamics(energy, step_size=0.01)\n        cd_loss = ContrastiveDivergence(model=energy, sampler=sampler, k_steps=10)\n        x = torch.randn(32, 2)\n        loss, neg_samples = cd_loss(x)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model,\n        sampler,\n        k_steps=10,\n        persistent=False,\n        buffer_size=10000,\n        init_steps=100,\n        new_sample_ratio=0.05,\n        energy_reg_weight=0.001,\n        use_temperature_annealing=False,\n        min_temp=0.01,\n        max_temp=2.0,\n        temp_decay=0.999,\n        dtype=torch.float32,\n        device=torch.device(\"cpu\"),\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            sampler=sampler,\n            k_steps=k_steps,\n            persistent=persistent,\n            buffer_size=buffer_size,\n            new_sample_ratio=new_sample_ratio,\n            init_steps=init_steps,\n            dtype=dtype,\n            device=device,\n            *args,\n            **kwargs,\n        )\n        # Additional parameters for improved stability\n        self.energy_reg_weight = energy_reg_weight\n        self.use_temperature_annealing = use_temperature_annealing\n        self.min_temp = min_temp\n        self.max_temp = max_temp\n        self.temp_decay = temp_decay\n        self.current_temp = max_temp\n\n        # Register temperature as buffer for persistence\n        self.register_buffer(\n            \"temperature\", torch.tensor(max_temp, dtype=self.dtype, device=self.device)\n        )\n\n    def forward(\n        self, x: torch.Tensor, *args, **kwargs\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Computes the Contrastive Divergence loss and generates negative samples.\n\n        Args:\n            x (torch.Tensor): A batch of real data samples (positive samples).\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            Tuple[torch.Tensor, torch.Tensor]:\n                - The scalar CD loss value.\n                - The generated negative samples.\n        \"\"\"\n\n        batch_size = x.shape[0]\n        data_shape = x.shape[1:]\n\n        # Update temperature if annealing is enabled\n        if self.use_temperature_annealing and self.training:\n            self.current_temp = max(self.min_temp, self.current_temp * self.temp_decay)\n            self.temperature[...] = self.current_temp  # Use ellipsis instead of index\n\n            # If sampler has a temperature parameter, update it\n            if hasattr(self.sampler, \"temperature\"):\n                self.sampler.temperature = self.current_temp\n            elif hasattr(self.sampler, \"noise_scale\"):\n                # For samplers like Langevin, adjust noise scale based on temperature\n                original_noise = getattr(self.sampler, \"_original_noise_scale\", None)\n                if original_noise is None:\n                    setattr(\n                        self.sampler, \"_original_noise_scale\", self.sampler.noise_scale\n                    )\n                    original_noise = self.sampler.noise_scale\n\n                self.sampler.noise_scale = original_noise * math.sqrt(self.current_temp)\n\n        # Get starting points for chains (either from buffer or data)\n        start_points = self.get_start_points(x)\n\n        # Run MCMC chains to get negative samples\n        pred_samples = self.sampler.sample(\n            x=start_points,\n            n_steps=self.k_steps,\n        )\n\n        # Update persistent buffer if using PCD\n        if self.persistent:\n            with torch.no_grad():\n                self.update_buffer(pred_samples.detach())\n\n        # Add energy regularization to kwargs for compute_loss\n        kwargs[\"energy_reg_weight\"] = kwargs.get(\n            \"energy_reg_weight\", self.energy_reg_weight\n        )\n\n        # Compute contrastive divergence loss\n        loss = self.compute_loss(x, pred_samples, *args, **kwargs)\n\n        return loss, pred_samples\n\n    def compute_loss(\n        self, x: torch.Tensor, pred_x: torch.Tensor, *args, **kwargs\n    ) -&gt; torch.Tensor:\n        \"\"\"\n        Computes the Contrastive Divergence loss from positive and negative samples.\n\n        The loss is the difference between the mean energy of positive samples\n        and the mean energy of negative samples.\n\n        Args:\n            x (torch.Tensor): Real data samples (positive samples).\n            pred_x (torch.Tensor): Generated negative samples.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar loss value.\n        \"\"\"\n        # Ensure inputs are on the correct device and dtype\n        x = x.to(self.device, self.dtype)\n        pred_x = pred_x.to(self.device, self.dtype)\n\n        # Compute energy of real and generated samples\n        with torch.set_grad_enabled(True):\n            # Add small noise to real data for stability (optional)\n            if kwargs.get(\"add_noise_to_real\", False):\n                noise_scale = kwargs.get(\"noise_scale\", 1e-4)\n                x_noisy = x + noise_scale * torch.randn_like(x)\n                x_energy = self.model(x_noisy)\n            else:\n                x_energy = self.model(x)\n\n            pred_x_energy = self.model(pred_x)\n\n        # Compute mean energies with improved numerical stability\n        mean_x_energy = torch.mean(x_energy)\n        mean_pred_energy = torch.mean(pred_x_energy)\n\n        # Basic contrastive divergence loss: E[data] - E[model]\n        loss = mean_x_energy - mean_pred_energy\n\n        # Optional: Regularization to prevent energies from becoming too large\n        # This helps with stability especially in the early phases of training\n        energy_reg_weight = kwargs.get(\"energy_reg_weight\", 0.001)\n        if energy_reg_weight &gt; 0:\n            energy_reg = energy_reg_weight * (\n                torch.mean(x_energy**2) + torch.mean(pred_x_energy**2)\n            )\n            loss = loss + energy_reg\n\n        # Prevent extremely large gradients with a safety check\n        if torch.isnan(loss) or torch.isinf(loss):\n            warnings.warn(\n                f\"NaN or Inf detected in CD loss. x_energy: {mean_x_energy}, pred_energy: {mean_pred_energy}\",\n                RuntimeWarning,\n            )\n            # Return a small positive constant instead of NaN/Inf to prevent training collapse\n            return torch.tensor(0.1, device=self.device, dtype=self.dtype)\n\n        return loss\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.energy_reg_weight","title":"energy_reg_weight  <code>instance-attribute</code>","text":"<pre><code>energy_reg_weight = energy_reg_weight\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.use_temperature_annealing","title":"use_temperature_annealing  <code>instance-attribute</code>","text":"<pre><code>use_temperature_annealing = use_temperature_annealing\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.min_temp","title":"min_temp  <code>instance-attribute</code>","text":"<pre><code>min_temp = min_temp\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.max_temp","title":"max_temp  <code>instance-attribute</code>","text":"<pre><code>max_temp = max_temp\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.temp_decay","title":"temp_decay  <code>instance-attribute</code>","text":"<pre><code>temp_decay = temp_decay\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.current_temp","title":"current_temp  <code>instance-attribute</code>","text":"<pre><code>current_temp = max_temp\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.forward","title":"forward","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Computes the Contrastive Divergence loss and generates negative samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>A batch of real data samples (positive samples).</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[Tensor, Tensor]</code> <p>Tuple[torch.Tensor, torch.Tensor]: - The scalar CD loss value. - The generated negative samples.</p> Source code in <code>torchebm/losses/contrastive_divergence.py</code> <pre><code>def forward(\n    self, x: torch.Tensor, *args, **kwargs\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Computes the Contrastive Divergence loss and generates negative samples.\n\n    Args:\n        x (torch.Tensor): A batch of real data samples (positive samples).\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        Tuple[torch.Tensor, torch.Tensor]:\n            - The scalar CD loss value.\n            - The generated negative samples.\n    \"\"\"\n\n    batch_size = x.shape[0]\n    data_shape = x.shape[1:]\n\n    # Update temperature if annealing is enabled\n    if self.use_temperature_annealing and self.training:\n        self.current_temp = max(self.min_temp, self.current_temp * self.temp_decay)\n        self.temperature[...] = self.current_temp  # Use ellipsis instead of index\n\n        # If sampler has a temperature parameter, update it\n        if hasattr(self.sampler, \"temperature\"):\n            self.sampler.temperature = self.current_temp\n        elif hasattr(self.sampler, \"noise_scale\"):\n            # For samplers like Langevin, adjust noise scale based on temperature\n            original_noise = getattr(self.sampler, \"_original_noise_scale\", None)\n            if original_noise is None:\n                setattr(\n                    self.sampler, \"_original_noise_scale\", self.sampler.noise_scale\n                )\n                original_noise = self.sampler.noise_scale\n\n            self.sampler.noise_scale = original_noise * math.sqrt(self.current_temp)\n\n    # Get starting points for chains (either from buffer or data)\n    start_points = self.get_start_points(x)\n\n    # Run MCMC chains to get negative samples\n    pred_samples = self.sampler.sample(\n        x=start_points,\n        n_steps=self.k_steps,\n    )\n\n    # Update persistent buffer if using PCD\n    if self.persistent:\n        with torch.no_grad():\n            self.update_buffer(pred_samples.detach())\n\n    # Add energy regularization to kwargs for compute_loss\n    kwargs[\"energy_reg_weight\"] = kwargs.get(\n        \"energy_reg_weight\", self.energy_reg_weight\n    )\n\n    # Compute contrastive divergence loss\n    loss = self.compute_loss(x, pred_samples, *args, **kwargs)\n\n    return loss, pred_samples\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ContrastiveDivergence/#torchebm.losses.contrastive_divergence.ContrastiveDivergence.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(x: Tensor, pred_x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the Contrastive Divergence loss from positive and negative samples.</p> <p>The loss is the difference between the mean energy of positive samples and the mean energy of negative samples.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Real data samples (positive samples).</p> required <code>pred_x</code> <code>Tensor</code> <p>Generated negative samples.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar loss value.</p> Source code in <code>torchebm/losses/contrastive_divergence.py</code> <pre><code>def compute_loss(\n    self, x: torch.Tensor, pred_x: torch.Tensor, *args, **kwargs\n) -&gt; torch.Tensor:\n    \"\"\"\n    Computes the Contrastive Divergence loss from positive and negative samples.\n\n    The loss is the difference between the mean energy of positive samples\n    and the mean energy of negative samples.\n\n    Args:\n        x (torch.Tensor): Real data samples (positive samples).\n        pred_x (torch.Tensor): Generated negative samples.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar loss value.\n    \"\"\"\n    # Ensure inputs are on the correct device and dtype\n    x = x.to(self.device, self.dtype)\n    pred_x = pred_x.to(self.device, self.dtype)\n\n    # Compute energy of real and generated samples\n    with torch.set_grad_enabled(True):\n        # Add small noise to real data for stability (optional)\n        if kwargs.get(\"add_noise_to_real\", False):\n            noise_scale = kwargs.get(\"noise_scale\", 1e-4)\n            x_noisy = x + noise_scale * torch.randn_like(x)\n            x_energy = self.model(x_noisy)\n        else:\n            x_energy = self.model(x)\n\n        pred_x_energy = self.model(pred_x)\n\n    # Compute mean energies with improved numerical stability\n    mean_x_energy = torch.mean(x_energy)\n    mean_pred_energy = torch.mean(pred_x_energy)\n\n    # Basic contrastive divergence loss: E[data] - E[model]\n    loss = mean_x_energy - mean_pred_energy\n\n    # Optional: Regularization to prevent energies from becoming too large\n    # This helps with stability especially in the early phases of training\n    energy_reg_weight = kwargs.get(\"energy_reg_weight\", 0.001)\n    if energy_reg_weight &gt; 0:\n        energy_reg = energy_reg_weight * (\n            torch.mean(x_energy**2) + torch.mean(pred_x_energy**2)\n        )\n        loss = loss + energy_reg\n\n    # Prevent extremely large gradients with a safety check\n    if torch.isnan(loss) or torch.isinf(loss):\n        warnings.warn(\n            f\"NaN or Inf detected in CD loss. x_energy: {mean_x_energy}, pred_energy: {mean_pred_energy}\",\n            RuntimeWarning,\n        )\n        # Return a small positive constant instead of NaN/Inf to prevent training collapse\n        return torch.tensor(0.1, device=self.device, dtype=self.dtype)\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ParallelTemperingCD/","title":"ParallelTemperingCD","text":""},{"location":"api/torchebm/losses/contrastive_divergence/classes/ParallelTemperingCD/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseContrastiveDivergence</code></p> Source code in <code>torchebm/losses/contrastive_divergence.py</code> <pre><code>class ParallelTemperingCD(BaseContrastiveDivergence):\n    def __init__(self, temps=[1.0, 0.5], k=5):\n        super().__init__(k)\n        self.temps = temps  # List of temperatures\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/ParallelTemperingCD/#torchebm.losses.contrastive_divergence.ParallelTemperingCD.temps","title":"temps  <code>instance-attribute</code>","text":"<pre><code>temps = temps\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/PersistentContrastiveDivergence/","title":"PersistentContrastiveDivergence","text":""},{"location":"api/torchebm/losses/contrastive_divergence/classes/PersistentContrastiveDivergence/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseContrastiveDivergence</code></p> Source code in <code>torchebm/losses/contrastive_divergence.py</code> <pre><code>class PersistentContrastiveDivergence(BaseContrastiveDivergence):\n    def __init__(self, buffer_size=100):\n        super().__init__(k_steps=1)\n        self.buffer = None  # Persistent chain state\n        self.buffer_size = buffer_size\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/PersistentContrastiveDivergence/#torchebm.losses.contrastive_divergence.PersistentContrastiveDivergence.buffer","title":"buffer  <code>instance-attribute</code>","text":"<pre><code>buffer = None\n</code></pre>"},{"location":"api/torchebm/losses/contrastive_divergence/classes/PersistentContrastiveDivergence/#torchebm.losses.contrastive_divergence.PersistentContrastiveDivergence.buffer_size","title":"buffer_size  <code>instance-attribute</code>","text":"<pre><code>buffer_size = buffer_size\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/","title":"Torchebm &gt; Losses &gt; Equilibrium_matching","text":""},{"location":"api/torchebm/losses/equilibrium_matching/#torchebm-losses-equilibrium_matching","title":"Torchebm &gt; Losses &gt; Equilibrium_matching","text":""},{"location":"api/torchebm/losses/equilibrium_matching/#contents","title":"Contents","text":""},{"location":"api/torchebm/losses/equilibrium_matching/#classes","title":"Classes","text":"<ul> <li><code>EquilibriumMatchingLoss</code> - Equilibrium Matching (EqM) training loss.</li> </ul>"},{"location":"api/torchebm/losses/equilibrium_matching/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/losses/equilibrium_matching/#torchebm.losses.equilibrium_matching","title":"torchebm.losses.equilibrium_matching","text":"<p>Equilibrium Matching (EqM) loss.</p> <p>Implements equilibrium training objective that matches a time-invariant velocity/score/noise target along a coupling path between x0~N(0,I) and x1~data.</p>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/","title":"EquilibriumMatchingLoss","text":""},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseLoss</code></p> <p>Equilibrium Matching (EqM) training loss.</p> <p>Implements the flow matching objective with optional dispersive regularization for training generative models on unnormalized densities.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Neural network predicting velocity/score/noise.</p> required <code>prediction</code> <code>Literal['velocity', 'score', 'noise']</code> <p>Network prediction type ('velocity', 'score', or 'noise').</p> <code>'velocity'</code> <code>interpolant</code> <code>Literal['linear', 'cosine', 'vp']</code> <p>Interpolant type ('linear', 'cosine', or 'vp').</p> <code>'linear'</code> <code>loss_weight</code> <code>Optional[Literal['velocity', 'likelihood']]</code> <p>Loss weighting scheme ('velocity', 'likelihood', or None).</p> <code>None</code> <code>train_eps</code> <code>float</code> <p>Epsilon for training time interval stability.</p> <code>0.0</code> <code>apply_dispersion</code> <code>bool</code> <p>Whether to apply dispersive regularization.</p> <code>False</code> <code>dispersion_weight</code> <code>float</code> <p>Weight for dispersive loss term.</p> <code>0.5</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision.</p> <code>False</code> <code>clip_value</code> <code>Optional[float]</code> <p>Optional value to clamp the loss.</p> <code>None</code> Example <pre><code>from torchebm.losses import EquilibriumMatchingLoss\nimport torch.nn as nn\nimport torch\n\nmodel = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 2))\nloss_fn = EquilibriumMatchingLoss(\n    model=model,\n    prediction=\"velocity\",\n    interpolant=\"linear\",\n)\nx = torch.randn(32, 2)\nloss = loss_fn(x)\n</code></pre> Source code in <code>torchebm/losses/equilibrium_matching.py</code> <pre><code>class EquilibriumMatchingLoss(BaseLoss):\n    r\"\"\"\n    Equilibrium Matching (EqM) training loss.\n\n    Implements the flow matching objective with optional dispersive regularization\n    for training generative models on unnormalized densities.\n\n    Args:\n        model: Neural network predicting velocity/score/noise.\n        prediction: Network prediction type ('velocity', 'score', or 'noise').\n        interpolant: Interpolant type ('linear', 'cosine', or 'vp').\n        loss_weight: Loss weighting scheme ('velocity', 'likelihood', or None).\n        train_eps: Epsilon for training time interval stability.\n        apply_dispersion: Whether to apply dispersive regularization.\n        dispersion_weight: Weight for dispersive loss term.\n        dtype: Data type for computations.\n        device: Device for computations.\n        use_mixed_precision: Whether to use mixed precision.\n        clip_value: Optional value to clamp the loss.\n\n    Example:\n        ```python\n        from torchebm.losses import EquilibriumMatchingLoss\n        import torch.nn as nn\n        import torch\n\n        model = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 2))\n        loss_fn = EquilibriumMatchingLoss(\n            model=model,\n            prediction=\"velocity\",\n            interpolant=\"linear\",\n        )\n        x = torch.randn(32, 2)\n        loss = loss_fn(x)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: nn.Module,\n        prediction: Literal[\"velocity\", \"score\", \"noise\"] = \"velocity\",\n        interpolant: Literal[\"linear\", \"cosine\", \"vp\"] = \"linear\",\n        loss_weight: Optional[Literal[\"velocity\", \"likelihood\"]] = None,\n        train_eps: float = 0.0,\n        apply_dispersion: bool = False,\n        dispersion_weight: float = 0.5,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        clip_value: Optional[float] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n            clip_value=clip_value,\n            *args,\n            **kwargs,\n        )\n        self.model = model.to(device=self.device, dtype=self.dtype)\n        self.prediction = prediction\n        self.loss_weight = loss_weight\n        self.train_eps = train_eps\n        self.apply_dispersion = apply_dispersion\n        self.dispersion_weight = dispersion_weight\n        self.interpolant = get_interpolant(interpolant)\n\n    def _check_interval(self) -&gt; tuple[float, float]:\n        r\"\"\"Get training time interval respecting epsilon.\"\"\"\n        t0 = self.train_eps\n        t1 = 1.0 - self.train_eps\n        return t0, t1\n\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute EqM loss (nn.Module interface).\n\n        Args:\n            x: Data samples of shape (batch_size, ...).\n            *args: Additional positional arguments.\n            **kwargs: Additional model arguments.\n\n        Returns:\n            Scalar loss value.\n        \"\"\"\n        if (x.device != self.device) or (x.dtype != self.dtype):\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            loss = self.compute_loss(x, *args, **kwargs)\n\n        return loss\n\n    def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Compute the equilibrium matching loss.\n\n        Args:\n            x: Data samples of shape (batch_size, ...).\n            *args: Additional positional arguments.\n            **kwargs: Additional model arguments passed to the network.\n\n        Returns:\n            Scalar loss value.\n        \"\"\"\n        terms = self.training_losses(x, model_kwargs=kwargs)\n        return terms[\"loss\"].mean()\n\n    def training_losses(\n        self,\n        x1: torch.Tensor,\n        model_kwargs: Optional[Dict[str, Any]] = None,\n    ) -&gt; Dict[str, torch.Tensor]:\n        r\"\"\"\n        Compute training losses with detailed outputs.\n\n        This method provides the full loss dictionary including predictions,\n        useful for logging and debugging.\n\n        Args:\n            x1: Data samples of shape (batch_size, ...).\n            model_kwargs: Additional model arguments.\n\n        Returns:\n            Dictionary with 'loss' (per-sample) and 'pred' tensors.\n        \"\"\"\n        if model_kwargs is None:\n            model_kwargs = {}\n\n        x1 = x1.to(device=self.device, dtype=self.dtype)\n        batch = x1.shape[0]\n\n        x0 = torch.randn_like(x1)\n        t0, t1 = self._check_interval()\n        t = torch.rand(batch, device=self.device, dtype=self.dtype) * (t1 - t0) + t0\n\n        xt, ut = self.interpolant.interpolate(x0, x1, t)\n\n        # Apply energy-compatible target scaling\n        ct = compute_eqm_ct(t)\n        ct = ct.view(batch, *([1] * (xt.ndim - 1)))\n        ut = ut * ct\n\n        with self.autocast_context():\n            model_output = self.model(xt, t, **model_kwargs)\n\n        if isinstance(model_output, tuple):\n            model_output, act = model_output\n        else:\n            act = []\n\n        disp_loss = 0.0\n        if self.apply_dispersion and len(act) &gt; 0:\n             if isinstance(act, list):\n                disp_loss = dispersive_loss(act[-1])\n             else:\n                 # Handle case where act might be a single tensor\n                 disp_loss = dispersive_loss(act)\n\n        terms = {\"pred\": model_output}\n\n        if self.prediction == \"velocity\":\n            terms[\"loss\"] = mean_flat((model_output - ut) ** 2)\n        else:\n            t_expanded = expand_t_like_x(t, xt)\n            _, drift_var = self.interpolant.compute_drift(xt, t)\n            sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n\n            if self.loss_weight == \"velocity\":\n                weight = (drift_var / sigma_t) ** 2\n            elif self.loss_weight == \"likelihood\":\n                weight = drift_var / (sigma_t**2)\n            else:\n                weight = 1.0\n\n            if self.prediction == \"noise\":\n                terms[\"loss\"] = mean_flat(weight * (model_output - x0) ** 2)\n            elif self.prediction == \"score\":\n                terms[\"loss\"] = mean_flat(weight * (model_output * sigma_t + x0) ** 2)\n            else:\n                raise ValueError(f\"Unknown prediction type: {self.prediction}\")\n\n        # Add dispersive regularization\n        if self.apply_dispersion:\n            terms[\"loss\"] = terms[\"loss\"] + self.dispersion_weight * disp_loss\n\n        return terms\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"{self.__class__.__name__}(\"\n            f\"prediction={self.prediction!r}, \"\n            f\"interpolant={type(self.interpolant).__name__})\"\n        )\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = to(device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.prediction","title":"prediction  <code>instance-attribute</code>","text":"<pre><code>prediction = prediction\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.loss_weight","title":"loss_weight  <code>instance-attribute</code>","text":"<pre><code>loss_weight = loss_weight\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.train_eps","title":"train_eps  <code>instance-attribute</code>","text":"<pre><code>train_eps = train_eps\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.apply_dispersion","title":"apply_dispersion  <code>instance-attribute</code>","text":"<pre><code>apply_dispersion = apply_dispersion\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.dispersion_weight","title":"dispersion_weight  <code>instance-attribute</code>","text":"<pre><code>dispersion_weight = dispersion_weight\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.interpolant","title":"interpolant  <code>instance-attribute</code>","text":"<pre><code>interpolant = get_interpolant(interpolant)\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss._check_interval","title":"_check_interval","text":"<pre><code>_check_interval() -&gt; tuple[float, float]\n</code></pre> <p>Get training time interval respecting epsilon.</p> Source code in <code>torchebm/losses/equilibrium_matching.py</code> <pre><code>def _check_interval(self) -&gt; tuple[float, float]:\n    r\"\"\"Get training time interval respecting epsilon.\"\"\"\n    t0 = self.train_eps\n    t1 = 1.0 - self.train_eps\n    return t0, t1\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.forward","title":"forward","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Compute EqM loss (nn.Module interface).</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Data samples of shape (batch_size, ...).</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional model arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Scalar loss value.</p> Source code in <code>torchebm/losses/equilibrium_matching.py</code> <pre><code>def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute EqM loss (nn.Module interface).\n\n    Args:\n        x: Data samples of shape (batch_size, ...).\n        *args: Additional positional arguments.\n        **kwargs: Additional model arguments.\n\n    Returns:\n        Scalar loss value.\n    \"\"\"\n    if (x.device != self.device) or (x.dtype != self.dtype):\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    with self.autocast_context():\n        loss = self.compute_loss(x, *args, **kwargs)\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Compute the equilibrium matching loss.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Data samples of shape (batch_size, ...).</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional model arguments passed to the network.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Scalar loss value.</p> Source code in <code>torchebm/losses/equilibrium_matching.py</code> <pre><code>def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Compute the equilibrium matching loss.\n\n    Args:\n        x: Data samples of shape (batch_size, ...).\n        *args: Additional positional arguments.\n        **kwargs: Additional model arguments passed to the network.\n\n    Returns:\n        Scalar loss value.\n    \"\"\"\n    terms = self.training_losses(x, model_kwargs=kwargs)\n    return terms[\"loss\"].mean()\n</code></pre>"},{"location":"api/torchebm/losses/equilibrium_matching/classes/EquilibriumMatchingLoss/#torchebm.losses.equilibrium_matching.EquilibriumMatchingLoss.training_losses","title":"training_losses","text":"<pre><code>training_losses(x1: Tensor, model_kwargs: Optional[Dict[str, Any]] = None) -&gt; Dict[str, torch.Tensor]\n</code></pre> <p>Compute training losses with detailed outputs.</p> <p>This method provides the full loss dictionary including predictions, useful for logging and debugging.</p> <p>Parameters:</p> Name Type Description Default <code>x1</code> <code>Tensor</code> <p>Data samples of shape (batch_size, ...).</p> required <code>model_kwargs</code> <code>Optional[Dict[str, Any]]</code> <p>Additional model arguments.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, Tensor]</code> <p>Dictionary with 'loss' (per-sample) and 'pred' tensors.</p> Source code in <code>torchebm/losses/equilibrium_matching.py</code> <pre><code>def training_losses(\n    self,\n    x1: torch.Tensor,\n    model_kwargs: Optional[Dict[str, Any]] = None,\n) -&gt; Dict[str, torch.Tensor]:\n    r\"\"\"\n    Compute training losses with detailed outputs.\n\n    This method provides the full loss dictionary including predictions,\n    useful for logging and debugging.\n\n    Args:\n        x1: Data samples of shape (batch_size, ...).\n        model_kwargs: Additional model arguments.\n\n    Returns:\n        Dictionary with 'loss' (per-sample) and 'pred' tensors.\n    \"\"\"\n    if model_kwargs is None:\n        model_kwargs = {}\n\n    x1 = x1.to(device=self.device, dtype=self.dtype)\n    batch = x1.shape[0]\n\n    x0 = torch.randn_like(x1)\n    t0, t1 = self._check_interval()\n    t = torch.rand(batch, device=self.device, dtype=self.dtype) * (t1 - t0) + t0\n\n    xt, ut = self.interpolant.interpolate(x0, x1, t)\n\n    # Apply energy-compatible target scaling\n    ct = compute_eqm_ct(t)\n    ct = ct.view(batch, *([1] * (xt.ndim - 1)))\n    ut = ut * ct\n\n    with self.autocast_context():\n        model_output = self.model(xt, t, **model_kwargs)\n\n    if isinstance(model_output, tuple):\n        model_output, act = model_output\n    else:\n        act = []\n\n    disp_loss = 0.0\n    if self.apply_dispersion and len(act) &gt; 0:\n         if isinstance(act, list):\n            disp_loss = dispersive_loss(act[-1])\n         else:\n             # Handle case where act might be a single tensor\n             disp_loss = dispersive_loss(act)\n\n    terms = {\"pred\": model_output}\n\n    if self.prediction == \"velocity\":\n        terms[\"loss\"] = mean_flat((model_output - ut) ** 2)\n    else:\n        t_expanded = expand_t_like_x(t, xt)\n        _, drift_var = self.interpolant.compute_drift(xt, t)\n        sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n\n        if self.loss_weight == \"velocity\":\n            weight = (drift_var / sigma_t) ** 2\n        elif self.loss_weight == \"likelihood\":\n            weight = drift_var / (sigma_t**2)\n        else:\n            weight = 1.0\n\n        if self.prediction == \"noise\":\n            terms[\"loss\"] = mean_flat(weight * (model_output - x0) ** 2)\n        elif self.prediction == \"score\":\n            terms[\"loss\"] = mean_flat(weight * (model_output * sigma_t + x0) ** 2)\n        else:\n            raise ValueError(f\"Unknown prediction type: {self.prediction}\")\n\n    # Add dispersive regularization\n    if self.apply_dispersion:\n        terms[\"loss\"] = terms[\"loss\"] + self.dispersion_weight * disp_loss\n\n    return terms\n</code></pre>"},{"location":"api/torchebm/losses/loss_utils/","title":"Loss_utils","text":""},{"location":"api/torchebm/losses/loss_utils/#torchebm-losses-loss_utils","title":"Torchebm &gt; Losses &gt; Loss_utils","text":""},{"location":"api/torchebm/losses/loss_utils/#contents","title":"Contents","text":""},{"location":"api/torchebm/losses/loss_utils/#functions","title":"Functions","text":"<ul> <li><code>compute_eqm_ct()</code> - Energy-compatible target scaling c(t) used in EqM.</li> <li><code>dispersive_loss()</code> - Dispersive loss (InfoNCE-L2 variant) for regularization.</li> <li><code>get_interpolant()</code> - Get interpolant instance by name.</li> <li><code>mean_flat()</code> - Take mean over all non-batch dimensions.</li> </ul>"},{"location":"api/torchebm/losses/loss_utils/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/losses/loss_utils/#torchebm.losses.loss_utils","title":"torchebm.losses.loss_utils","text":"<p>Utility functions for loss computations.</p>"},{"location":"api/torchebm/losses/score_matching/","title":"Torchebm &gt; Losses &gt; Score_matching","text":""},{"location":"api/torchebm/losses/score_matching/#torchebm-losses-score_matching","title":"Torchebm &gt; Losses &gt; Score_matching","text":""},{"location":"api/torchebm/losses/score_matching/#contents","title":"Contents","text":""},{"location":"api/torchebm/losses/score_matching/#classes","title":"Classes","text":"<ul> <li><code>DenoisingScoreMatching</code> - Denoising Score Matching (DSM) from Vincent (2011).</li> <li><code>ScoreMatching</code> - Original Score Matching loss from Hyv\u00e4rinen (2005).</li> <li><code>SlicedScoreMatching</code> - Sliced Score Matching (SSM) from Song et al. (2019).</li> </ul>"},{"location":"api/torchebm/losses/score_matching/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/losses/score_matching/#torchebm.losses.score_matching","title":"torchebm.losses.score_matching","text":"<p>Score Matching Loss Module</p>"},{"location":"api/torchebm/losses/score_matching/classes/DenoisingScoreMatching/","title":"DenoisingScoreMatching","text":""},{"location":"api/torchebm/losses/score_matching/classes/DenoisingScoreMatching/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScoreMatching</code></p> <p>Denoising Score Matching (DSM) from Vincent (2011).</p> <p>Avoids computing the Hessian trace by matching the score of noise-perturbed data. More computationally efficient and often more stable than standard Score Matching.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The energy-based model to train.</p> required <code>noise_scale</code> <code>float</code> <p>Standard deviation of Gaussian noise to add.</p> <code>0.01</code> <code>regularization_strength</code> <code>float</code> <p>Coefficient for regularization.</p> <code>0.0</code> <code>custom_regularization</code> <code>Optional[Callable]</code> <p>A custom regularization function.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed-precision training.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> Example <pre><code>from torchebm.losses import DenoisingScoreMatching\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nloss_fn = DenoisingScoreMatching(model=energy, noise_scale=0.1)\nx = torch.randn(32, 2)\nloss = loss_fn(x)\n</code></pre> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>class DenoisingScoreMatching(BaseScoreMatching):\n    r\"\"\"\n    Denoising Score Matching (DSM) from Vincent (2011).\n\n    Avoids computing the Hessian trace by matching the score of noise-perturbed\n    data. More computationally efficient and often more stable than standard\n    Score Matching.\n\n    Args:\n        model: The energy-based model to train.\n        noise_scale: Standard deviation of Gaussian noise to add.\n        regularization_strength: Coefficient for regularization.\n        custom_regularization: A custom regularization function.\n        use_mixed_precision: Whether to use mixed-precision training.\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.losses import DenoisingScoreMatching\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        loss_fn = DenoisingScoreMatching(model=energy, noise_scale=0.1)\n        x = torch.randn(32, 2)\n        loss = loss_fn(x)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        noise_scale: float = 0.01,\n        regularization_strength: float = 0.0,\n        custom_regularization: Optional[Callable] = None,\n        use_mixed_precision: bool = False,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            noise_scale=noise_scale,\n            regularization_strength=regularization_strength,\n            use_autograd=True,\n            custom_regularization=custom_regularization,\n            use_mixed_precision=use_mixed_precision,\n            dtype=dtype,\n            device=device,\n            *args,\n            **kwargs,\n        )\n\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the denoising score matching loss for a batch of data.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar denoising score matching loss.\n        \"\"\"\n        if (x.device != self.device) or (x.dtype != self.dtype):\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            loss = self.compute_loss(x, *args, **kwargs)\n\n        if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n            loss = self.add_regularization(loss, x)\n\n        return loss\n\n    def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the denoising score matching loss.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar denoising score matching loss.\n        \"\"\"\n        x_perturbed, noise = self.perturb_data(x)\n\n        score = self.compute_score(x_perturbed)\n\n        target_score = -noise / (self.noise_scale**2)\n\n        loss = (\n            0.5\n            * torch.sum(\n                (score - target_score) ** 2, dim=list(range(1, len(x.shape)))\n            ).mean()\n        )\n\n        return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/DenoisingScoreMatching/#torchebm.losses.score_matching.DenoisingScoreMatching.forward","title":"forward","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the denoising score matching loss for a batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar denoising score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the denoising score matching loss for a batch of data.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar denoising score matching loss.\n    \"\"\"\n    if (x.device != self.device) or (x.dtype != self.dtype):\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    with self.autocast_context():\n        loss = self.compute_loss(x, *args, **kwargs)\n\n    if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n        loss = self.add_regularization(loss, x)\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/DenoisingScoreMatching/#torchebm.losses.score_matching.DenoisingScoreMatching.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the denoising score matching loss.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar denoising score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the denoising score matching loss.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar denoising score matching loss.\n    \"\"\"\n    x_perturbed, noise = self.perturb_data(x)\n\n    score = self.compute_score(x_perturbed)\n\n    target_score = -noise / (self.noise_scale**2)\n\n    loss = (\n        0.5\n        * torch.sum(\n            (score - target_score) ** 2, dim=list(range(1, len(x.shape)))\n        ).mean()\n    )\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/","title":"ScoreMatching","text":""},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScoreMatching</code></p> <p>Original Score Matching loss from Hyv\u00e4rinen (2005).</p> <p>Trains an energy-based model by matching the model's score function \\(\\nabla_x \\log p_\\theta(x)\\) to the data's score. Avoids MCMC sampling but requires computing the trace of the Hessian.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The energy-based model to train.</p> required <code>hessian_method</code> <code>str</code> <p>Method for Hessian trace ('exact' or 'approx').</p> <code>'exact'</code> <code>regularization_strength</code> <code>float</code> <p>Coefficient for regularization.</p> <code>0.0</code> <code>custom_regularization</code> <code>Optional[Callable]</code> <p>A custom regularization function.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed-precision training.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> Example <pre><code>from torchebm.losses import ScoreMatching\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nloss_fn = ScoreMatching(model=energy, hessian_method=\"exact\")\nx = torch.randn(32, 2)\nloss = loss_fn(x)\n</code></pre> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>class ScoreMatching(BaseScoreMatching):\n    r\"\"\"\n    Original Score Matching loss from Hyv\u00e4rinen (2005).\n\n    Trains an energy-based model by matching the model's score function\n    \\(\\nabla_x \\log p_\\theta(x)\\) to the data's score. Avoids MCMC sampling\n    but requires computing the trace of the Hessian.\n\n    Args:\n        model: The energy-based model to train.\n        hessian_method: Method for Hessian trace ('exact' or 'approx').\n        regularization_strength: Coefficient for regularization.\n        custom_regularization: A custom regularization function.\n        use_mixed_precision: Whether to use mixed-precision training.\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.losses import ScoreMatching\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        loss_fn = ScoreMatching(model=energy, hessian_method=\"exact\")\n        x = torch.randn(32, 2)\n        loss = loss_fn(x)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        hessian_method: str = \"exact\",\n        regularization_strength: float = 0.0,\n        custom_regularization: Optional[Callable] = None,\n        use_mixed_precision: bool = False,\n        is_training=True,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            regularization_strength=regularization_strength,\n            use_autograd=True,\n            custom_regularization=custom_regularization,\n            use_mixed_precision=use_mixed_precision,\n            dtype=dtype,\n            device=device,\n            *args,\n            **kwargs,\n        )\n\n        self.hessian_method = hessian_method\n        self.training = is_training\n        valid_methods = [\"exact\", \"approx\"]\n        if self.hessian_method not in valid_methods:\n            warnings.warn(\n                f\"Invalid hessian_method '{self.hessian_method}'. \"\n                f\"Using 'exact' instead. Valid options are: {valid_methods}\",\n                UserWarning,\n            )\n            self.hessian_method = \"exact\"\n\n        if self.use_mixed_precision and self.hessian_method == \"exact\":\n            warnings.warn(\n                \"Using 'exact' Hessian method with mixed precision may be unstable. \"\n                \"Consider using SlicedScoreMatching for better numerical stability.\",\n                UserWarning,\n            )\n\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the score matching loss for a batch of data.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar score matching loss.\n        \"\"\"\n        if (x.device != self.device) or (x.dtype != self.dtype):\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            loss = self.compute_loss(x, *args, **kwargs)\n\n        if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n            loss = self.add_regularization(loss, x)\n\n        return loss\n\n    def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the score matching loss using the specified Hessian computation method.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar score matching loss.\n        \"\"\"\n\n        if self.hessian_method == \"approx\":\n            return self._approx_score_matching(x)\n        else:\n            return self._exact_score_matching(x)\n\n    def _exact_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes score matching loss with an exact Hessian trace.\n\n        This method is computationally expensive for high-dimensional data.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n\n        Returns:\n            torch.Tensor: The score matching loss.\n        \"\"\"\n        batch_size = x.shape[0]\n        feature_dim = x.numel() // batch_size\n\n        x_leaf = x.detach().clone()\n        x_leaf.requires_grad_(True)\n\n        energy = self.model(x_leaf)\n        logp_sum = (-energy).sum()\n        grad1 = torch.autograd.grad(\n            logp_sum, x_leaf, create_graph=True, retain_graph=True\n        )[0]\n\n        grad1_flat = grad1.view(batch_size, -1)\n        term1 = 0.5 * grad1_flat.pow(2).sum(dim=1)\n\n        laplacian = torch.zeros(batch_size, device=x.device, dtype=x.dtype)\n        for i in range(feature_dim):\n            comp_sum = grad1_flat[:, i].sum()\n            grad2_full = torch.autograd.grad(\n                comp_sum,\n                x_leaf,\n                create_graph=True,\n                retain_graph=True,\n                allow_unused=True,\n            )[0]\n            if grad2_full is None:\n                grad2_comp = torch.zeros(batch_size, device=x.device, dtype=x.dtype)\n            else:\n                grad2_comp = grad2_full.view(batch_size, -1)[:, i]\n            laplacian += grad2_comp\n\n        loss_per_sample = term1 + laplacian\n        return loss_per_sample.mean()\n\n    def _approx_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes score matching loss using a finite-difference approximation for the Hessian trace.\n\n        Args:\n            x (torch.Tensor): Input data tensor.\n\n        Returns:\n            torch.Tensor: The score matching loss.\n        \"\"\"\n\n        batch_size = x.shape[0]\n        data_dim = x.numel() // batch_size\n\n        x_detached = x.detach().clone()\n        x_detached.requires_grad_(True)\n\n        score = self.compute_score(x_detached)\n        score_square_term = (\n            0.5 * torch.sum(score**2, dim=list(range(1, len(x.shape)))).mean()\n        )\n\n        epsilon = 1e-5\n        x_noise = x_detached + epsilon * torch.randn_like(x_detached)\n\n        score_x = self.compute_score(x_detached)\n        score_x_noise = self.compute_score(x_noise)\n\n        hessian_trace = torch.sum(\n            (score_x_noise - score_x) * (x_noise - x_detached),\n            dim=list(range(1, len(x.shape))),\n        ).mean() / (epsilon**2 * data_dim)\n\n        loss = score_square_term - hessian_trace\n\n        return loss\n\n    def _hutchinson_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        DEPRECATED: Use SlicedScoreMatching for efficient trace estimation.\n\n        This method has been deprecated in favor of SlicedScoreMatching which provides\n        a more efficient and theoretically sound implementation of Hutchinson's estimator.\n        \"\"\"\n        warnings.warn(\n            \"ScoreMatching._hutchinson_score_matching is deprecated. \"\n            \"Use SlicedScoreMatching for efficient trace estimation instead.\",\n            DeprecationWarning,\n        )\n        return self._exact_score_matching(x)\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching.hessian_method","title":"hessian_method  <code>instance-attribute</code>","text":"<pre><code>hessian_method = hessian_method\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching.training","title":"training  <code>instance-attribute</code>","text":"<pre><code>training = is_training\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching.forward","title":"forward","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the score matching loss for a batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the score matching loss for a batch of data.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar score matching loss.\n    \"\"\"\n    if (x.device != self.device) or (x.dtype != self.dtype):\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    with self.autocast_context():\n        loss = self.compute_loss(x, *args, **kwargs)\n\n    if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n        loss = self.add_regularization(loss, x)\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the score matching loss using the specified Hessian computation method.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the score matching loss using the specified Hessian computation method.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar score matching loss.\n    \"\"\"\n\n    if self.hessian_method == \"approx\":\n        return self._approx_score_matching(x)\n    else:\n        return self._exact_score_matching(x)\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching._exact_score_matching","title":"_exact_score_matching","text":"<pre><code>_exact_score_matching(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes score matching loss with an exact Hessian trace.</p> <p>This method is computationally expensive for high-dimensional data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def _exact_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes score matching loss with an exact Hessian trace.\n\n    This method is computationally expensive for high-dimensional data.\n\n    Args:\n        x (torch.Tensor): Input data tensor.\n\n    Returns:\n        torch.Tensor: The score matching loss.\n    \"\"\"\n    batch_size = x.shape[0]\n    feature_dim = x.numel() // batch_size\n\n    x_leaf = x.detach().clone()\n    x_leaf.requires_grad_(True)\n\n    energy = self.model(x_leaf)\n    logp_sum = (-energy).sum()\n    grad1 = torch.autograd.grad(\n        logp_sum, x_leaf, create_graph=True, retain_graph=True\n    )[0]\n\n    grad1_flat = grad1.view(batch_size, -1)\n    term1 = 0.5 * grad1_flat.pow(2).sum(dim=1)\n\n    laplacian = torch.zeros(batch_size, device=x.device, dtype=x.dtype)\n    for i in range(feature_dim):\n        comp_sum = grad1_flat[:, i].sum()\n        grad2_full = torch.autograd.grad(\n            comp_sum,\n            x_leaf,\n            create_graph=True,\n            retain_graph=True,\n            allow_unused=True,\n        )[0]\n        if grad2_full is None:\n            grad2_comp = torch.zeros(batch_size, device=x.device, dtype=x.dtype)\n        else:\n            grad2_comp = grad2_full.view(batch_size, -1)[:, i]\n        laplacian += grad2_comp\n\n    loss_per_sample = term1 + laplacian\n    return loss_per_sample.mean()\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching._approx_score_matching","title":"_approx_score_matching","text":"<pre><code>_approx_score_matching(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes score matching loss using a finite-difference approximation for the Hessian trace.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def _approx_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes score matching loss using a finite-difference approximation for the Hessian trace.\n\n    Args:\n        x (torch.Tensor): Input data tensor.\n\n    Returns:\n        torch.Tensor: The score matching loss.\n    \"\"\"\n\n    batch_size = x.shape[0]\n    data_dim = x.numel() // batch_size\n\n    x_detached = x.detach().clone()\n    x_detached.requires_grad_(True)\n\n    score = self.compute_score(x_detached)\n    score_square_term = (\n        0.5 * torch.sum(score**2, dim=list(range(1, len(x.shape)))).mean()\n    )\n\n    epsilon = 1e-5\n    x_noise = x_detached + epsilon * torch.randn_like(x_detached)\n\n    score_x = self.compute_score(x_detached)\n    score_x_noise = self.compute_score(x_noise)\n\n    hessian_trace = torch.sum(\n        (score_x_noise - score_x) * (x_noise - x_detached),\n        dim=list(range(1, len(x.shape))),\n    ).mean() / (epsilon**2 * data_dim)\n\n    loss = score_square_term - hessian_trace\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/ScoreMatching/#torchebm.losses.score_matching.ScoreMatching._hutchinson_score_matching","title":"_hutchinson_score_matching","text":"<pre><code>_hutchinson_score_matching(x: Tensor) -&gt; torch.Tensor\n</code></pre> <p>DEPRECATED: Use SlicedScoreMatching for efficient trace estimation.</p> <p>This method has been deprecated in favor of SlicedScoreMatching which provides a more efficient and theoretically sound implementation of Hutchinson's estimator.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def _hutchinson_score_matching(self, x: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    DEPRECATED: Use SlicedScoreMatching for efficient trace estimation.\n\n    This method has been deprecated in favor of SlicedScoreMatching which provides\n    a more efficient and theoretically sound implementation of Hutchinson's estimator.\n    \"\"\"\n    warnings.warn(\n        \"ScoreMatching._hutchinson_score_matching is deprecated. \"\n        \"Use SlicedScoreMatching for efficient trace estimation instead.\",\n        DeprecationWarning,\n    )\n    return self._exact_score_matching(x)\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/","title":"SlicedScoreMatching","text":""},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseScoreMatching</code></p> <p>Sliced Score Matching (SSM) from Song et al. (2019).</p> <p>A scalable variant that uses random projections to efficiently approximate the score matching objective, avoiding expensive Hessian trace computation.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>The energy-based model to train.</p> required <code>n_projections</code> <code>int</code> <p>Number of random projections to use.</p> <code>5</code> <code>projection_type</code> <code>str</code> <p>Type of projections ('rademacher', 'sphere', 'gaussian').</p> <code>'rademacher'</code> <code>regularization_strength</code> <code>float</code> <p>Coefficient for regularization.</p> <code>0.0</code> <code>custom_regularization</code> <code>Optional[Callable]</code> <p>A custom regularization function.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed-precision training.</p> <code>False</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> Example <pre><code>from torchebm.losses import SlicedScoreMatching\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nloss_fn = SlicedScoreMatching(model=energy, n_projections=5)\nx = torch.randn(32, 2)\nloss = loss_fn(x)\n</code></pre> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>class SlicedScoreMatching(BaseScoreMatching):\n    r\"\"\"\n    Sliced Score Matching (SSM) from Song et al. (2019).\n\n    A scalable variant that uses random projections to efficiently approximate\n    the score matching objective, avoiding expensive Hessian trace computation.\n\n    Args:\n        model: The energy-based model to train.\n        n_projections: Number of random projections to use.\n        projection_type: Type of projections ('rademacher', 'sphere', 'gaussian').\n        regularization_strength: Coefficient for regularization.\n        custom_regularization: A custom regularization function.\n        use_mixed_precision: Whether to use mixed-precision training.\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.losses import SlicedScoreMatching\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        loss_fn = SlicedScoreMatching(model=energy, n_projections=5)\n        x = torch.randn(32, 2)\n        loss = loss_fn(x)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        n_projections: int = 5,\n        projection_type: str = \"rademacher\",\n        regularization_strength: float = 0.0,\n        custom_regularization: Optional[Callable] = None,\n        use_mixed_precision: bool = False,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            regularization_strength=regularization_strength,\n            use_autograd=True,\n            custom_regularization=custom_regularization,\n            use_mixed_precision=use_mixed_precision,\n            dtype=dtype,\n            device=device,\n            *args,\n            **kwargs,\n        )\n\n        self.n_projections = n_projections\n        self.projection_type = projection_type\n\n        # Validate projection_type\n        valid_types = [\"rademacher\", \"sphere\", \"gaussian\"]\n        if self.projection_type not in valid_types:\n            warnings.warn(\n                f\"Invalid projection_type '{self.projection_type}'. \"\n                f\"Using 'rademacher' instead. Valid options are: {valid_types}\",\n                UserWarning,\n            )\n            self.projection_type = \"rademacher\"\n\n    def _get_random_projections(self, shape: torch.Size) -&gt; torch.Tensor:\n        r\"\"\"\n        Generates random vectors for projections.\n\n        Args:\n            shape (torch.Size): The shape of the vectors to generate.\n\n        Returns:\n            torch.Tensor: A tensor of random projection vectors.\n        \"\"\"\n        vectors = torch.randn_like(shape)\n        if self.projection_type == \"rademacher\":\n            return vectors.sign()\n        elif self.projection_type == \"sphere\":\n            return (\n                vectors\n                / torch.norm(vectors, dim=-1, keepdim=True)\n                * torch.sqrt(vectors.shape[-1])\n            )\n        else:\n            return vectors\n\n    def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the sliced score matching loss for a batch of data.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional positional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar sliced score matching loss.\n        \"\"\"\n        if (x.device != self.device) or (x.dtype != self.dtype):\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        with self.autocast_context():\n            loss = self.compute_loss(x, *args, **kwargs)\n\n        if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n            loss = self.add_regularization(loss, x)\n\n        return loss\n\n    def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the sliced score matching loss using random projections.\n\n        Args:\n            x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n            *args: Additional arguments.\n            **kwargs: Additional keyword arguments.\n\n        Returns:\n            torch.Tensor: The scalar sliced score matching loss.\n        \"\"\"\n\n        dup_x = (\n            x.unsqueeze(0)\n            .expand(self.n_projections, *x.shape)\n            .contiguous()\n            .view(-1, *x.shape[1:])\n        ).requires_grad_(\n            True\n        )  # final shape: (n_particles * batch_size, d). tracing the shape: (batch_size, d) -&gt; (1, batch_size, d)\n        # -&gt; (n_particles, batch_size, d) -&gt; (n_particles, batch_size, d) -&gt; (n_particles * batch_size, d)\n\n        n_vectors = self._get_random_projections(dup_x)\n\n        logp = (-self.model(dup_x)).sum()\n        grad1 = torch.autograd.grad(logp, dup_x, create_graph=True)[0]\n        v_score = torch.sum(grad1 * n_vectors, dim=-1)\n        term1 = 0.5 * (v_score**2)\n\n        grad_v = torch.autograd.grad(v_score.sum(), dup_x, create_graph=True)[0]\n        term2 = torch.sum(n_vectors * grad_v, dim=-1)\n\n        term1 = term1.view(self.n_projections, -1).mean(dim=0)\n        term2 = term2.view(self.n_projections, -1).mean(dim=0)\n\n        loss = term2 + term1\n\n        return loss.mean()\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#torchebm.losses.score_matching.SlicedScoreMatching.n_projections","title":"n_projections  <code>instance-attribute</code>","text":"<pre><code>n_projections = n_projections\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#torchebm.losses.score_matching.SlicedScoreMatching.projection_type","title":"projection_type  <code>instance-attribute</code>","text":"<pre><code>projection_type = projection_type\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#torchebm.losses.score_matching.SlicedScoreMatching._get_random_projections","title":"_get_random_projections","text":"<pre><code>_get_random_projections(shape: Size) -&gt; torch.Tensor\n</code></pre> <p>Generates random vectors for projections.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Size</code> <p>The shape of the vectors to generate.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: A tensor of random projection vectors.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def _get_random_projections(self, shape: torch.Size) -&gt; torch.Tensor:\n    r\"\"\"\n    Generates random vectors for projections.\n\n    Args:\n        shape (torch.Size): The shape of the vectors to generate.\n\n    Returns:\n        torch.Tensor: A tensor of random projection vectors.\n    \"\"\"\n    vectors = torch.randn_like(shape)\n    if self.projection_type == \"rademacher\":\n        return vectors.sign()\n    elif self.projection_type == \"sphere\":\n        return (\n            vectors\n            / torch.norm(vectors, dim=-1, keepdim=True)\n            * torch.sqrt(vectors.shape[-1])\n        )\n    else:\n        return vectors\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#torchebm.losses.score_matching.SlicedScoreMatching.forward","title":"forward","text":"<pre><code>forward(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the sliced score matching loss for a batch of data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional positional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar sliced score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def forward(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the sliced score matching loss for a batch of data.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional positional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar sliced score matching loss.\n    \"\"\"\n    if (x.device != self.device) or (x.dtype != self.dtype):\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    with self.autocast_context():\n        loss = self.compute_loss(x, *args, **kwargs)\n\n    if self.regularization_strength &gt; 0 or self.custom_regularization is not None:\n        loss = self.add_regularization(loss, x)\n\n    return loss\n</code></pre>"},{"location":"api/torchebm/losses/score_matching/classes/SlicedScoreMatching/#torchebm.losses.score_matching.SlicedScoreMatching.compute_loss","title":"compute_loss","text":"<pre><code>compute_loss(x: Tensor, *args, **kwargs) -&gt; torch.Tensor\n</code></pre> <p>Computes the sliced score matching loss using random projections.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Tensor</code> <p>Input data tensor of shape <code>(batch_size, *data_dims)</code>.</p> required <code>*args</code> <p>Additional arguments.</p> <code>()</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The scalar sliced score matching loss.</p> Source code in <code>torchebm/losses/score_matching.py</code> <pre><code>def compute_loss(self, x: torch.Tensor, *args, **kwargs) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the sliced score matching loss using random projections.\n\n    Args:\n        x (torch.Tensor): Input data tensor of shape `(batch_size, *data_dims)`.\n        *args: Additional arguments.\n        **kwargs: Additional keyword arguments.\n\n    Returns:\n        torch.Tensor: The scalar sliced score matching loss.\n    \"\"\"\n\n    dup_x = (\n        x.unsqueeze(0)\n        .expand(self.n_projections, *x.shape)\n        .contiguous()\n        .view(-1, *x.shape[1:])\n    ).requires_grad_(\n        True\n    )  # final shape: (n_particles * batch_size, d). tracing the shape: (batch_size, d) -&gt; (1, batch_size, d)\n    # -&gt; (n_particles, batch_size, d) -&gt; (n_particles, batch_size, d) -&gt; (n_particles * batch_size, d)\n\n    n_vectors = self._get_random_projections(dup_x)\n\n    logp = (-self.model(dup_x)).sum()\n    grad1 = torch.autograd.grad(logp, dup_x, create_graph=True)[0]\n    v_score = torch.sum(grad1 * n_vectors, dim=-1)\n    term1 = 0.5 * (v_score**2)\n\n    grad_v = torch.autograd.grad(v_score.sum(), dup_x, create_graph=True)[0]\n    term2 = torch.sum(n_vectors * grad_v, dim=-1)\n\n    term1 = term1.view(self.n_projections, -1).mean(dim=0)\n    term2 = term2.view(self.n_projections, -1).mean(dim=0)\n\n    loss = term2 + term1\n\n    return loss.mean()\n</code></pre>"},{"location":"api/torchebm/models/","title":"Torchebm &gt; Models","text":""},{"location":"api/torchebm/models/#torchebm-models","title":"Torchebm &gt; Models","text":""},{"location":"api/torchebm/models/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/#subpackages","title":"Subpackages","text":"<ul> <li>Components</li> </ul>"},{"location":"api/torchebm/models/#modules","title":"Modules","text":"<ul> <li>Conditional_transformer_2d</li> <li>Wrappers</li> </ul>"},{"location":"api/torchebm/models/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/#torchebm.models","title":"torchebm.models","text":"<p>Model namespace.</p> <p>TorchEBM is designed for plug-and-play experimentation: - try different losses with the same backbone - try different backbones with the same loss - use samplers as long as the model signature matches</p> <p>This package therefore exposes reusable building blocks under <code>torchebm.models.components</code> and a small set of generic backbones/wrappers.</p>"},{"location":"api/torchebm/models/components/","title":"Torchebm &gt; Models &gt; Components","text":""},{"location":"api/torchebm/models/components/#torchebm-models-components","title":"Torchebm &gt; Models &gt; Components","text":""},{"location":"api/torchebm/models/components/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/#modules","title":"Modules","text":"<ul> <li>Embeddings</li> <li>Heads</li> <li>Patch</li> <li>Positional</li> <li>Transformer</li> </ul>"},{"location":"api/torchebm/models/components/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/#torchebm.models.components","title":"torchebm.models.components","text":"<p>Reusable neural network building blocks for TorchEBM models.</p> <p>These are intentionally model-agnostic components that can be composed into backbones compatible with different losses and samplers.</p> <p>The library avoids exposing paper-specific preset/config objects here; keep those at the example/use-case layer.</p>"},{"location":"api/torchebm/models/components/embeddings/","title":"Torchebm &gt; Models &gt; Components &gt; Embeddings","text":""},{"location":"api/torchebm/models/components/embeddings/#torchebm-models-components-embeddings","title":"Torchebm &gt; Models &gt; Components &gt; Embeddings","text":""},{"location":"api/torchebm/models/components/embeddings/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/embeddings/#classes","title":"Classes","text":"<ul> <li><code>LabelEmbedder</code> - Label embedding with optional classifier-free guidance token dropping.</li> <li><code>MLPTimestepEmbedder</code> - Embed a scalar timestep into a vector via sinusoid + MLP.</li> </ul>"},{"location":"api/torchebm/models/components/embeddings/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/embeddings/#torchebm.models.components.embeddings","title":"torchebm.models.components.embeddings","text":""},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/","title":"LabelEmbedder","text":""},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Label embedding with optional classifier-free guidance token dropping.</p> <p>If <code>dropout_prob&gt;0</code>, one extra embedding row is allocated to represent the null/unconditional label.</p> <p>Note: this module does not assume any specific loss/sampler; it only produces vectors.</p> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>class LabelEmbedder(nn.Module):\n    \"\"\"Label embedding with optional classifier-free guidance token dropping.\n\n    If `dropout_prob&gt;0`, one extra embedding row is allocated to represent the\n    *null/unconditional* label.\n\n    Note: this module does *not* assume any specific loss/sampler; it only\n    produces vectors.\n    \"\"\"\n\n    def __init__(self, num_classes: int, out_dim: int, dropout_prob: float = 0.0):\n        super().__init__()\n        self.num_classes = int(num_classes)\n        self.dropout_prob = float(dropout_prob)\n        use_null = self.dropout_prob &gt; 0\n        self.null_label_id = self.num_classes if use_null else None\n        self.embedding = nn.Embedding(self.num_classes + (1 if use_null else 0), out_dim)\n\n    def maybe_drop_labels(\n        self,\n        labels: torch.Tensor,\n        *,\n        force_drop_mask: Optional[torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        if self.dropout_prob &lt;= 0:\n            return labels\n        if self.null_label_id is None:\n            raise RuntimeError(\"LabelEmbedder configured without null label.\")\n\n        if force_drop_mask is None:\n            drop_mask = torch.rand(labels.shape[0], device=labels.device) &lt; self.dropout_prob\n        else:\n            drop_mask = force_drop_mask.to(device=labels.device, dtype=torch.bool)\n\n        return torch.where(drop_mask, torch.full_like(labels, self.null_label_id), labels)\n\n    def forward(\n        self,\n        labels: torch.Tensor,\n        *,\n        training: bool,\n        force_drop_mask: Optional[torch.Tensor] = None,\n    ) -&gt; torch.Tensor:\n        if training or (force_drop_mask is not None):\n            labels = self.maybe_drop_labels(labels, force_drop_mask=force_drop_mask)\n        return self.embedding(labels)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.num_classes","title":"num_classes  <code>instance-attribute</code>","text":"<pre><code>num_classes = int(num_classes)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.dropout_prob","title":"dropout_prob  <code>instance-attribute</code>","text":"<pre><code>dropout_prob = float(dropout_prob)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.null_label_id","title":"null_label_id  <code>instance-attribute</code>","text":"<pre><code>null_label_id = num_classes if use_null else None\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.embedding","title":"embedding  <code>instance-attribute</code>","text":"<pre><code>embedding = Embedding(num_classes + (1 if use_null else 0), out_dim)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.maybe_drop_labels","title":"maybe_drop_labels","text":"<pre><code>maybe_drop_labels(labels: Tensor, *, force_drop_mask: Optional[Tensor] = None) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>def maybe_drop_labels(\n    self,\n    labels: torch.Tensor,\n    *,\n    force_drop_mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    if self.dropout_prob &lt;= 0:\n        return labels\n    if self.null_label_id is None:\n        raise RuntimeError(\"LabelEmbedder configured without null label.\")\n\n    if force_drop_mask is None:\n        drop_mask = torch.rand(labels.shape[0], device=labels.device) &lt; self.dropout_prob\n    else:\n        drop_mask = force_drop_mask.to(device=labels.device, dtype=torch.bool)\n\n    return torch.where(drop_mask, torch.full_like(labels, self.null_label_id), labels)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/LabelEmbedder/#torchebm.models.components.embeddings.LabelEmbedder.forward","title":"forward","text":"<pre><code>forward(labels: Tensor, *, training: bool, force_drop_mask: Optional[Tensor] = None) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>def forward(\n    self,\n    labels: torch.Tensor,\n    *,\n    training: bool,\n    force_drop_mask: Optional[torch.Tensor] = None,\n) -&gt; torch.Tensor:\n    if training or (force_drop_mask is not None):\n        labels = self.maybe_drop_labels(labels, force_drop_mask=force_drop_mask)\n    return self.embedding(labels)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/","title":"MLPTimestepEmbedder","text":""},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Embed a scalar timestep into a vector via sinusoid + MLP.</p> <p>This is a generic block (useful for EqM, diffusion, flows, etc.).</p> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>class MLPTimestepEmbedder(nn.Module):\n    \"\"\"Embed a scalar timestep into a vector via sinusoid + MLP.\n\n    This is a generic block (useful for EqM, diffusion, flows, etc.).\n    \"\"\"\n\n    def __init__(self, out_dim: int, frequency_embedding_size: int = 256):\n        super().__init__()\n        self.frequency_embedding_size = int(frequency_embedding_size)\n        self.mlp = nn.Sequential(\n            nn.Linear(self.frequency_embedding_size, out_dim, bias=True),\n            nn.SiLU(),\n            nn.Linear(out_dim, out_dim, bias=True),\n        )\n\n    @staticmethod\n    def sinusoidal_embedding(t: torch.Tensor, dim: int, max_period: int = 10000) -&gt; torch.Tensor:\n        # t: (B,)\n        half = dim // 2\n        freqs = torch.exp(\n            -math.log(max_period)\n            * torch.arange(start=0, end=half, device=t.device, dtype=torch.float32)\n            / half\n        )\n        args = t[:, None].float() * freqs[None]\n        emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n        if dim % 2:\n            emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n        return emb\n\n    def forward(self, t: torch.Tensor) -&gt; torch.Tensor:\n        if t.ndim != 1:\n            t = t.reshape(t.shape[0])\n        freq = self.sinusoidal_embedding(t, self.frequency_embedding_size)\n        return self.mlp(freq)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/#torchebm.models.components.embeddings.MLPTimestepEmbedder.frequency_embedding_size","title":"frequency_embedding_size  <code>instance-attribute</code>","text":"<pre><code>frequency_embedding_size = int(frequency_embedding_size)\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/#torchebm.models.components.embeddings.MLPTimestepEmbedder.mlp","title":"mlp  <code>instance-attribute</code>","text":"<pre><code>mlp = Sequential(Linear(frequency_embedding_size, out_dim, bias=True), SiLU(), Linear(out_dim, out_dim, bias=True))\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/#torchebm.models.components.embeddings.MLPTimestepEmbedder.sinusoidal_embedding","title":"sinusoidal_embedding  <code>staticmethod</code>","text":"<pre><code>sinusoidal_embedding(t: Tensor, dim: int, max_period: int = 10000) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>@staticmethod\ndef sinusoidal_embedding(t: torch.Tensor, dim: int, max_period: int = 10000) -&gt; torch.Tensor:\n    # t: (B,)\n    half = dim // 2\n    freqs = torch.exp(\n        -math.log(max_period)\n        * torch.arange(start=0, end=half, device=t.device, dtype=torch.float32)\n        / half\n    )\n    args = t[:, None].float() * freqs[None]\n    emb = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n    if dim % 2:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n    return emb\n</code></pre>"},{"location":"api/torchebm/models/components/embeddings/classes/MLPTimestepEmbedder/#torchebm.models.components.embeddings.MLPTimestepEmbedder.forward","title":"forward","text":"<pre><code>forward(t: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/embeddings.py</code> <pre><code>def forward(self, t: torch.Tensor) -&gt; torch.Tensor:\n    if t.ndim != 1:\n        t = t.reshape(t.shape[0])\n    freq = self.sinusoidal_embedding(t, self.frequency_embedding_size)\n    return self.mlp(freq)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/","title":"Torchebm &gt; Models &gt; Components &gt; Heads","text":""},{"location":"api/torchebm/models/components/heads/#torchebm-models-components-heads","title":"Torchebm &gt; Models &gt; Components &gt; Heads","text":""},{"location":"api/torchebm/models/components/heads/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/heads/#classes","title":"Classes","text":"<ul> <li><code>AdaLNZeroPatchHead</code> - Final layer that maps token features to patch pixels with adaLN-Zero.</li> </ul>"},{"location":"api/torchebm/models/components/heads/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/heads/#torchebm.models.components.heads","title":"torchebm.models.components.heads","text":""},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/","title":"AdaLNZeroPatchHead","text":""},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Final layer that maps token features to patch pixels with adaLN-Zero.</p> Source code in <code>torchebm/models/components/heads.py</code> <pre><code>class AdaLNZeroPatchHead(nn.Module):\n    \"\"\"Final layer that maps token features to patch pixels with adaLN-Zero.\"\"\"\n\n    def __init__(\n        self,\n        *,\n        embed_dim: int,\n        cond_dim: Optional[int] = None,\n        patch_size: int,\n        out_channels: int,\n        eps: float = 1e-6,\n    ):\n        super().__init__()\n        self.embed_dim = int(embed_dim)\n        self.cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n        self.patch_size = int(patch_size)\n        self.out_channels = int(out_channels)\n\n        self.norm = nn.LayerNorm(self.embed_dim, elementwise_affine=False, eps=eps)\n        self.modulation = nn.Sequential(\n            nn.SiLU(),\n            nn.Linear(self.cond_dim, 2 * self.embed_dim, bias=True),\n        )\n        self.proj = nn.Linear(self.embed_dim, self.patch_size * self.patch_size * self.out_channels, bias=True)\n\n        nn.init.zeros_(self.modulation[-1].weight)\n        nn.init.zeros_(self.modulation[-1].bias)\n        nn.init.zeros_(self.proj.weight)\n        nn.init.zeros_(self.proj.bias)\n\n    def forward(self, tokens: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n        shift, scale = self.modulation(cond).chunk(2, dim=1)\n        tokens = modulate(self.norm(tokens), shift, scale)\n        patches = self.proj(tokens)\n        return unpatchify2d(patches, self.patch_size, out_channels=self.out_channels)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.embed_dim","title":"embed_dim  <code>instance-attribute</code>","text":"<pre><code>embed_dim = int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.cond_dim","title":"cond_dim  <code>instance-attribute</code>","text":"<pre><code>cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.patch_size","title":"patch_size  <code>instance-attribute</code>","text":"<pre><code>patch_size = int(patch_size)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.out_channels","title":"out_channels  <code>instance-attribute</code>","text":"<pre><code>out_channels = int(out_channels)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.norm","title":"norm  <code>instance-attribute</code>","text":"<pre><code>norm = LayerNorm(embed_dim, elementwise_affine=False, eps=eps)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.modulation","title":"modulation  <code>instance-attribute</code>","text":"<pre><code>modulation = Sequential(SiLU(), Linear(cond_dim, 2 * embed_dim, bias=True))\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.proj","title":"proj  <code>instance-attribute</code>","text":"<pre><code>proj = Linear(embed_dim, patch_size * patch_size * out_channels, bias=True)\n</code></pre>"},{"location":"api/torchebm/models/components/heads/classes/AdaLNZeroPatchHead/#torchebm.models.components.heads.AdaLNZeroPatchHead.forward","title":"forward","text":"<pre><code>forward(tokens: Tensor, cond: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/heads.py</code> <pre><code>def forward(self, tokens: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n    shift, scale = self.modulation(cond).chunk(2, dim=1)\n    tokens = modulate(self.norm(tokens), shift, scale)\n    patches = self.proj(tokens)\n    return unpatchify2d(patches, self.patch_size, out_channels=self.out_channels)\n</code></pre>"},{"location":"api/torchebm/models/components/patch/","title":"Torchebm &gt; Models &gt; Components &gt; Patch","text":""},{"location":"api/torchebm/models/components/patch/#torchebm-models-components-patch","title":"Torchebm &gt; Models &gt; Components &gt; Patch","text":""},{"location":"api/torchebm/models/components/patch/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/patch/#classes","title":"Classes","text":"<ul> <li><code>ConvPatchEmbed2d</code> - Patch embedding via strided conv.</li> </ul>"},{"location":"api/torchebm/models/components/patch/#functions","title":"Functions","text":"<ul> <li><code>patchify2d()</code> - Convert (B,C,H,W) into patch tokens (B, N, C*P*P).</li> <li><code>unpatchify2d()</code> - Convert patch tokens (B,N,P*P*C) back to (B,C,H,W).</li> </ul>"},{"location":"api/torchebm/models/components/patch/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/patch/#torchebm.models.components.patch","title":"torchebm.models.components.patch","text":""},{"location":"api/torchebm/models/components/patch/classes/ConvPatchEmbed2d/","title":"ConvPatchEmbed2d","text":""},{"location":"api/torchebm/models/components/patch/classes/ConvPatchEmbed2d/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Patch embedding via strided conv.</p> <p>This is a lightweight replacement for timm's PatchEmbed.</p> Source code in <code>torchebm/models/components/patch.py</code> <pre><code>class ConvPatchEmbed2d(nn.Module):\n    \"\"\"Patch embedding via strided conv.\n\n    This is a lightweight replacement for timm's PatchEmbed.\n    \"\"\"\n\n    def __init__(self, *, in_channels: int, embed_dim: int, patch_size: int):\n        super().__init__()\n        p = int(patch_size)\n        self.patch_size = p\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=p, stride=p, bias=True)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        # (B,C,H,W) -&gt; (B, N, D)\n        y = self.proj(x)\n        b, d, gh, gw = y.shape\n        return y.flatten(2).transpose(1, 2).contiguous()\n</code></pre>"},{"location":"api/torchebm/models/components/patch/classes/ConvPatchEmbed2d/#torchebm.models.components.patch.ConvPatchEmbed2d.patch_size","title":"patch_size  <code>instance-attribute</code>","text":"<pre><code>patch_size = p\n</code></pre>"},{"location":"api/torchebm/models/components/patch/classes/ConvPatchEmbed2d/#torchebm.models.components.patch.ConvPatchEmbed2d.proj","title":"proj  <code>instance-attribute</code>","text":"<pre><code>proj = Conv2d(in_channels, embed_dim, kernel_size=p, stride=p, bias=True)\n</code></pre>"},{"location":"api/torchebm/models/components/patch/classes/ConvPatchEmbed2d/#torchebm.models.components.patch.ConvPatchEmbed2d.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/patch.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    # (B,C,H,W) -&gt; (B, N, D)\n    y = self.proj(x)\n    b, d, gh, gw = y.shape\n    return y.flatten(2).transpose(1, 2).contiguous()\n</code></pre>"},{"location":"api/torchebm/models/components/positional/","title":"Positional","text":""},{"location":"api/torchebm/models/components/positional/#torchebm-models-components-positional","title":"Torchebm &gt; Models &gt; Components &gt; Positional","text":""},{"location":"api/torchebm/models/components/positional/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/positional/#functions","title":"Functions","text":"<ul> <li><code>build_2d_sincos_pos_embed()</code> - Create 2D sin/cos positional embeddings.</li> </ul>"},{"location":"api/torchebm/models/components/positional/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/positional/#torchebm.models.components.positional","title":"torchebm.models.components.positional","text":""},{"location":"api/torchebm/models/components/transformer/","title":"Torchebm &gt; Models &gt; Components &gt; Transformer","text":""},{"location":"api/torchebm/models/components/transformer/#torchebm-models-components-transformer","title":"Torchebm &gt; Models &gt; Components &gt; Transformer","text":""},{"location":"api/torchebm/models/components/transformer/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/components/transformer/#classes","title":"Classes","text":"<ul> <li><code>AdaLNZeroBlock</code> - Transformer block with adaLN-Zero conditioning.</li> <li><code>FeedForward</code> - No description available.</li> <li><code>MultiheadSelfAttention</code> - Self-attention wrapper with batch-first API.</li> </ul>"},{"location":"api/torchebm/models/components/transformer/#functions","title":"Functions","text":"<ul> <li><code>modulate()</code> - No description available.</li> </ul>"},{"location":"api/torchebm/models/components/transformer/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/components/transformer/#torchebm.models.components.transformer","title":"torchebm.models.components.transformer","text":""},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/","title":"AdaLNZeroBlock","text":""},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Transformer block with adaLN-Zero conditioning.</p> <p>Takes a per-sample conditioning vector <code>cond</code> (B, cond_dim) and applies it to modulate norms + gate residuals.</p> <p>This is a reusable block; it does not assume anything about what <code>cond</code> represents (time, labels, text, etc.).</p> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>class AdaLNZeroBlock(nn.Module):\n    \"\"\"Transformer block with adaLN-Zero conditioning.\n\n    Takes a per-sample conditioning vector `cond` (B, cond_dim) and applies it\n    to modulate norms + gate residuals.\n\n    This is a reusable block; it does not assume anything about what `cond`\n    represents (time, labels, text, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        embed_dim: int,\n        num_heads: int,\n        cond_dim: Optional[int] = None,\n        mlp_ratio: float = 4.0,\n        attn: Optional[nn.Module] = None,\n        mlp: Optional[nn.Module] = None,\n        eps: float = 1e-6,\n    ):\n        super().__init__()\n        self.embed_dim = int(embed_dim)\n        self.cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n\n        self.norm1 = nn.LayerNorm(self.embed_dim, elementwise_affine=False, eps=eps)\n        self.attn = attn if attn is not None else MultiheadSelfAttention(self.embed_dim, num_heads=num_heads)\n        self.norm2 = nn.LayerNorm(self.embed_dim, elementwise_affine=False, eps=eps)\n        self.mlp = mlp if mlp is not None else FeedForward(self.embed_dim, mlp_ratio=mlp_ratio)\n\n        self.modulation = nn.Sequential(\n            nn.SiLU(),\n            nn.Linear(self.cond_dim, 6 * self.embed_dim, bias=True),\n        )\n\n        # Zero-init to start near identity.\n        nn.init.zeros_(self.modulation[-1].weight)\n        nn.init.zeros_(self.modulation[-1].bias)\n\n    def forward(self, x: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n        # x: (B,N,D), cond: (B,cond_dim)\n        shift1, scale1, gate1, shift2, scale2, gate2 = self.modulation(cond).chunk(6, dim=1)\n\n        x = x + gate1.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift1, scale1))\n        x = x + gate2.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift2, scale2))\n        return x\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.embed_dim","title":"embed_dim  <code>instance-attribute</code>","text":"<pre><code>embed_dim = int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.cond_dim","title":"cond_dim  <code>instance-attribute</code>","text":"<pre><code>cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.norm1","title":"norm1  <code>instance-attribute</code>","text":"<pre><code>norm1 = LayerNorm(embed_dim, elementwise_affine=False, eps=eps)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.attn","title":"attn  <code>instance-attribute</code>","text":"<pre><code>attn = attn if attn is not None else MultiheadSelfAttention(embed_dim, num_heads=num_heads)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.norm2","title":"norm2  <code>instance-attribute</code>","text":"<pre><code>norm2 = LayerNorm(embed_dim, elementwise_affine=False, eps=eps)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.mlp","title":"mlp  <code>instance-attribute</code>","text":"<pre><code>mlp = mlp if mlp is not None else FeedForward(embed_dim, mlp_ratio=mlp_ratio)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.modulation","title":"modulation  <code>instance-attribute</code>","text":"<pre><code>modulation = Sequential(SiLU(), Linear(cond_dim, 6 * embed_dim, bias=True))\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/AdaLNZeroBlock/#torchebm.models.components.transformer.AdaLNZeroBlock.forward","title":"forward","text":"<pre><code>forward(x: Tensor, cond: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>def forward(self, x: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n    # x: (B,N,D), cond: (B,cond_dim)\n    shift1, scale1, gate1, shift2, scale2, gate2 = self.modulation(cond).chunk(6, dim=1)\n\n    x = x + gate1.unsqueeze(1) * self.attn(modulate(self.norm1(x), shift1, scale1))\n    x = x + gate2.unsqueeze(1) * self.mlp(modulate(self.norm2(x), shift2, scale2))\n    return x\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/FeedForward/","title":"FeedForward","text":""},{"location":"api/torchebm/models/components/transformer/classes/FeedForward/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>class FeedForward(nn.Module):\n    def __init__(self, embed_dim: int, mlp_ratio: float = 4.0, dropout: float = 0.0):\n        super().__init__()\n        hidden = int(embed_dim * mlp_ratio)\n        self.net = nn.Sequential(\n            nn.Linear(embed_dim, hidden, bias=True),\n            nn.GELU(approximate=\"tanh\"),\n            nn.Dropout(dropout),\n            nn.Linear(hidden, embed_dim, bias=True),\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.net(x)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/FeedForward/#torchebm.models.components.transformer.FeedForward.net","title":"net  <code>instance-attribute</code>","text":"<pre><code>net = Sequential(Linear(embed_dim, hidden, bias=True), GELU(approximate='tanh'), Dropout(dropout), Linear(hidden, embed_dim, bias=True))\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/FeedForward/#torchebm.models.components.transformer.FeedForward.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    return self.net(x)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/MultiheadSelfAttention/","title":"MultiheadSelfAttention","text":""},{"location":"api/torchebm/models/components/transformer/classes/MultiheadSelfAttention/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Self-attention wrapper with batch-first API.</p> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>class MultiheadSelfAttention(nn.Module):\n    \"\"\"Self-attention wrapper with batch-first API.\"\"\"\n\n    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.0):\n        super().__init__()\n        self.mha = nn.MultiheadAttention(\n            embed_dim=embed_dim,\n            num_heads=num_heads,\n            dropout=dropout,\n            batch_first=True,\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        y, _ = self.mha(x, x, x, need_weights=False)\n        return y\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/MultiheadSelfAttention/#torchebm.models.components.transformer.MultiheadSelfAttention.mha","title":"mha  <code>instance-attribute</code>","text":"<pre><code>mha = MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, dropout=dropout, batch_first=True)\n</code></pre>"},{"location":"api/torchebm/models/components/transformer/classes/MultiheadSelfAttention/#torchebm.models.components.transformer.MultiheadSelfAttention.forward","title":"forward","text":"<pre><code>forward(x: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/components/transformer.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    y, _ = self.mha(x, x, x, need_weights=False)\n    return y\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/","title":"Torchebm &gt; Models &gt; Conditional_transformer_2d","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/#torchebm-models-conditional_transformer_2d","title":"Torchebm &gt; Models &gt; Conditional_transformer_2d","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/#classes","title":"Classes","text":"<ul> <li><code>ConditionalTransformer2D</code> - Generic conditional 2D Transformer backbone.</li> </ul>"},{"location":"api/torchebm/models/conditional_transformer_2d/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/#torchebm.models.conditional_transformer_2d","title":"torchebm.models.conditional_transformer_2d","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/","title":"ConditionalTransformer2D","text":""},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Generic conditional 2D Transformer backbone.</p> <p>This module is intentionally loss-agnostic.</p> Inputs <ul> <li><code>x</code>: image-like tensor (B,C,H,W)</li> <li><code>cond</code>: conditioning vector (B, cond_dim)</li> </ul> Output <ul> <li>image-like tensor (B, out_channels, H, W)</li> </ul> <p>You can plug this into EqM, diffusion, score matching, etc. by choosing:   - how <code>cond</code> is produced (time, labels, text, ...)   - <code>out_channels</code> and head behavior</p> Source code in <code>torchebm/models/conditional_transformer_2d.py</code> <pre><code>class ConditionalTransformer2D(nn.Module):\n    \"\"\"Generic conditional 2D Transformer backbone.\n\n    This module is intentionally *loss-agnostic*.\n\n    Inputs:\n      - `x`: image-like tensor (B,C,H,W)\n      - `cond`: conditioning vector (B, cond_dim)\n\n    Output:\n      - image-like tensor (B, out_channels, H, W)\n\n    You can plug this into EqM, diffusion, score matching, etc. by choosing:\n      - how `cond` is produced (time, labels, text, ...)\n      - `out_channels` and head behavior\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        in_channels: int,\n        out_channels: int,\n        input_size: int,\n        patch_size: int,\n        embed_dim: int,\n        depth: int,\n        num_heads: int,\n        cond_dim: Optional[int] = None,\n        mlp_ratio: float = 4.0,\n        use_sincos_pos_embed: bool = True,\n    ):\n        super().__init__()\n        self.in_channels = int(in_channels)\n        self.out_channels = int(out_channels)\n        self.input_size = int(input_size)\n        self.patch_size = int(patch_size)\n        self.embed_dim = int(embed_dim)\n        self.depth = int(depth)\n        self.num_heads = int(num_heads)\n        self.cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n\n        self.patch_embed = ConvPatchEmbed2d(\n            in_channels=self.in_channels,\n            embed_dim=self.embed_dim,\n            patch_size=self.patch_size,\n        )\n\n        num_patches_per_side = self.input_size // self.patch_size\n        if num_patches_per_side * self.patch_size != self.input_size:\n            raise ValueError(\"input_size must be divisible by patch_size\")\n\n        self.use_sincos_pos_embed = bool(use_sincos_pos_embed)\n        if self.use_sincos_pos_embed:\n            pe = build_2d_sincos_pos_embed(self.embed_dim, num_patches_per_side)\n            self.register_buffer(\"pos_embed\", pe.unsqueeze(0), persistent=False)  # (1,N,D)\n        else:\n            self.pos_embed = None\n\n        self.blocks = nn.ModuleList(\n            [\n                AdaLNZeroBlock(\n                    embed_dim=self.embed_dim,\n                    num_heads=self.num_heads,\n                    cond_dim=self.cond_dim,\n                    mlp_ratio=mlp_ratio,\n                )\n                for _ in range(self.depth)\n            ]\n        )\n\n        self.head = AdaLNZeroPatchHead(\n            embed_dim=self.embed_dim,\n            cond_dim=self.cond_dim,\n            patch_size=self.patch_size,\n            out_channels=self.out_channels,\n        )\n\n    def forward(self, x: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n        tokens = self.patch_embed(x)  # (B,N,D)\n        if self.pos_embed is not None:\n            tokens = tokens + self.pos_embed.to(device=tokens.device, dtype=tokens.dtype)\n\n        for block in self.blocks:\n            tokens = block(tokens, cond)\n\n        return self.head(tokens, cond)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.in_channels","title":"in_channels  <code>instance-attribute</code>","text":"<pre><code>in_channels = int(in_channels)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.out_channels","title":"out_channels  <code>instance-attribute</code>","text":"<pre><code>out_channels = int(out_channels)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.input_size","title":"input_size  <code>instance-attribute</code>","text":"<pre><code>input_size = int(input_size)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.patch_size","title":"patch_size  <code>instance-attribute</code>","text":"<pre><code>patch_size = int(patch_size)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.embed_dim","title":"embed_dim  <code>instance-attribute</code>","text":"<pre><code>embed_dim = int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.depth","title":"depth  <code>instance-attribute</code>","text":"<pre><code>depth = int(depth)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.num_heads","title":"num_heads  <code>instance-attribute</code>","text":"<pre><code>num_heads = int(num_heads)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.cond_dim","title":"cond_dim  <code>instance-attribute</code>","text":"<pre><code>cond_dim = int(cond_dim) if cond_dim is not None else int(embed_dim)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.patch_embed","title":"patch_embed  <code>instance-attribute</code>","text":"<pre><code>patch_embed = ConvPatchEmbed2d(in_channels=in_channels, embed_dim=embed_dim, patch_size=patch_size)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.use_sincos_pos_embed","title":"use_sincos_pos_embed  <code>instance-attribute</code>","text":"<pre><code>use_sincos_pos_embed = bool(use_sincos_pos_embed)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.pos_embed","title":"pos_embed  <code>instance-attribute</code>","text":"<pre><code>pos_embed = None\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.blocks","title":"blocks  <code>instance-attribute</code>","text":"<pre><code>blocks = ModuleList([(AdaLNZeroBlock(embed_dim=embed_dim, num_heads=num_heads, cond_dim=cond_dim, mlp_ratio=mlp_ratio)) for _ in (range(depth))])\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.head","title":"head  <code>instance-attribute</code>","text":"<pre><code>head = AdaLNZeroPatchHead(embed_dim=embed_dim, cond_dim=cond_dim, patch_size=patch_size, out_channels=out_channels)\n</code></pre>"},{"location":"api/torchebm/models/conditional_transformer_2d/classes/ConditionalTransformer2D/#torchebm.models.conditional_transformer_2d.ConditionalTransformer2D.forward","title":"forward","text":"<pre><code>forward(x: Tensor, cond: Tensor) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/conditional_transformer_2d.py</code> <pre><code>def forward(self, x: torch.Tensor, cond: torch.Tensor) -&gt; torch.Tensor:\n    tokens = self.patch_embed(x)  # (B,N,D)\n    if self.pos_embed is not None:\n        tokens = tokens + self.pos_embed.to(device=tokens.device, dtype=tokens.dtype)\n\n    for block in self.blocks:\n        tokens = block(tokens, cond)\n\n    return self.head(tokens, cond)\n</code></pre>"},{"location":"api/torchebm/models/wrappers/","title":"Torchebm &gt; Models &gt; Wrappers","text":""},{"location":"api/torchebm/models/wrappers/#torchebm-models-wrappers","title":"Torchebm &gt; Models &gt; Wrappers","text":""},{"location":"api/torchebm/models/wrappers/#contents","title":"Contents","text":""},{"location":"api/torchebm/models/wrappers/#classes","title":"Classes","text":"<ul> <li><code>LabelClassifierFreeGuidance</code> - Classifier-free guidance wrapper for label-conditioned models.</li> </ul>"},{"location":"api/torchebm/models/wrappers/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/models/wrappers/#torchebm.models.wrappers","title":"torchebm.models.wrappers","text":""},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/","title":"LabelClassifierFreeGuidance","text":""},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Module</code></p> <p>Classifier-free guidance wrapper for label-conditioned models.</p> <p>This wrapper is intentionally small and generic: - assumes the base model accepts <code>y</code> (labels) and supports a null label id - performs two forward passes (cond and uncond) - applies guidance to the first <code>guide_channels</code> channels by default</p> <p>It does not assume a specific loss (EqM/diffusion/etc).</p> Expected base signature <p><code>base(x, t, y=..., **kwargs) -&gt; Tensor[B,C,H,W]</code></p> <p>You can use it with <code>FlowSampler</code> by wrapping your model instance.</p> Source code in <code>torchebm/models/wrappers.py</code> <pre><code>class LabelClassifierFreeGuidance(nn.Module):\n    \"\"\"Classifier-free guidance wrapper for label-conditioned models.\n\n    This wrapper is intentionally small and generic:\n    - assumes the base model accepts `y` (labels) and supports a *null label id*\n    - performs two forward passes (cond and uncond)\n    - applies guidance to the first `guide_channels` channels by default\n\n    It does **not** assume a specific loss (EqM/diffusion/etc).\n\n    Expected base signature:\n      `base(x, t, y=..., **kwargs) -&gt; Tensor[B,C,H,W]`\n\n    You can use it with `FlowSampler` by wrapping your model instance.\n    \"\"\"\n\n    def __init__(\n        self,\n        base: nn.Module,\n        *,\n        null_label_id: int,\n        cfg_scale: float = 1.0,\n        guide_channels: int = 3,\n    ):\n        super().__init__()\n        self.base = base\n        self.null_label_id = int(null_label_id)\n        self.cfg_scale = float(cfg_scale)\n        self.guide_channels = int(guide_channels)\n\n    def forward(self, x: torch.Tensor, t: torch.Tensor, *, y: torch.Tensor, **kwargs) -&gt; torch.Tensor:\n        if self.cfg_scale &lt;= 1.0:\n            return self.base(x, t, y=y, **kwargs)\n\n        y_null = torch.full_like(y, fill_value=self.null_label_id)\n\n        cond = self.base(x, t, y=y, **kwargs)\n        uncond = self.base(x, t, y=y_null, **kwargs)\n\n        c = min(self.guide_channels, cond.shape[1])\n        guided = uncond[:, :c] + self.cfg_scale * (cond[:, :c] - uncond[:, :c])\n\n        if c == cond.shape[1]:\n            return guided\n        return torch.cat([guided, uncond[:, c:]], dim=1)\n</code></pre>"},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#torchebm.models.wrappers.LabelClassifierFreeGuidance.base","title":"base  <code>instance-attribute</code>","text":"<pre><code>base = base\n</code></pre>"},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#torchebm.models.wrappers.LabelClassifierFreeGuidance.null_label_id","title":"null_label_id  <code>instance-attribute</code>","text":"<pre><code>null_label_id = int(null_label_id)\n</code></pre>"},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#torchebm.models.wrappers.LabelClassifierFreeGuidance.cfg_scale","title":"cfg_scale  <code>instance-attribute</code>","text":"<pre><code>cfg_scale = float(cfg_scale)\n</code></pre>"},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#torchebm.models.wrappers.LabelClassifierFreeGuidance.guide_channels","title":"guide_channels  <code>instance-attribute</code>","text":"<pre><code>guide_channels = int(guide_channels)\n</code></pre>"},{"location":"api/torchebm/models/wrappers/classes/LabelClassifierFreeGuidance/#torchebm.models.wrappers.LabelClassifierFreeGuidance.forward","title":"forward","text":"<pre><code>forward(x: Tensor, t: Tensor, *, y: Tensor, **kwargs) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/models/wrappers.py</code> <pre><code>def forward(self, x: torch.Tensor, t: torch.Tensor, *, y: torch.Tensor, **kwargs) -&gt; torch.Tensor:\n    if self.cfg_scale &lt;= 1.0:\n        return self.base(x, t, y=y, **kwargs)\n\n    y_null = torch.full_like(y, fill_value=self.null_label_id)\n\n    cond = self.base(x, t, y=y, **kwargs)\n    uncond = self.base(x, t, y=y_null, **kwargs)\n\n    c = min(self.guide_channels, cond.shape[1])\n    guided = uncond[:, :c] + self.cfg_scale * (cond[:, :c] - uncond[:, :c])\n\n    if c == cond.shape[1]:\n        return guided\n    return torch.cat([guided, uncond[:, c:]], dim=1)\n</code></pre>"},{"location":"api/torchebm/samplers/","title":"Torchebm &gt; Samplers","text":""},{"location":"api/torchebm/samplers/#torchebm-samplers","title":"Torchebm &gt; Samplers","text":""},{"location":"api/torchebm/samplers/#contents","title":"Contents","text":""},{"location":"api/torchebm/samplers/#modules","title":"Modules","text":"<ul> <li>Flow</li> <li>Gradient_descent</li> <li>Hmc</li> <li>Langevin_dynamics</li> </ul>"},{"location":"api/torchebm/samplers/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/samplers/#torchebm.samplers","title":"torchebm.samplers","text":"<p>Sampling algorithms for energy-based models and generative models.</p> <p>Includes: - MCMC samplers (Langevin dynamics, HMC) for energy-based models - Gradient-based optimization samplers for energy minimization - Flow/diffusion samplers for trained generative models</p>"},{"location":"api/torchebm/samplers/flow/","title":"Torchebm &gt; Samplers &gt; Flow","text":""},{"location":"api/torchebm/samplers/flow/#torchebm-samplers-flow","title":"Torchebm &gt; Samplers &gt; Flow","text":""},{"location":"api/torchebm/samplers/flow/#contents","title":"Contents","text":""},{"location":"api/torchebm/samplers/flow/#classes","title":"Classes","text":"<ul> <li><code>FlowSampler</code> - Sampler for flow-based and diffusion generative models.</li> <li><code>PredictionType</code> - Model prediction type for generative models.</li> </ul>"},{"location":"api/torchebm/samplers/flow/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/samplers/flow/#torchebm.samplers.flow","title":"torchebm.samplers.flow","text":"<p>Flow-based sampler for trained generative models.</p> <p>Supports both ODE (probability flow) and SDE (diffusion) sampling modes with various numerical integration methods.</p>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/","title":"FlowSampler","text":""},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Sampler for flow-based and diffusion generative models.</p> <p>Supports ODE (probability flow) and SDE (diffusion) sampling with various numerical integration methods including Euler, Heun, and adaptive solvers.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Trained neural network predicting velocity/score/noise.</p> required <code>interpolant</code> <code>Union[str, BaseInterpolant]</code> <p>Interpolant type ('linear', 'cosine', 'vp') or instance.</p> <code>'linear'</code> <code>prediction</code> <code>Literal['velocity', 'score', 'noise']</code> <p>Model prediction type ('velocity', 'score', or 'noise').</p> <code>'velocity'</code> <code>train_eps</code> <code>float</code> <p>Epsilon used during training for time interval stability.</p> <code>0.0</code> <code>sample_eps</code> <code>float</code> <p>Epsilon for sampling time interval.</p> <code>0.0</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision.</p> <code>False</code> Example <pre><code>from torchebm.samplers import FlowSampler\nimport torch.nn as nn\nimport torch\n\nmodel = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 2))\nsampler = FlowSampler(\n    model=model,\n    interpolant=\"linear\",\n    prediction=\"velocity\",\n)\nz = torch.randn(100, 2)\nsamples = sampler.sample_ode(z, num_steps=50, method=\"euler\")\n</code></pre> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>class FlowSampler(BaseSampler):\n    r\"\"\"\n    Sampler for flow-based and diffusion generative models.\n\n    Supports ODE (probability flow) and SDE (diffusion) sampling with various\n    numerical integration methods including Euler, Heun, and adaptive solvers.\n\n    Args:\n        model: Trained neural network predicting velocity/score/noise.\n        interpolant: Interpolant type ('linear', 'cosine', 'vp') or instance.\n        prediction: Model prediction type ('velocity', 'score', or 'noise').\n        train_eps: Epsilon used during training for time interval stability.\n        sample_eps: Epsilon for sampling time interval.\n        dtype: Data type for computations.\n        device: Device for computations.\n        use_mixed_precision: Whether to use mixed precision.\n\n    Example:\n        ```python\n        from torchebm.samplers import FlowSampler\n        import torch.nn as nn\n        import torch\n\n        model = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 2))\n        sampler = FlowSampler(\n            model=model,\n            interpolant=\"linear\",\n            prediction=\"velocity\",\n        )\n        z = torch.randn(100, 2)\n        samples = sampler.sample_ode(z, num_steps=50, method=\"euler\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: nn.Module,\n        interpolant: Union[str, BaseInterpolant] = \"linear\",\n        prediction: Literal[\"velocity\", \"score\", \"noise\"] = \"velocity\",\n        train_eps: float = 0.0,\n        sample_eps: float = 0.0,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n        )\n        self.train_eps = train_eps\n        self.sample_eps = sample_eps\n\n        if isinstance(interpolant, str):\n            self.interpolant = get_interpolant(interpolant)\n        else:\n            self.interpolant = interpolant\n\n        prediction_map = {\n            \"velocity\": PredictionType.VELOCITY,\n            \"score\": PredictionType.SCORE,\n            \"noise\": PredictionType.NOISE,\n        }\n        self.prediction_type = prediction_map[prediction]\n\n        self.interpolant = BaseSampler.safe_to(\n            self.interpolant, device=self.device, dtype=self.dtype\n        )\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 50,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *,\n        mode: Literal[\"ode\", \"sde\"] = \"ode\",\n        shape: Optional[Tuple[int, ...]] = None,\n        ode_method: str = \"dopri5\",\n        atol: float = 1e-6,\n        rtol: float = 1e-3,\n        reverse: bool = False,\n        sde_method: str = \"euler\",\n        diffusion_form: str = \"SBDM\",\n        diffusion_norm: float = 1.0,\n        last_step: Optional[str] = \"Mean\",\n        last_step_size: float = 0.04,\n        **model_kwargs,\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Unified sampling entrypoint for flow/diffusion models.\n\n        This method exists for API compatibility with `BaseSampler`. For full control,\n        prefer calling `sample_ode` or `sample_sde` directly.\n        \"\"\"\n        if thin != 1:\n            raise ValueError(\"thin is not supported for FlowSampler\")\n        if return_trajectory or return_diagnostics:\n            raise ValueError(\"FlowSampler does not support trajectories/diagnostics\")\n\n        if x is None:\n            if shape is not None:\n                z = torch.randn(*shape, device=self.device, dtype=self.dtype)\n            else:\n                z = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n        else:\n            z = x.to(device=self.device, dtype=self.dtype)\n\n        if mode == \"ode\":\n            return self.sample_ode(\n                z=z,\n                num_steps=n_steps,\n                method=ode_method,\n                atol=atol,\n                rtol=rtol,\n                reverse=reverse,\n                **model_kwargs,\n            )\n        if mode == \"sde\":\n            return self.sample_sde(\n                z=z,\n                num_steps=n_steps,\n                method=sde_method,\n                diffusion_form=diffusion_form,\n                diffusion_norm=diffusion_norm,\n                last_step=last_step,\n                last_step_size=last_step_size,\n                **model_kwargs,\n            )\n        raise ValueError(f\"Unknown mode: {mode}\")\n\n    def _get_drift(self) -&gt; Callable:\n        r\"\"\"Get drift function for probability flow ODE.\"\"\"\n\n        def velocity_drift(x, t, **model_kwargs):\n            return self.model(x, t, **model_kwargs)\n\n        def score_drift(x, t, **model_kwargs):\n            drift_mean, drift_var = self.interpolant.compute_drift(x, t)\n            model_output = self.model(x, t, **model_kwargs)\n            return -drift_mean + drift_var * model_output\n\n        def noise_drift(x, t, **model_kwargs):\n            drift_mean, drift_var = self.interpolant.compute_drift(x, t)\n            t_expanded = expand_t_like_x(t, x)\n            sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n            model_output = self.model(x, t, **model_kwargs)\n            score = model_output / (-sigma_t + 1e-8)\n            return -drift_mean + drift_var * score\n\n        drifts = {\n            PredictionType.VELOCITY: velocity_drift,\n            PredictionType.SCORE: score_drift,\n            PredictionType.NOISE: noise_drift,\n        }\n        return drifts[self.prediction_type]\n\n    def _get_score(self) -&gt; Callable:\n        r\"\"\"Get score function from model output.\"\"\"\n\n        def velocity_score(x, t, **model_kwargs):\n            velocity = self.model(x, t, **model_kwargs)\n            return self.interpolant.velocity_to_score(velocity, x, t)\n\n        def score_score(x, t, **model_kwargs):\n            return self.model(x, t, **model_kwargs)\n\n        def noise_score(x, t, **model_kwargs):\n            t_expanded = expand_t_like_x(t, x)\n            sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n            return self.model(x, t, **model_kwargs) / (-sigma_t + 1e-8)\n\n        scores = {\n            PredictionType.VELOCITY: velocity_score,\n            PredictionType.SCORE: score_score,\n            PredictionType.NOISE: noise_score,\n        }\n        return scores[self.prediction_type]\n\n    def _check_interval(\n        self,\n        sde: bool = False,\n        reverse: bool = False,\n        last_step_size: float = 0.0,\n        diffusion_form: str = \"SBDM\",\n    ) -&gt; Tuple[float, float]:\n        r\"\"\"Compute time interval for sampling.\"\"\"\n        t0 = 0.0\n        t1 = 1.0\n        eps = self.sample_eps\n\n        is_vp = isinstance(self.interpolant, VariancePreservingInterpolant)\n        is_linear_or_cosine = isinstance(\n            self.interpolant, (LinearInterpolant, CosineInterpolant)\n        )\n\n        if is_vp:\n            t1 = 1 - eps if (not sde or last_step_size == 0) else 1 - last_step_size\n        elif is_linear_or_cosine and (\n            self.prediction_type != PredictionType.VELOCITY or sde\n        ):\n            t0 = (\n                eps\n                if (diffusion_form == \"SBDM\" and sde)\n                or self.prediction_type != PredictionType.VELOCITY\n                else 0\n            )\n            t1 = 1 - eps if (not sde or last_step_size == 0) else 1 - last_step_size\n\n        if reverse:\n            t0, t1 = 1 - t0, 1 - t1\n\n        return t0, t1\n\n    @torch.no_grad()\n    def sample_ode(\n        self,\n        z: torch.Tensor,\n        num_steps: int = 50,\n        method: str = \"dopri5\",\n        atol: float = 1e-6,\n        rtol: float = 1e-3,\n        reverse: bool = False,\n        **model_kwargs,\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Sample using probability flow ODE.\n\n        Args:\n            z: Initial noise tensor of shape (batch_size, ...).\n            num_steps: Number of discretization steps (for fixed-step methods).\n            method: ODE solver ('euler', 'heun', 'dopri5', 'dopri8').\n            atol: Absolute tolerance for adaptive solvers.\n            rtol: Relative tolerance for adaptive solvers.\n            reverse: If True, sample from data to noise.\n            **model_kwargs: Additional arguments passed to the model.\n\n        Returns:\n            Generated samples tensor.\n        \"\"\"\n        z = z.to(device=self.device, dtype=self.dtype)\n        drift_fn = self._get_drift()\n\n        t0, t1 = self._check_interval(sde=False, reverse=reverse)\n        t = torch.linspace(t0, t1, num_steps, device=self.device, dtype=self.dtype)\n\n        if reverse:\n\n            def wrapped_drift(x, t_val, **kwargs):\n                return drift_fn(x, torch.ones_like(t_val) * (1 - t_val), **kwargs)\n\n        else:\n            wrapped_drift = drift_fn\n\n        def ode_fn(t_val, x):\n            t_batch = (\n                torch.ones(x.size(0), device=self.device, dtype=self.dtype) * t_val\n            )\n            return wrapped_drift(x, t_batch, **model_kwargs)\n\n        def fixed_step_drift(x, t_batch):\n            return wrapped_drift(x, t_batch, **model_kwargs)\n\n        if method in [\"dopri5\", \"dopri8\", \"bosh3\", \"adaptive_heun\"]:\n            if not HAS_TORCHDIFFEQ:\n                raise ImportError(\"torchdiffeq required for adaptive solvers\")\n            samples = odeint(ode_fn, z, t, method=method, atol=atol, rtol=rtol)\n            return samples[-1]\n        if method == \"euler\":\n            integrator = EulerMaruyamaIntegrator(device=self.device, dtype=self.dtype)\n            return integrator.integrate(\n                state={\"x\": z},\n                model=None,\n                step_size=t[1] - t[0],\n                n_steps=num_steps,\n                drift=fixed_step_drift,\n                t=t,\n            )[\"x\"]\n        if method == \"heun\":\n            integrator = HeunIntegrator(device=self.device, dtype=self.dtype)\n            return integrator.integrate(\n                state={\"x\": z},\n                model=None,\n                step_size=t[1] - t[0],\n                n_steps=num_steps,\n                drift=fixed_step_drift,\n                t=t,\n            )[\"x\"]\n        raise ValueError(f\"Unknown ODE method: {method}\")\n\n    @torch.no_grad()\n    def sample_sde(\n        self,\n        z: torch.Tensor,\n        num_steps: int = 250,\n        method: str = \"euler\",\n        diffusion_form: str = \"SBDM\",\n        diffusion_norm: float = 1.0,\n        last_step: Optional[str] = \"Mean\",\n        last_step_size: float = 0.04,\n        **model_kwargs,\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Sample using reverse-time SDE.\n\n        Args:\n            z: Initial noise tensor of shape (batch_size, ...).\n            num_steps: Number of discretization steps.\n            method: SDE solver ('euler', 'heun').\n            diffusion_form: Form of diffusion coefficient ('SBDM', 'constant', 'sigma').\n            diffusion_norm: Scaling factor for diffusion.\n            last_step: Type of last step ('Mean', 'Tweedie', 'Euler', or None).\n            last_step_size: Size of the last step.\n            **model_kwargs: Additional arguments passed to the model.\n\n        Returns:\n            Generated samples tensor.\n        \"\"\"\n        z = z.to(device=self.device, dtype=self.dtype)\n\n        if last_step is None:\n            last_step_size = 0.0\n\n        t0, t1 = self._check_interval(\n            sde=True, last_step_size=last_step_size, diffusion_form=diffusion_form\n        )\n        t = torch.linspace(t0, t1, num_steps, device=self.device, dtype=self.dtype)\n\n        drift_fn = self._get_drift()\n        score_fn = self._get_score()\n\n        def diffusion_fn(x, t_val):\n            return self.interpolant.compute_diffusion(\n                x, t_val, form=diffusion_form, norm=diffusion_norm\n            )\n\n        def sde_drift(x, t_val, **kwargs):\n            diffusion = diffusion_fn(x, t_val)\n            return drift_fn(x, t_val, **kwargs) + diffusion * score_fn(\n                x, t_val, **kwargs\n            )\n\n        def fixed_sde_drift(x, t_val):\n            return sde_drift(x, t_val, **model_kwargs)\n\n        if method == \"euler\":\n            integrator = EulerMaruyamaIntegrator(device=self.device, dtype=self.dtype)\n            x = integrator.integrate(\n                state={\"x\": z},\n                model=None,\n                step_size=t[1] - t[0],\n                n_steps=num_steps,\n                drift=fixed_sde_drift,\n                diffusion=diffusion_fn,\n                t=t,\n            )[\"x\"]\n        elif method == \"heun\":\n            integrator = HeunIntegrator(device=self.device, dtype=self.dtype)\n            x = integrator.integrate(\n                state={\"x\": z},\n                model=None,\n                step_size=t[1] - t[0],\n                n_steps=num_steps,\n                drift=fixed_sde_drift,\n                diffusion=diffusion_fn,\n                t=t,\n            )[\"x\"]\n        else:\n            raise ValueError(f\"Unknown SDE method: {method}\")\n\n        # Apply last step\n        if last_step is not None:\n            t_final = torch.ones(x.size(0), device=self.device, dtype=self.dtype) * t1\n            x = self._apply_last_step(\n                x, t_final, sde_drift, last_step, last_step_size, **model_kwargs\n            )\n\n        return x\n\n    def _apply_last_step(\n        self,\n        x: torch.Tensor,\n        t: torch.Tensor,\n        sde_drift: Callable,\n        last_step: str,\n        last_step_size: float,\n        **model_kwargs,\n    ) -&gt; torch.Tensor:\n        r\"\"\"Apply final denoising step.\"\"\"\n        if last_step == \"Mean\":\n            return x + sde_drift(x, t, **model_kwargs) * last_step_size\n        elif last_step == \"Euler\":\n            drift_fn = self._get_drift()\n            return x + drift_fn(x, t, **model_kwargs) * last_step_size\n        elif last_step == \"Tweedie\":\n            t_expanded = expand_t_like_x(t, x)\n            alpha, _ = self.interpolant.compute_alpha_t(t_expanded)\n            sigma, _ = self.interpolant.compute_sigma_t(t_expanded)\n            score = self._get_score()(x, t, **model_kwargs)\n            return x / alpha + (sigma**2) / alpha * score\n        else:\n            return x\n\n    def prior_logp(self, z: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"Compute log probability under standard Gaussian prior.\"\"\"\n        shape = torch.tensor(z.size())\n        N = torch.prod(shape[1:])\n        return (\n            -N / 2.0 * np.log(2 * np.pi)\n            - torch.sum(z**2, dim=tuple(range(1, z.ndim))) / 2.0\n        )\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.train_eps","title":"train_eps  <code>instance-attribute</code>","text":"<pre><code>train_eps = train_eps\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.sample_eps","title":"sample_eps  <code>instance-attribute</code>","text":"<pre><code>sample_eps = sample_eps\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.prediction_type","title":"prediction_type  <code>instance-attribute</code>","text":"<pre><code>prediction_type = prediction_map[prediction]\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.interpolant","title":"interpolant  <code>instance-attribute</code>","text":"<pre><code>interpolant = safe_to(interpolant, device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.sample","title":"sample","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: int = 10, n_steps: int = 50, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False, *, mode: Literal['ode', 'sde'] = 'ode', shape: Optional[Tuple[int, ...]] = None, ode_method: str = 'dopri5', atol: float = 1e-06, rtol: float = 0.001, reverse: bool = False, sde_method: str = 'euler', diffusion_form: str = 'SBDM', diffusion_norm: float = 1.0, last_step: Optional[str] = 'Mean', last_step_size: float = 0.04, **model_kwargs) -&gt; torch.Tensor\n</code></pre> <p>Unified sampling entrypoint for flow/diffusion models.</p> <p>This method exists for API compatibility with <code>BaseSampler</code>. For full control, prefer calling <code>sample_ode</code> or <code>sample_sde</code> directly.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>@torch.no_grad()\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: int = 10,\n    n_steps: int = 50,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n    *,\n    mode: Literal[\"ode\", \"sde\"] = \"ode\",\n    shape: Optional[Tuple[int, ...]] = None,\n    ode_method: str = \"dopri5\",\n    atol: float = 1e-6,\n    rtol: float = 1e-3,\n    reverse: bool = False,\n    sde_method: str = \"euler\",\n    diffusion_form: str = \"SBDM\",\n    diffusion_norm: float = 1.0,\n    last_step: Optional[str] = \"Mean\",\n    last_step_size: float = 0.04,\n    **model_kwargs,\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Unified sampling entrypoint for flow/diffusion models.\n\n    This method exists for API compatibility with `BaseSampler`. For full control,\n    prefer calling `sample_ode` or `sample_sde` directly.\n    \"\"\"\n    if thin != 1:\n        raise ValueError(\"thin is not supported for FlowSampler\")\n    if return_trajectory or return_diagnostics:\n        raise ValueError(\"FlowSampler does not support trajectories/diagnostics\")\n\n    if x is None:\n        if shape is not None:\n            z = torch.randn(*shape, device=self.device, dtype=self.dtype)\n        else:\n            z = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n    else:\n        z = x.to(device=self.device, dtype=self.dtype)\n\n    if mode == \"ode\":\n        return self.sample_ode(\n            z=z,\n            num_steps=n_steps,\n            method=ode_method,\n            atol=atol,\n            rtol=rtol,\n            reverse=reverse,\n            **model_kwargs,\n        )\n    if mode == \"sde\":\n        return self.sample_sde(\n            z=z,\n            num_steps=n_steps,\n            method=sde_method,\n            diffusion_form=diffusion_form,\n            diffusion_norm=diffusion_norm,\n            last_step=last_step,\n            last_step_size=last_step_size,\n            **model_kwargs,\n        )\n    raise ValueError(f\"Unknown mode: {mode}\")\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler._get_drift","title":"_get_drift","text":"<pre><code>_get_drift() -&gt; Callable\n</code></pre> <p>Get drift function for probability flow ODE.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>def _get_drift(self) -&gt; Callable:\n    r\"\"\"Get drift function for probability flow ODE.\"\"\"\n\n    def velocity_drift(x, t, **model_kwargs):\n        return self.model(x, t, **model_kwargs)\n\n    def score_drift(x, t, **model_kwargs):\n        drift_mean, drift_var = self.interpolant.compute_drift(x, t)\n        model_output = self.model(x, t, **model_kwargs)\n        return -drift_mean + drift_var * model_output\n\n    def noise_drift(x, t, **model_kwargs):\n        drift_mean, drift_var = self.interpolant.compute_drift(x, t)\n        t_expanded = expand_t_like_x(t, x)\n        sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n        model_output = self.model(x, t, **model_kwargs)\n        score = model_output / (-sigma_t + 1e-8)\n        return -drift_mean + drift_var * score\n\n    drifts = {\n        PredictionType.VELOCITY: velocity_drift,\n        PredictionType.SCORE: score_drift,\n        PredictionType.NOISE: noise_drift,\n    }\n    return drifts[self.prediction_type]\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler._get_score","title":"_get_score","text":"<pre><code>_get_score() -&gt; Callable\n</code></pre> <p>Get score function from model output.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>def _get_score(self) -&gt; Callable:\n    r\"\"\"Get score function from model output.\"\"\"\n\n    def velocity_score(x, t, **model_kwargs):\n        velocity = self.model(x, t, **model_kwargs)\n        return self.interpolant.velocity_to_score(velocity, x, t)\n\n    def score_score(x, t, **model_kwargs):\n        return self.model(x, t, **model_kwargs)\n\n    def noise_score(x, t, **model_kwargs):\n        t_expanded = expand_t_like_x(t, x)\n        sigma_t, _ = self.interpolant.compute_sigma_t(t_expanded)\n        return self.model(x, t, **model_kwargs) / (-sigma_t + 1e-8)\n\n    scores = {\n        PredictionType.VELOCITY: velocity_score,\n        PredictionType.SCORE: score_score,\n        PredictionType.NOISE: noise_score,\n    }\n    return scores[self.prediction_type]\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler._check_interval","title":"_check_interval","text":"<pre><code>_check_interval(sde: bool = False, reverse: bool = False, last_step_size: float = 0.0, diffusion_form: str = 'SBDM') -&gt; Tuple[float, float]\n</code></pre> <p>Compute time interval for sampling.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>def _check_interval(\n    self,\n    sde: bool = False,\n    reverse: bool = False,\n    last_step_size: float = 0.0,\n    diffusion_form: str = \"SBDM\",\n) -&gt; Tuple[float, float]:\n    r\"\"\"Compute time interval for sampling.\"\"\"\n    t0 = 0.0\n    t1 = 1.0\n    eps = self.sample_eps\n\n    is_vp = isinstance(self.interpolant, VariancePreservingInterpolant)\n    is_linear_or_cosine = isinstance(\n        self.interpolant, (LinearInterpolant, CosineInterpolant)\n    )\n\n    if is_vp:\n        t1 = 1 - eps if (not sde or last_step_size == 0) else 1 - last_step_size\n    elif is_linear_or_cosine and (\n        self.prediction_type != PredictionType.VELOCITY or sde\n    ):\n        t0 = (\n            eps\n            if (diffusion_form == \"SBDM\" and sde)\n            or self.prediction_type != PredictionType.VELOCITY\n            else 0\n        )\n        t1 = 1 - eps if (not sde or last_step_size == 0) else 1 - last_step_size\n\n    if reverse:\n        t0, t1 = 1 - t0, 1 - t1\n\n    return t0, t1\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.sample_ode","title":"sample_ode","text":"<pre><code>sample_ode(z: Tensor, num_steps: int = 50, method: str = 'dopri5', atol: float = 1e-06, rtol: float = 0.001, reverse: bool = False, **model_kwargs) -&gt; torch.Tensor\n</code></pre> <p>Sample using probability flow ODE.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Tensor</code> <p>Initial noise tensor of shape (batch_size, ...).</p> required <code>num_steps</code> <code>int</code> <p>Number of discretization steps (for fixed-step methods).</p> <code>50</code> <code>method</code> <code>str</code> <p>ODE solver ('euler', 'heun', 'dopri5', 'dopri8').</p> <code>'dopri5'</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive solvers.</p> <code>1e-06</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive solvers.</p> <code>0.001</code> <code>reverse</code> <code>bool</code> <p>If True, sample from data to noise.</p> <code>False</code> <code>**model_kwargs</code> <p>Additional arguments passed to the model.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Generated samples tensor.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>@torch.no_grad()\ndef sample_ode(\n    self,\n    z: torch.Tensor,\n    num_steps: int = 50,\n    method: str = \"dopri5\",\n    atol: float = 1e-6,\n    rtol: float = 1e-3,\n    reverse: bool = False,\n    **model_kwargs,\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Sample using probability flow ODE.\n\n    Args:\n        z: Initial noise tensor of shape (batch_size, ...).\n        num_steps: Number of discretization steps (for fixed-step methods).\n        method: ODE solver ('euler', 'heun', 'dopri5', 'dopri8').\n        atol: Absolute tolerance for adaptive solvers.\n        rtol: Relative tolerance for adaptive solvers.\n        reverse: If True, sample from data to noise.\n        **model_kwargs: Additional arguments passed to the model.\n\n    Returns:\n        Generated samples tensor.\n    \"\"\"\n    z = z.to(device=self.device, dtype=self.dtype)\n    drift_fn = self._get_drift()\n\n    t0, t1 = self._check_interval(sde=False, reverse=reverse)\n    t = torch.linspace(t0, t1, num_steps, device=self.device, dtype=self.dtype)\n\n    if reverse:\n\n        def wrapped_drift(x, t_val, **kwargs):\n            return drift_fn(x, torch.ones_like(t_val) * (1 - t_val), **kwargs)\n\n    else:\n        wrapped_drift = drift_fn\n\n    def ode_fn(t_val, x):\n        t_batch = (\n            torch.ones(x.size(0), device=self.device, dtype=self.dtype) * t_val\n        )\n        return wrapped_drift(x, t_batch, **model_kwargs)\n\n    def fixed_step_drift(x, t_batch):\n        return wrapped_drift(x, t_batch, **model_kwargs)\n\n    if method in [\"dopri5\", \"dopri8\", \"bosh3\", \"adaptive_heun\"]:\n        if not HAS_TORCHDIFFEQ:\n            raise ImportError(\"torchdiffeq required for adaptive solvers\")\n        samples = odeint(ode_fn, z, t, method=method, atol=atol, rtol=rtol)\n        return samples[-1]\n    if method == \"euler\":\n        integrator = EulerMaruyamaIntegrator(device=self.device, dtype=self.dtype)\n        return integrator.integrate(\n            state={\"x\": z},\n            model=None,\n            step_size=t[1] - t[0],\n            n_steps=num_steps,\n            drift=fixed_step_drift,\n            t=t,\n        )[\"x\"]\n    if method == \"heun\":\n        integrator = HeunIntegrator(device=self.device, dtype=self.dtype)\n        return integrator.integrate(\n            state={\"x\": z},\n            model=None,\n            step_size=t[1] - t[0],\n            n_steps=num_steps,\n            drift=fixed_step_drift,\n            t=t,\n        )[\"x\"]\n    raise ValueError(f\"Unknown ODE method: {method}\")\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.sample_sde","title":"sample_sde","text":"<pre><code>sample_sde(z: Tensor, num_steps: int = 250, method: str = 'euler', diffusion_form: str = 'SBDM', diffusion_norm: float = 1.0, last_step: Optional[str] = 'Mean', last_step_size: float = 0.04, **model_kwargs) -&gt; torch.Tensor\n</code></pre> <p>Sample using reverse-time SDE.</p> <p>Parameters:</p> Name Type Description Default <code>z</code> <code>Tensor</code> <p>Initial noise tensor of shape (batch_size, ...).</p> required <code>num_steps</code> <code>int</code> <p>Number of discretization steps.</p> <code>250</code> <code>method</code> <code>str</code> <p>SDE solver ('euler', 'heun').</p> <code>'euler'</code> <code>diffusion_form</code> <code>str</code> <p>Form of diffusion coefficient ('SBDM', 'constant', 'sigma').</p> <code>'SBDM'</code> <code>diffusion_norm</code> <code>float</code> <p>Scaling factor for diffusion.</p> <code>1.0</code> <code>last_step</code> <code>Optional[str]</code> <p>Type of last step ('Mean', 'Tweedie', 'Euler', or None).</p> <code>'Mean'</code> <code>last_step_size</code> <code>float</code> <p>Size of the last step.</p> <code>0.04</code> <code>**model_kwargs</code> <p>Additional arguments passed to the model.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Generated samples tensor.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>@torch.no_grad()\ndef sample_sde(\n    self,\n    z: torch.Tensor,\n    num_steps: int = 250,\n    method: str = \"euler\",\n    diffusion_form: str = \"SBDM\",\n    diffusion_norm: float = 1.0,\n    last_step: Optional[str] = \"Mean\",\n    last_step_size: float = 0.04,\n    **model_kwargs,\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Sample using reverse-time SDE.\n\n    Args:\n        z: Initial noise tensor of shape (batch_size, ...).\n        num_steps: Number of discretization steps.\n        method: SDE solver ('euler', 'heun').\n        diffusion_form: Form of diffusion coefficient ('SBDM', 'constant', 'sigma').\n        diffusion_norm: Scaling factor for diffusion.\n        last_step: Type of last step ('Mean', 'Tweedie', 'Euler', or None).\n        last_step_size: Size of the last step.\n        **model_kwargs: Additional arguments passed to the model.\n\n    Returns:\n        Generated samples tensor.\n    \"\"\"\n    z = z.to(device=self.device, dtype=self.dtype)\n\n    if last_step is None:\n        last_step_size = 0.0\n\n    t0, t1 = self._check_interval(\n        sde=True, last_step_size=last_step_size, diffusion_form=diffusion_form\n    )\n    t = torch.linspace(t0, t1, num_steps, device=self.device, dtype=self.dtype)\n\n    drift_fn = self._get_drift()\n    score_fn = self._get_score()\n\n    def diffusion_fn(x, t_val):\n        return self.interpolant.compute_diffusion(\n            x, t_val, form=diffusion_form, norm=diffusion_norm\n        )\n\n    def sde_drift(x, t_val, **kwargs):\n        diffusion = diffusion_fn(x, t_val)\n        return drift_fn(x, t_val, **kwargs) + diffusion * score_fn(\n            x, t_val, **kwargs\n        )\n\n    def fixed_sde_drift(x, t_val):\n        return sde_drift(x, t_val, **model_kwargs)\n\n    if method == \"euler\":\n        integrator = EulerMaruyamaIntegrator(device=self.device, dtype=self.dtype)\n        x = integrator.integrate(\n            state={\"x\": z},\n            model=None,\n            step_size=t[1] - t[0],\n            n_steps=num_steps,\n            drift=fixed_sde_drift,\n            diffusion=diffusion_fn,\n            t=t,\n        )[\"x\"]\n    elif method == \"heun\":\n        integrator = HeunIntegrator(device=self.device, dtype=self.dtype)\n        x = integrator.integrate(\n            state={\"x\": z},\n            model=None,\n            step_size=t[1] - t[0],\n            n_steps=num_steps,\n            drift=fixed_sde_drift,\n            diffusion=diffusion_fn,\n            t=t,\n        )[\"x\"]\n    else:\n        raise ValueError(f\"Unknown SDE method: {method}\")\n\n    # Apply last step\n    if last_step is not None:\n        t_final = torch.ones(x.size(0), device=self.device, dtype=self.dtype) * t1\n        x = self._apply_last_step(\n            x, t_final, sde_drift, last_step, last_step_size, **model_kwargs\n        )\n\n    return x\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler._apply_last_step","title":"_apply_last_step","text":"<pre><code>_apply_last_step(x: Tensor, t: Tensor, sde_drift: Callable, last_step: str, last_step_size: float, **model_kwargs) -&gt; torch.Tensor\n</code></pre> <p>Apply final denoising step.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>def _apply_last_step(\n    self,\n    x: torch.Tensor,\n    t: torch.Tensor,\n    sde_drift: Callable,\n    last_step: str,\n    last_step_size: float,\n    **model_kwargs,\n) -&gt; torch.Tensor:\n    r\"\"\"Apply final denoising step.\"\"\"\n    if last_step == \"Mean\":\n        return x + sde_drift(x, t, **model_kwargs) * last_step_size\n    elif last_step == \"Euler\":\n        drift_fn = self._get_drift()\n        return x + drift_fn(x, t, **model_kwargs) * last_step_size\n    elif last_step == \"Tweedie\":\n        t_expanded = expand_t_like_x(t, x)\n        alpha, _ = self.interpolant.compute_alpha_t(t_expanded)\n        sigma, _ = self.interpolant.compute_sigma_t(t_expanded)\n        score = self._get_score()(x, t, **model_kwargs)\n        return x / alpha + (sigma**2) / alpha * score\n    else:\n        return x\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/FlowSampler/#torchebm.samplers.flow.FlowSampler.prior_logp","title":"prior_logp","text":"<pre><code>prior_logp(z: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Compute log probability under standard Gaussian prior.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>def prior_logp(self, z: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"Compute log probability under standard Gaussian prior.\"\"\"\n    shape = torch.tensor(z.size())\n    N = torch.prod(shape[1:])\n    return (\n        -N / 2.0 * np.log(2 * np.pi)\n        - torch.sum(z**2, dim=tuple(range(1, z.ndim))) / 2.0\n    )\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/PredictionType/","title":"PredictionType","text":""},{"location":"api/torchebm/samplers/flow/classes/PredictionType/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>Enum</code></p> <p>Model prediction type for generative models.</p> Source code in <code>torchebm/samplers/flow.py</code> <pre><code>class PredictionType(enum.Enum):\n    r\"\"\"Model prediction type for generative models.\"\"\"\n\n    NOISE = enum.auto()\n    SCORE = enum.auto()\n    VELOCITY = enum.auto()\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/PredictionType/#torchebm.samplers.flow.PredictionType.NOISE","title":"NOISE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>NOISE = auto()\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/PredictionType/#torchebm.samplers.flow.PredictionType.SCORE","title":"SCORE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SCORE = auto()\n</code></pre>"},{"location":"api/torchebm/samplers/flow/classes/PredictionType/#torchebm.samplers.flow.PredictionType.VELOCITY","title":"VELOCITY  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>VELOCITY = auto()\n</code></pre>"},{"location":"api/torchebm/samplers/gradient_descent/","title":"Torchebm &gt; Samplers &gt; Gradient_descent","text":""},{"location":"api/torchebm/samplers/gradient_descent/#torchebm-samplers-gradient_descent","title":"Torchebm &gt; Samplers &gt; Gradient_descent","text":""},{"location":"api/torchebm/samplers/gradient_descent/#contents","title":"Contents","text":""},{"location":"api/torchebm/samplers/gradient_descent/#classes","title":"Classes","text":"<ul> <li><code>GradientDescentSampler</code> - Gradient descent sampler for energy-based models.</li> <li><code>NesterovSampler</code> - Nesterov accelerated gradient sampler for energy-based models.</li> </ul>"},{"location":"api/torchebm/samplers/gradient_descent/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/samplers/gradient_descent/#torchebm.samplers.gradient_descent","title":"torchebm.samplers.gradient_descent","text":"<p>Gradient-based optimization samplers.</p> <p>First-order optimization methods for sampling from energy-based models by minimizing the energy function through gradient descent.</p>"},{"location":"api/torchebm/samplers/gradient_descent/classes/GradientDescentSampler/","title":"GradientDescentSampler","text":""},{"location":"api/torchebm/samplers/gradient_descent/classes/GradientDescentSampler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Gradient descent sampler for energy-based models.</p> <p>Generates samples by iteratively minimizing the energy function:</p> \\[ x_{k+1} = x_k - \\eta \\nabla_x E(x_k) \\] <p>This is a deterministic optimization-based sampler that finds low-energy configurations by following the negative gradient of the energy function.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy-based model with <code>gradient()</code> method.</p> required <code>step_size</code> <code>Union[float, BaseScheduler]</code> <p>Step size \\(\\eta\\) or scheduler.</p> <code>0.001</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision.</p> <code>False</code> Example <pre><code>from torchebm.samplers import GradientDescentSampler\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nsampler = GradientDescentSampler(energy, step_size=0.1)\nsamples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n</code></pre> Source code in <code>torchebm/samplers/gradient_descent.py</code> <pre><code>class GradientDescentSampler(BaseSampler):\n    r\"\"\"\n    Gradient descent sampler for energy-based models.\n\n    Generates samples by iteratively minimizing the energy function:\n\n    \\[\n    x_{k+1} = x_k - \\eta \\nabla_x E(x_k)\n    \\]\n\n    This is a deterministic optimization-based sampler that finds low-energy\n    configurations by following the negative gradient of the energy function.\n\n    Args:\n        model: Energy-based model with `gradient()` method.\n        step_size: Step size \\(\\eta\\) or scheduler.\n        dtype: Data type for computations.\n        device: Device for computations.\n        use_mixed_precision: Whether to use mixed precision.\n\n    Example:\n        ```python\n        from torchebm.samplers import GradientDescentSampler\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        sampler = GradientDescentSampler(energy, step_size=0.1)\n        samples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        step_size: Union[float, BaseScheduler] = 1e-3,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n        )\n        if isinstance(step_size, BaseScheduler):\n            self.register_scheduler(\"step_size\", step_size)\n        else:\n            if step_size &lt;= 0:\n                raise ValueError(\"step_size must be positive\")\n            self.register_scheduler(\"step_size\", ConstantScheduler(step_size))\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *args,\n        **kwargs,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        r\"\"\"\n        Generate samples via gradient descent optimization.\n\n        Args:\n            x: Initial state. If None, samples from N(0, I).\n            dim: Dimension of state space (used if x is None).\n            n_steps: Number of gradient descent steps.\n            n_samples: Number of parallel chains/samples.\n            thin: Thinning factor (not currently supported).\n            return_trajectory: Whether to return full trajectory.\n            return_diagnostics: Whether to return diagnostics.\n\n        Returns:\n            Final samples or (samples, diagnostics) if return_diagnostics=True.\n        \"\"\"\n        self.reset_schedulers()\n\n        if x is None:\n            x = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n        else:\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        diagnostics = self._setup_diagnostics() if return_diagnostics else None\n        trajectory = [x.clone()] if return_trajectory else None\n\n        with self.autocast_context():\n            for _ in range(n_steps):\n                self.step_schedulers()\n                eta = self.get_scheduled_value(\"step_size\")\n                grad = self.model.gradient(x)\n                x = x - eta * grad\n\n                if return_trajectory:\n                    trajectory.append(x.clone())\n\n        if return_diagnostics:\n            return (\n                torch.stack(trajectory, dim=1) if return_trajectory else x,\n                [diagnostics],\n            )\n        return torch.stack(trajectory, dim=1) if return_trajectory else x\n</code></pre>"},{"location":"api/torchebm/samplers/gradient_descent/classes/GradientDescentSampler/#torchebm.samplers.gradient_descent.GradientDescentSampler.sample","title":"sample","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: int = 10, n_steps: int = 100, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False, *args, **kwargs) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]\n</code></pre> <p>Generate samples via gradient descent optimization.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Optional[Tensor]</code> <p>Initial state. If None, samples from N(0, I).</p> <code>None</code> <code>dim</code> <code>int</code> <p>Dimension of state space (used if x is None).</p> <code>10</code> <code>n_steps</code> <code>int</code> <p>Number of gradient descent steps.</p> <code>100</code> <code>n_samples</code> <code>int</code> <p>Number of parallel chains/samples.</p> <code>1</code> <code>thin</code> <code>int</code> <p>Thinning factor (not currently supported).</p> <code>1</code> <code>return_trajectory</code> <code>bool</code> <p>Whether to return full trajectory.</p> <code>False</code> <code>return_diagnostics</code> <code>bool</code> <p>Whether to return diagnostics.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, Tuple[Tensor, List[dict]]]</code> <p>Final samples or (samples, diagnostics) if return_diagnostics=True.</p> Source code in <code>torchebm/samplers/gradient_descent.py</code> <pre><code>@torch.no_grad()\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: int = 10,\n    n_steps: int = 100,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n    *args,\n    **kwargs,\n) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n    r\"\"\"\n    Generate samples via gradient descent optimization.\n\n    Args:\n        x: Initial state. If None, samples from N(0, I).\n        dim: Dimension of state space (used if x is None).\n        n_steps: Number of gradient descent steps.\n        n_samples: Number of parallel chains/samples.\n        thin: Thinning factor (not currently supported).\n        return_trajectory: Whether to return full trajectory.\n        return_diagnostics: Whether to return diagnostics.\n\n    Returns:\n        Final samples or (samples, diagnostics) if return_diagnostics=True.\n    \"\"\"\n    self.reset_schedulers()\n\n    if x is None:\n        x = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n    else:\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    diagnostics = self._setup_diagnostics() if return_diagnostics else None\n    trajectory = [x.clone()] if return_trajectory else None\n\n    with self.autocast_context():\n        for _ in range(n_steps):\n            self.step_schedulers()\n            eta = self.get_scheduled_value(\"step_size\")\n            grad = self.model.gradient(x)\n            x = x - eta * grad\n\n            if return_trajectory:\n                trajectory.append(x.clone())\n\n    if return_diagnostics:\n        return (\n            torch.stack(trajectory, dim=1) if return_trajectory else x,\n            [diagnostics],\n        )\n    return torch.stack(trajectory, dim=1) if return_trajectory else x\n</code></pre>"},{"location":"api/torchebm/samplers/gradient_descent/classes/NesterovSampler/","title":"NesterovSampler","text":""},{"location":"api/torchebm/samplers/gradient_descent/classes/NesterovSampler/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Nesterov accelerated gradient sampler for energy-based models.</p> <p>Uses Nesterov momentum to accelerate convergence to low-energy states:</p> \\[ v_{k+1} = \\mu v_k - \\eta \\nabla_x E(x_k + \\mu v_k) \\] \\[ x_{k+1} = x_k + v_{k+1} \\] <p>where \\(\\mu\\) is the momentum coefficient and \\(\\eta\\) is the step size.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy-based model with <code>gradient()</code> method.</p> required <code>step_size</code> <code>Union[float, BaseScheduler]</code> <p>Step size \\(\\eta\\) or scheduler.</p> <code>0.001</code> <code>momentum</code> <code>float</code> <p>Momentum coefficient \\(\\mu \\in [0, 1)\\).</p> <code>0.9</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> <code>use_mixed_precision</code> <code>bool</code> <p>Whether to use mixed precision.</p> <code>False</code> Example <pre><code>from torchebm.samplers import NesterovSampler\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nsampler = NesterovSampler(energy, step_size=0.1, momentum=0.9)\nsamples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n</code></pre> Source code in <code>torchebm/samplers/gradient_descent.py</code> <pre><code>class NesterovSampler(BaseSampler):\n    r\"\"\"\n    Nesterov accelerated gradient sampler for energy-based models.\n\n    Uses Nesterov momentum to accelerate convergence to low-energy states:\n\n    \\[\n    v_{k+1} = \\mu v_k - \\eta \\nabla_x E(x_k + \\mu v_k)\n    \\]\n\n    \\[\n    x_{k+1} = x_k + v_{k+1}\n    \\]\n\n    where \\(\\mu\\) is the momentum coefficient and \\(\\eta\\) is the step size.\n\n    Args:\n        model: Energy-based model with `gradient()` method.\n        step_size: Step size \\(\\eta\\) or scheduler.\n        momentum: Momentum coefficient \\(\\mu \\in [0, 1)\\).\n        dtype: Data type for computations.\n        device: Device for computations.\n        use_mixed_precision: Whether to use mixed precision.\n\n    Example:\n        ```python\n        from torchebm.samplers import NesterovSampler\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        sampler = NesterovSampler(energy, step_size=0.1, momentum=0.9)\n        samples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        step_size: Union[float, BaseScheduler] = 1e-3,\n        momentum: float = 0.9,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        use_mixed_precision: bool = False,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(\n            model=model,\n            dtype=dtype,\n            device=device,\n            use_mixed_precision=use_mixed_precision,\n        )\n        if not (0 &lt;= momentum &lt; 1):\n            raise ValueError(\"momentum must be in [0, 1)\")\n        self.momentum = momentum\n\n        if isinstance(step_size, BaseScheduler):\n            self.register_scheduler(\"step_size\", step_size)\n        else:\n            if step_size &lt;= 0:\n                raise ValueError(\"step_size must be positive\")\n            self.register_scheduler(\"step_size\", ConstantScheduler(step_size))\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *args,\n        **kwargs,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        r\"\"\"\n        Generate samples via Nesterov accelerated gradient descent.\n\n        Args:\n            x: Initial state. If None, samples from N(0, I).\n            dim: Dimension of state space (used if x is None).\n            n_steps: Number of optimization steps.\n            n_samples: Number of parallel chains/samples.\n            thin: Thinning factor (not currently supported).\n            return_trajectory: Whether to return full trajectory.\n            return_diagnostics: Whether to return diagnostics.\n\n        Returns:\n            Final samples or (samples, diagnostics) if return_diagnostics=True.\n        \"\"\"\n        self.reset_schedulers()\n\n        if x is None:\n            x = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n        else:\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        v = torch.zeros_like(x)\n        diagnostics = self._setup_diagnostics() if return_diagnostics else None\n        trajectory = [x.clone()] if return_trajectory else None\n\n        mu = self.momentum\n        with self.autocast_context():\n            for _ in range(n_steps):\n                self.step_schedulers()\n                eta = self.get_scheduled_value(\"step_size\")\n                lookahead = x + mu * v\n                grad = self.model.gradient(lookahead)\n                v = mu * v - eta * grad\n                x = x + v\n\n                if return_trajectory:\n                    trajectory.append(x.clone())\n\n        if return_diagnostics:\n            return (\n                torch.stack(trajectory, dim=1) if return_trajectory else x,\n                [diagnostics],\n            )\n        return torch.stack(trajectory, dim=1) if return_trajectory else x\n</code></pre>"},{"location":"api/torchebm/samplers/gradient_descent/classes/NesterovSampler/#torchebm.samplers.gradient_descent.NesterovSampler.momentum","title":"momentum  <code>instance-attribute</code>","text":"<pre><code>momentum = momentum\n</code></pre>"},{"location":"api/torchebm/samplers/gradient_descent/classes/NesterovSampler/#torchebm.samplers.gradient_descent.NesterovSampler.sample","title":"sample","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: int = 10, n_steps: int = 100, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False, *args, **kwargs) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]\n</code></pre> <p>Generate samples via Nesterov accelerated gradient descent.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Optional[Tensor]</code> <p>Initial state. If None, samples from N(0, I).</p> <code>None</code> <code>dim</code> <code>int</code> <p>Dimension of state space (used if x is None).</p> <code>10</code> <code>n_steps</code> <code>int</code> <p>Number of optimization steps.</p> <code>100</code> <code>n_samples</code> <code>int</code> <p>Number of parallel chains/samples.</p> <code>1</code> <code>thin</code> <code>int</code> <p>Thinning factor (not currently supported).</p> <code>1</code> <code>return_trajectory</code> <code>bool</code> <p>Whether to return full trajectory.</p> <code>False</code> <code>return_diagnostics</code> <code>bool</code> <p>Whether to return diagnostics.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, Tuple[Tensor, List[dict]]]</code> <p>Final samples or (samples, diagnostics) if return_diagnostics=True.</p> Source code in <code>torchebm/samplers/gradient_descent.py</code> <pre><code>@torch.no_grad()\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: int = 10,\n    n_steps: int = 100,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n    *args,\n    **kwargs,\n) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n    r\"\"\"\n    Generate samples via Nesterov accelerated gradient descent.\n\n    Args:\n        x: Initial state. If None, samples from N(0, I).\n        dim: Dimension of state space (used if x is None).\n        n_steps: Number of optimization steps.\n        n_samples: Number of parallel chains/samples.\n        thin: Thinning factor (not currently supported).\n        return_trajectory: Whether to return full trajectory.\n        return_diagnostics: Whether to return diagnostics.\n\n    Returns:\n        Final samples or (samples, diagnostics) if return_diagnostics=True.\n    \"\"\"\n    self.reset_schedulers()\n\n    if x is None:\n        x = torch.randn(n_samples, dim, device=self.device, dtype=self.dtype)\n    else:\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    v = torch.zeros_like(x)\n    diagnostics = self._setup_diagnostics() if return_diagnostics else None\n    trajectory = [x.clone()] if return_trajectory else None\n\n    mu = self.momentum\n    with self.autocast_context():\n        for _ in range(n_steps):\n            self.step_schedulers()\n            eta = self.get_scheduled_value(\"step_size\")\n            lookahead = x + mu * v\n            grad = self.model.gradient(lookahead)\n            v = mu * v - eta * grad\n            x = x + v\n\n            if return_trajectory:\n                trajectory.append(x.clone())\n\n    if return_diagnostics:\n        return (\n            torch.stack(trajectory, dim=1) if return_trajectory else x,\n            [diagnostics],\n        )\n    return torch.stack(trajectory, dim=1) if return_trajectory else x\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/","title":"Torchebm &gt; Samplers &gt; Hmc","text":""},{"location":"api/torchebm/samplers/hmc/#torchebm-samplers-hmc","title":"Torchebm &gt; Samplers &gt; Hmc","text":""},{"location":"api/torchebm/samplers/hmc/#contents","title":"Contents","text":""},{"location":"api/torchebm/samplers/hmc/#classes","title":"Classes","text":"<ul> <li><code>HamiltonianMonteCarlo</code> - Hamiltonian Monte Carlo sampler.</li> </ul>"},{"location":"api/torchebm/samplers/hmc/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/samplers/hmc/#torchebm.samplers.hmc","title":"torchebm.samplers.hmc","text":"<p>Hamiltonian Monte Carlo Sampler Module.</p>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/","title":"HamiltonianMonteCarlo","text":""},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Hamiltonian Monte Carlo sampler.</p> <p>Uses Hamiltonian dynamics with Metropolis-Hastings acceptance to sample from the target distribution defined by the energy model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy-based model to sample from.</p> required <code>step_size</code> <code>Union[float, BaseScheduler]</code> <p>Step size for leapfrog integration.</p> <code>0.001</code> <code>n_leapfrog_steps</code> <code>int</code> <p>Number of leapfrog steps per trajectory.</p> <code>10</code> <code>mass</code> <code>Optional[Union[float, Tensor]]</code> <p>Mass matrix (scalar or tensor).</p> <code>None</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> Example <pre><code>from torchebm.samplers import HamiltonianMonteCarlo\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nsampler = HamiltonianMonteCarlo(\n    energy, step_size=0.1, n_leapfrog_steps=10\n)\nsamples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n</code></pre> Source code in <code>torchebm/samplers/hmc.py</code> <pre><code>class HamiltonianMonteCarlo(BaseSampler):\n    r\"\"\"\n    Hamiltonian Monte Carlo sampler.\n\n    Uses Hamiltonian dynamics with Metropolis-Hastings acceptance to sample\n    from the target distribution defined by the energy model.\n\n    Args:\n        model: Energy-based model to sample from.\n        step_size: Step size for leapfrog integration.\n        n_leapfrog_steps: Number of leapfrog steps per trajectory.\n        mass: Mass matrix (scalar or tensor).\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.samplers import HamiltonianMonteCarlo\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        sampler = HamiltonianMonteCarlo(\n            energy, step_size=0.1, n_leapfrog_steps=10\n        )\n        samples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        step_size: Union[float, BaseScheduler] = 1e-3,\n        n_leapfrog_steps: int = 10,\n        mass: Optional[Union[float, torch.Tensor]] = None,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(model=model, dtype=dtype, device=device)\n        if isinstance(step_size, BaseScheduler):\n            self.register_scheduler(\"step_size\", step_size)\n        else:\n            if step_size &lt;= 0:\n                raise ValueError(\"step_size must be positive\")\n            self.register_scheduler(\"step_size\", ConstantScheduler(step_size))\n\n        if n_leapfrog_steps &lt;= 0:\n            raise ValueError(\"n_leapfrog_steps must be positive\")\n\n        self.n_leapfrog_steps = n_leapfrog_steps\n        self.mass = (\n            mass.to(self.device)\n            if (mass is not None and not isinstance(mass, float))\n            else mass\n        )\n        self.integrator = LeapfrogIntegrator(device=self.device, dtype=self.dtype)\n\n    def _initialize_momentum(self, shape: torch.Size) -&gt; torch.Tensor:\n        \"\"\"\n        Initializes momentum variables from a Gaussian distribution.\n\n        The momentum is sampled from \\(\\mathcal{N}(0, M)\\), where `M` is the mass matrix.\n\n        Args:\n            shape (torch.Size): The shape of the momentum tensor to generate.\n\n        Returns:\n            torch.Tensor: The initialized momentum tensor.\n        \"\"\"\n        p = torch.randn(shape, dtype=self.dtype, device=self.device)\n\n        if self.mass is not None:\n            # Apply mass matrix (equivalent to sampling from N(0, M))\n            if isinstance(self.mass, float):\n                p = p * torch.sqrt(\n                    torch.tensor(self.mass, dtype=self.dtype, device=self.device)\n                )\n            else:\n                mass_sqrt = torch.sqrt(self.mass)\n                p = p * mass_sqrt.view(*([1] * (len(shape) - 1)), -1).expand_as(p)\n        return p\n\n    def _compute_kinetic_energy(self, p: torch.Tensor) -&gt; torch.Tensor:\n        r\"\"\"\n        Computes the kinetic energy of the momentum.\n\n        The kinetic energy is \\(K(p) = \\frac{1}{2} p^T M^{-1} p\\).\n\n        Args:\n            p (torch.Tensor): The momentum tensor.\n\n        Returns:\n            torch.Tensor: The kinetic energy for each sample in the batch.\n        \"\"\"\n        if self.mass is None:\n            return 0.5 * torch.sum(p**2, dim=-1)\n        elif isinstance(self.mass, float):\n            return 0.5 * torch.sum(p**2, dim=-1) / self.mass\n        else:\n            return 0.5 * torch.sum(\n                p**2 / self.mass.view(*([1] * (len(p.shape) - 1)), -1), dim=-1\n            )\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: Optional[int] = None,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n    ) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        self.reset_schedulers()\n\n        if x is None:\n            if dim is None:\n                if hasattr(self.model, \"mean\") and isinstance(\n                    self.model.mean, torch.Tensor\n                ):\n                    dim = self.model.mean.shape[0]\n                else:\n                    raise ValueError(\n                        \"dim must be provided when x is None and cannot be inferred from model\"\n                    )\n            x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n        else:\n            x = x.to(device=self.device, dtype=self.dtype)\n\n        dim = x.shape[1]\n        batch_size = x.shape[0]\n\n        if return_trajectory:\n            trajectory = torch.empty(\n                (batch_size, n_steps, dim),\n                dtype=self.dtype,\n                device=self.device,\n                requires_grad=False,\n            )\n\n        if return_diagnostics:\n            diagnostics = self._setup_diagnostics(dim, n_steps, n_samples=batch_size)\n\n        with self.autocast_context():\n            for i in range(n_steps):\n                self.step_schedulers()\n\n                current_momentum = self._initialize_momentum(x.shape)\n\n                momentum_direction = (\n                    torch.randint(0, 2, (batch_size, 1), device=self.device) * 2 - 1\n                )  # -1/+1 -&gt; for sign flipping\n                current_momentum = current_momentum * momentum_direction\n\n                current_energy = torch.clamp(self.model(x), min=-1e10, max=1e10)\n                current_kinetic = torch.clamp(\n                    self._compute_kinetic_energy(current_momentum), min=0, max=1e10\n                )\n\n                current_hamiltonian = current_energy + current_kinetic\n\n                state = {\"x\": x, \"p\": current_momentum}\n                proposed = self.integrator.integrate(\n                    state,\n                    self.model,\n                    self.get_scheduled_value(\"step_size\"),\n                    self.n_leapfrog_steps,\n                    self.mass,\n                )\n                proposed_position, proposed_momentum = proposed[\"x\"], proposed[\"p\"]\n\n                proposed_energy = torch.clamp(\n                    self.model(proposed_position), min=-1e10, max=1e10\n                )\n                proposed_kinetic = torch.clamp(\n                    self._compute_kinetic_energy(proposed_momentum), min=0, max=1e10\n                )\n\n                proposed_hamiltonian = proposed_energy + proposed_kinetic\n\n                hamiltonian_diff = current_hamiltonian - proposed_hamiltonian\n                hamiltonian_diff = torch.clamp(hamiltonian_diff, max=50, min=-50)\n\n                acceptance_prob = torch.minimum(\n                    torch.ones(batch_size, device=self.device),\n                    torch.exp(hamiltonian_diff),\n                )\n\n                random_uniform = torch.rand(batch_size, device=self.device)\n                accepted = random_uniform &lt; acceptance_prob\n                accepted_mask = accepted.float().view(-1, *([1] * (len(x.shape) - 1)))\n\n                x = accepted_mask * proposed_position + (1.0 - accepted_mask) * x\n\n                if return_trajectory:\n                    trajectory[:, i, :] = x\n\n                if return_diagnostics:\n                    mean_x = x.mean(dim=0, keepdim=True)\n                    var_x = torch.clamp(\n                        x.var(dim=0, unbiased=False, keepdim=True),\n                        min=1e-10,\n                        max=1e10,\n                    )\n                    energy = torch.clamp(self.model(x), min=-1e10, max=1e10)\n                    acceptance_rate = accepted.float().mean()\n\n                    diagnostics[i, 0, :, :] = mean_x.expand(batch_size, dim)\n                    diagnostics[i, 1, :, :] = var_x.expand(batch_size, dim)\n                    diagnostics[i, 2, :, :] = energy.view(-1, 1).expand(-1, dim)\n                    diagnostics[i, 3, :, :] = torch.full(\n                        (batch_size, dim),\n                        acceptance_rate,\n                        dtype=self.dtype,\n                        device=self.device,\n                    )\n\n        if return_trajectory:\n            if return_diagnostics:\n                return trajectory.to(dtype=self.dtype), diagnostics.to(dtype=self.dtype)\n            return trajectory.to(dtype=self.dtype)\n\n        if return_diagnostics:\n            return x.to(dtype=self.dtype), diagnostics.to(dtype=self.dtype)\n\n        return x.to(dtype=self.dtype)\n\n    def _setup_diagnostics(\n        self, dim: int, n_steps: int, n_samples: int = None\n    ) -&gt; torch.Tensor:\n        r\"\"\"\n        Initializes a tensor to store diagnostics during sampling.\n\n        Args:\n            dim (int): The dimensionality of the state space.\n            n_steps (int): The number of sampling steps.\n            n_samples (Optional[int]): The number of parallel chains.\n\n        Returns:\n            torch.Tensor: An empty tensor for storing diagnostics.\n        \"\"\"\n        if n_samples is not None:\n            return torch.empty(\n                (n_steps, 4, n_samples, dim), device=self.device, dtype=self.dtype\n            )\n        else:\n            return torch.empty((n_steps, 4, dim), device=self.device, dtype=self.dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo.n_leapfrog_steps","title":"n_leapfrog_steps  <code>instance-attribute</code>","text":"<pre><code>n_leapfrog_steps = n_leapfrog_steps\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo.mass","title":"mass  <code>instance-attribute</code>","text":"<pre><code>mass = to(device) if mass is not None and not isinstance(mass, float) else mass\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo.integrator","title":"integrator  <code>instance-attribute</code>","text":"<pre><code>integrator = LeapfrogIntegrator(device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo._initialize_momentum","title":"_initialize_momentum","text":"<pre><code>_initialize_momentum(shape: Size) -&gt; torch.Tensor\n</code></pre> <p>Initializes momentum variables from a Gaussian distribution.</p> <p>The momentum is sampled from \\(\\mathcal{N}(0, M)\\), where <code>M</code> is the mass matrix.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Size</code> <p>The shape of the momentum tensor to generate.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The initialized momentum tensor.</p> Source code in <code>torchebm/samplers/hmc.py</code> <pre><code>def _initialize_momentum(self, shape: torch.Size) -&gt; torch.Tensor:\n    \"\"\"\n    Initializes momentum variables from a Gaussian distribution.\n\n    The momentum is sampled from \\(\\mathcal{N}(0, M)\\), where `M` is the mass matrix.\n\n    Args:\n        shape (torch.Size): The shape of the momentum tensor to generate.\n\n    Returns:\n        torch.Tensor: The initialized momentum tensor.\n    \"\"\"\n    p = torch.randn(shape, dtype=self.dtype, device=self.device)\n\n    if self.mass is not None:\n        # Apply mass matrix (equivalent to sampling from N(0, M))\n        if isinstance(self.mass, float):\n            p = p * torch.sqrt(\n                torch.tensor(self.mass, dtype=self.dtype, device=self.device)\n            )\n        else:\n            mass_sqrt = torch.sqrt(self.mass)\n            p = p * mass_sqrt.view(*([1] * (len(shape) - 1)), -1).expand_as(p)\n    return p\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo._compute_kinetic_energy","title":"_compute_kinetic_energy","text":"<pre><code>_compute_kinetic_energy(p: Tensor) -&gt; torch.Tensor\n</code></pre> <p>Computes the kinetic energy of the momentum.</p> <p>The kinetic energy is \\(K(p) = \\frac{1}{2} p^T M^{-1} p\\).</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>Tensor</code> <p>The momentum tensor.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: The kinetic energy for each sample in the batch.</p> Source code in <code>torchebm/samplers/hmc.py</code> <pre><code>def _compute_kinetic_energy(self, p: torch.Tensor) -&gt; torch.Tensor:\n    r\"\"\"\n    Computes the kinetic energy of the momentum.\n\n    The kinetic energy is \\(K(p) = \\frac{1}{2} p^T M^{-1} p\\).\n\n    Args:\n        p (torch.Tensor): The momentum tensor.\n\n    Returns:\n        torch.Tensor: The kinetic energy for each sample in the batch.\n    \"\"\"\n    if self.mass is None:\n        return 0.5 * torch.sum(p**2, dim=-1)\n    elif isinstance(self.mass, float):\n        return 0.5 * torch.sum(p**2, dim=-1) / self.mass\n    else:\n        return 0.5 * torch.sum(\n            p**2 / self.mass.view(*([1] * (len(p.shape) - 1)), -1), dim=-1\n        )\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo.sample","title":"sample","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: Optional[int] = None, n_steps: int = 100, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False) -&gt; Tuple[torch.Tensor, torch.Tensor]\n</code></pre> Source code in <code>torchebm/samplers/hmc.py</code> <pre><code>@torch.no_grad()\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: Optional[int] = None,\n    n_steps: int = 100,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    self.reset_schedulers()\n\n    if x is None:\n        if dim is None:\n            if hasattr(self.model, \"mean\") and isinstance(\n                self.model.mean, torch.Tensor\n            ):\n                dim = self.model.mean.shape[0]\n            else:\n                raise ValueError(\n                    \"dim must be provided when x is None and cannot be inferred from model\"\n                )\n        x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n    else:\n        x = x.to(device=self.device, dtype=self.dtype)\n\n    dim = x.shape[1]\n    batch_size = x.shape[0]\n\n    if return_trajectory:\n        trajectory = torch.empty(\n            (batch_size, n_steps, dim),\n            dtype=self.dtype,\n            device=self.device,\n            requires_grad=False,\n        )\n\n    if return_diagnostics:\n        diagnostics = self._setup_diagnostics(dim, n_steps, n_samples=batch_size)\n\n    with self.autocast_context():\n        for i in range(n_steps):\n            self.step_schedulers()\n\n            current_momentum = self._initialize_momentum(x.shape)\n\n            momentum_direction = (\n                torch.randint(0, 2, (batch_size, 1), device=self.device) * 2 - 1\n            )  # -1/+1 -&gt; for sign flipping\n            current_momentum = current_momentum * momentum_direction\n\n            current_energy = torch.clamp(self.model(x), min=-1e10, max=1e10)\n            current_kinetic = torch.clamp(\n                self._compute_kinetic_energy(current_momentum), min=0, max=1e10\n            )\n\n            current_hamiltonian = current_energy + current_kinetic\n\n            state = {\"x\": x, \"p\": current_momentum}\n            proposed = self.integrator.integrate(\n                state,\n                self.model,\n                self.get_scheduled_value(\"step_size\"),\n                self.n_leapfrog_steps,\n                self.mass,\n            )\n            proposed_position, proposed_momentum = proposed[\"x\"], proposed[\"p\"]\n\n            proposed_energy = torch.clamp(\n                self.model(proposed_position), min=-1e10, max=1e10\n            )\n            proposed_kinetic = torch.clamp(\n                self._compute_kinetic_energy(proposed_momentum), min=0, max=1e10\n            )\n\n            proposed_hamiltonian = proposed_energy + proposed_kinetic\n\n            hamiltonian_diff = current_hamiltonian - proposed_hamiltonian\n            hamiltonian_diff = torch.clamp(hamiltonian_diff, max=50, min=-50)\n\n            acceptance_prob = torch.minimum(\n                torch.ones(batch_size, device=self.device),\n                torch.exp(hamiltonian_diff),\n            )\n\n            random_uniform = torch.rand(batch_size, device=self.device)\n            accepted = random_uniform &lt; acceptance_prob\n            accepted_mask = accepted.float().view(-1, *([1] * (len(x.shape) - 1)))\n\n            x = accepted_mask * proposed_position + (1.0 - accepted_mask) * x\n\n            if return_trajectory:\n                trajectory[:, i, :] = x\n\n            if return_diagnostics:\n                mean_x = x.mean(dim=0, keepdim=True)\n                var_x = torch.clamp(\n                    x.var(dim=0, unbiased=False, keepdim=True),\n                    min=1e-10,\n                    max=1e10,\n                )\n                energy = torch.clamp(self.model(x), min=-1e10, max=1e10)\n                acceptance_rate = accepted.float().mean()\n\n                diagnostics[i, 0, :, :] = mean_x.expand(batch_size, dim)\n                diagnostics[i, 1, :, :] = var_x.expand(batch_size, dim)\n                diagnostics[i, 2, :, :] = energy.view(-1, 1).expand(-1, dim)\n                diagnostics[i, 3, :, :] = torch.full(\n                    (batch_size, dim),\n                    acceptance_rate,\n                    dtype=self.dtype,\n                    device=self.device,\n                )\n\n    if return_trajectory:\n        if return_diagnostics:\n            return trajectory.to(dtype=self.dtype), diagnostics.to(dtype=self.dtype)\n        return trajectory.to(dtype=self.dtype)\n\n    if return_diagnostics:\n        return x.to(dtype=self.dtype), diagnostics.to(dtype=self.dtype)\n\n    return x.to(dtype=self.dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/hmc/classes/HamiltonianMonteCarlo/#torchebm.samplers.hmc.HamiltonianMonteCarlo._setup_diagnostics","title":"_setup_diagnostics","text":"<pre><code>_setup_diagnostics(dim: int, n_steps: int, n_samples: int = None) -&gt; torch.Tensor\n</code></pre> <p>Initializes a tensor to store diagnostics during sampling.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>The dimensionality of the state space.</p> required <code>n_steps</code> <code>int</code> <p>The number of sampling steps.</p> required <code>n_samples</code> <code>Optional[int]</code> <p>The number of parallel chains.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: An empty tensor for storing diagnostics.</p> Source code in <code>torchebm/samplers/hmc.py</code> <pre><code>def _setup_diagnostics(\n    self, dim: int, n_steps: int, n_samples: int = None\n) -&gt; torch.Tensor:\n    r\"\"\"\n    Initializes a tensor to store diagnostics during sampling.\n\n    Args:\n        dim (int): The dimensionality of the state space.\n        n_steps (int): The number of sampling steps.\n        n_samples (Optional[int]): The number of parallel chains.\n\n    Returns:\n        torch.Tensor: An empty tensor for storing diagnostics.\n    \"\"\"\n    if n_samples is not None:\n        return torch.empty(\n            (n_steps, 4, n_samples, dim), device=self.device, dtype=self.dtype\n        )\n    else:\n        return torch.empty((n_steps, 4, dim), device=self.device, dtype=self.dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/langevin_dynamics/","title":"Torchebm &gt; Samplers &gt; Langevin_dynamics","text":""},{"location":"api/torchebm/samplers/langevin_dynamics/#torchebm-samplers-langevin_dynamics","title":"Torchebm &gt; Samplers &gt; Langevin_dynamics","text":""},{"location":"api/torchebm/samplers/langevin_dynamics/#contents","title":"Contents","text":""},{"location":"api/torchebm/samplers/langevin_dynamics/#classes","title":"Classes","text":"<ul> <li><code>LangevinDynamics</code> - Langevin Dynamics sampler.</li> </ul>"},{"location":"api/torchebm/samplers/langevin_dynamics/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/samplers/langevin_dynamics/#torchebm.samplers.langevin_dynamics","title":"torchebm.samplers.langevin_dynamics","text":"<p>Langevin Dynamics Sampler Module.</p>"},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/","title":"LangevinDynamics","text":""},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/#methods-and-attributes","title":"Methods and Attributes","text":"<p>               Bases: <code>BaseSampler</code></p> <p>Langevin Dynamics sampler.</p> <p>Update rule:</p> \\[ x_{t+1} = x_t - \\eta \\nabla_x U(x_t) + \\sqrt{2\\eta} \\epsilon_t \\] <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseModel</code> <p>Energy-based model to sample from.</p> required <code>step_size</code> <code>Union[float, BaseScheduler]</code> <p>Step size for gradient descent.</p> <code>0.001</code> <code>noise_scale</code> <code>Union[float, BaseScheduler]</code> <p>Scale of Gaussian noise injection.</p> <code>1.0</code> <code>decay</code> <code>float</code> <p>Damping coefficient (not supported).</p> <code>0.0</code> <code>dtype</code> <code>dtype</code> <p>Data type for computations.</p> <code>float32</code> <code>device</code> <code>Optional[Union[str, device]]</code> <p>Device for computations.</p> <code>None</code> Example <pre><code>from torchebm.samplers import LangevinDynamics\nfrom torchebm.core import DoubleWellEnergy\nimport torch\n\nenergy = DoubleWellEnergy()\nsampler = LangevinDynamics(energy, step_size=0.01, noise_scale=1.0)\nsamples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n</code></pre> Source code in <code>torchebm/samplers/langevin_dynamics.py</code> <pre><code>class LangevinDynamics(BaseSampler):\n    r\"\"\"\n    Langevin Dynamics sampler.\n\n    Update rule:\n\n    \\[\n    x_{t+1} = x_t - \\eta \\nabla_x U(x_t) + \\sqrt{2\\eta} \\epsilon_t\n    \\]\n\n    Args:\n        model: Energy-based model to sample from.\n        step_size: Step size for gradient descent.\n        noise_scale: Scale of Gaussian noise injection.\n        decay: Damping coefficient (not supported).\n        dtype: Data type for computations.\n        device: Device for computations.\n\n    Example:\n        ```python\n        from torchebm.samplers import LangevinDynamics\n        from torchebm.core import DoubleWellEnergy\n        import torch\n\n        energy = DoubleWellEnergy()\n        sampler = LangevinDynamics(energy, step_size=0.01, noise_scale=1.0)\n        samples = sampler.sample(n_samples=100, dim=2, n_steps=500)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        model: BaseModel,\n        step_size: Union[float, BaseScheduler] = 1e-3,\n        noise_scale: Union[float, BaseScheduler] = 1.0,\n        decay: float = 0.0,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n        *args,\n        **kwargs,\n    ):\n        super().__init__(model=model, dtype=dtype, device=device)\n\n        if isinstance(step_size, BaseScheduler):\n            self.register_scheduler(\"step_size\", step_size)\n        else:\n            if step_size &lt;= 0:\n                raise ValueError(\"step_size must be positive\")\n            self.register_scheduler(\"step_size\", ConstantScheduler(step_size))\n\n        if isinstance(noise_scale, BaseScheduler):\n            self.register_scheduler(\"noise_scale\", noise_scale)\n        else:\n            if noise_scale &lt;= 0:\n                raise ValueError(\"noise_scale must be positive\")\n            self.register_scheduler(\"noise_scale\", ConstantScheduler(noise_scale))\n\n        self.decay = decay\n        self.integrator = EulerMaruyamaIntegrator(device=self.device, dtype=self.dtype)\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *args,\n        **kwargs,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        \"\"\"\n        Generates samples using Langevin dynamics.\n\n        Args:\n            x (Optional[torch.Tensor]): The initial state to start sampling from. If `None`,\n                a random state is created.\n            dim (int): The dimension of the state space (if `x` is not provided).\n            n_steps (int): The number of MCMC steps to perform.\n            n_samples (int): The number of parallel chains/samples to generate.\n            thin (int): The thinning factor (not currently supported).\n            return_trajectory (bool): Whether to return the full sample trajectory.\n            return_diagnostics (bool): Whether to return sampling diagnostics.\n\n        Returns:\n            Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n                - The final samples.\n                - If `return_trajectory` is `True`, the full trajectory.\n                - If `return_diagnostics` is `True`, a tuple of samples and diagnostics.\n        \"\"\"\n\n        self.reset_schedulers()\n\n        if x is None:\n            x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n        else:\n            x = x.to(device=self.device, dtype=self.dtype)\n            dim = x.shape[-1]\n            n_samples = x.shape[0]\n\n        if return_trajectory:\n            trajectory = torch.empty(\n                (n_samples, n_steps, dim), dtype=self.dtype, device=self.device\n            )\n\n        if return_diagnostics:\n            diagnostics = self._setup_diagnostics(dim, n_steps, n_samples=n_samples)\n\n        with self.autocast_context():\n            for i in range(n_steps):\n                self.step_schedulers()\n                state = {\"x\": x}\n                x = self.integrator.step(\n                    state=state,\n                    model=self.model,\n                    step_size=self.get_scheduled_value(\"step_size\"),\n                    noise_scale=self.get_scheduled_value(\"noise_scale\"),\n                )[\"x\"]\n\n                if return_trajectory:\n                    trajectory[:, i, :] = x\n\n                if return_diagnostics:\n                    if n_samples &gt; 1:\n                        mean_x = x.mean(dim=0, keepdim=True)\n                        var_x = torch.clamp(\n                            x.var(dim=0, unbiased=False, keepdim=True),\n                            min=1e-10,\n                            max=1e10,\n                        )\n                    else:\n                        mean_x = x\n                        var_x = torch.zeros_like(x)\n                    energy = self.model(x)\n                    diagnostics[i, 0, :, :] = (\n                        mean_x if n_samples &gt; 1 else mean_x.unsqueeze(0)\n                    )\n                    diagnostics[i, 1, :, :] = (\n                        var_x if n_samples &gt; 1 else var_x.unsqueeze(0)\n                    )\n                    diagnostics[i, 2, :, :] = energy.view(-1, 1).expand(n_samples, dim)\n\n        if return_trajectory:\n            if return_diagnostics:\n                return trajectory, diagnostics\n            return trajectory\n        if return_diagnostics:\n            return x, diagnostics\n        return x\n\n    def _setup_diagnostics(\n        self, dim: int, n_steps: int, n_samples: int = None\n    ) -&gt; torch.Tensor:\n        if n_samples is not None:\n            return torch.empty(\n                (n_steps, 3, n_samples, dim), device=self.device, dtype=self.dtype\n            )\n        return torch.empty((n_steps, 3, dim), device=self.device, dtype=self.dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/#torchebm.samplers.langevin_dynamics.LangevinDynamics.decay","title":"decay  <code>instance-attribute</code>","text":"<pre><code>decay = decay\n</code></pre>"},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/#torchebm.samplers.langevin_dynamics.LangevinDynamics.integrator","title":"integrator  <code>instance-attribute</code>","text":"<pre><code>integrator = EulerMaruyamaIntegrator(device=device, dtype=dtype)\n</code></pre>"},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/#torchebm.samplers.langevin_dynamics.LangevinDynamics.sample","title":"sample","text":"<pre><code>sample(x: Optional[Tensor] = None, dim: int = 10, n_steps: int = 100, n_samples: int = 1, thin: int = 1, return_trajectory: bool = False, return_diagnostics: bool = False, *args, **kwargs) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]\n</code></pre> <p>Generates samples using Langevin dynamics.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Optional[Tensor]</code> <p>The initial state to start sampling from. If <code>None</code>, a random state is created.</p> <code>None</code> <code>dim</code> <code>int</code> <p>The dimension of the state space (if <code>x</code> is not provided).</p> <code>10</code> <code>n_steps</code> <code>int</code> <p>The number of MCMC steps to perform.</p> <code>100</code> <code>n_samples</code> <code>int</code> <p>The number of parallel chains/samples to generate.</p> <code>1</code> <code>thin</code> <code>int</code> <p>The thinning factor (not currently supported).</p> <code>1</code> <code>return_trajectory</code> <code>bool</code> <p>Whether to return the full sample trajectory.</p> <code>False</code> <code>return_diagnostics</code> <code>bool</code> <p>Whether to return sampling diagnostics.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[Tensor, Tuple[Tensor, List[dict]]]</code> <p>Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]: - The final samples. - If <code>return_trajectory</code> is <code>True</code>, the full trajectory. - If <code>return_diagnostics</code> is <code>True</code>, a tuple of samples and diagnostics.</p> Source code in <code>torchebm/samplers/langevin_dynamics.py</code> <pre><code>@torch.no_grad()\ndef sample(\n    self,\n    x: Optional[torch.Tensor] = None,\n    dim: int = 10,\n    n_steps: int = 100,\n    n_samples: int = 1,\n    thin: int = 1,\n    return_trajectory: bool = False,\n    return_diagnostics: bool = False,\n    *args,\n    **kwargs,\n) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n    \"\"\"\n    Generates samples using Langevin dynamics.\n\n    Args:\n        x (Optional[torch.Tensor]): The initial state to start sampling from. If `None`,\n            a random state is created.\n        dim (int): The dimension of the state space (if `x` is not provided).\n        n_steps (int): The number of MCMC steps to perform.\n        n_samples (int): The number of parallel chains/samples to generate.\n        thin (int): The thinning factor (not currently supported).\n        return_trajectory (bool): Whether to return the full sample trajectory.\n        return_diagnostics (bool): Whether to return sampling diagnostics.\n\n    Returns:\n        Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n            - The final samples.\n            - If `return_trajectory` is `True`, the full trajectory.\n            - If `return_diagnostics` is `True`, a tuple of samples and diagnostics.\n    \"\"\"\n\n    self.reset_schedulers()\n\n    if x is None:\n        x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n    else:\n        x = x.to(device=self.device, dtype=self.dtype)\n        dim = x.shape[-1]\n        n_samples = x.shape[0]\n\n    if return_trajectory:\n        trajectory = torch.empty(\n            (n_samples, n_steps, dim), dtype=self.dtype, device=self.device\n        )\n\n    if return_diagnostics:\n        diagnostics = self._setup_diagnostics(dim, n_steps, n_samples=n_samples)\n\n    with self.autocast_context():\n        for i in range(n_steps):\n            self.step_schedulers()\n            state = {\"x\": x}\n            x = self.integrator.step(\n                state=state,\n                model=self.model,\n                step_size=self.get_scheduled_value(\"step_size\"),\n                noise_scale=self.get_scheduled_value(\"noise_scale\"),\n            )[\"x\"]\n\n            if return_trajectory:\n                trajectory[:, i, :] = x\n\n            if return_diagnostics:\n                if n_samples &gt; 1:\n                    mean_x = x.mean(dim=0, keepdim=True)\n                    var_x = torch.clamp(\n                        x.var(dim=0, unbiased=False, keepdim=True),\n                        min=1e-10,\n                        max=1e10,\n                    )\n                else:\n                    mean_x = x\n                    var_x = torch.zeros_like(x)\n                energy = self.model(x)\n                diagnostics[i, 0, :, :] = (\n                    mean_x if n_samples &gt; 1 else mean_x.unsqueeze(0)\n                )\n                diagnostics[i, 1, :, :] = (\n                    var_x if n_samples &gt; 1 else var_x.unsqueeze(0)\n                )\n                diagnostics[i, 2, :, :] = energy.view(-1, 1).expand(n_samples, dim)\n\n    if return_trajectory:\n        if return_diagnostics:\n            return trajectory, diagnostics\n        return trajectory\n    if return_diagnostics:\n        return x, diagnostics\n    return x\n</code></pre>"},{"location":"api/torchebm/samplers/langevin_dynamics/classes/LangevinDynamics/#torchebm.samplers.langevin_dynamics.LangevinDynamics._setup_diagnostics","title":"_setup_diagnostics","text":"<pre><code>_setup_diagnostics(dim: int, n_steps: int, n_samples: int = None) -&gt; torch.Tensor\n</code></pre> Source code in <code>torchebm/samplers/langevin_dynamics.py</code> <pre><code>def _setup_diagnostics(\n    self, dim: int, n_steps: int, n_samples: int = None\n) -&gt; torch.Tensor:\n    if n_samples is not None:\n        return torch.empty(\n            (n_steps, 3, n_samples, dim), device=self.device, dtype=self.dtype\n        )\n    return torch.empty((n_steps, 3, dim), device=self.device, dtype=self.dtype)\n</code></pre>"},{"location":"api/torchebm/utils/","title":"Torchebm &gt; Utils","text":""},{"location":"api/torchebm/utils/#torchebm-utils","title":"Torchebm &gt; Utils","text":""},{"location":"api/torchebm/utils/#contents","title":"Contents","text":""},{"location":"api/torchebm/utils/#modules","title":"Modules","text":"<ul> <li>Eqm_utils</li> <li>Visualization</li> </ul>"},{"location":"api/torchebm/utils/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/utils/#torchebm.utils","title":"torchebm.utils","text":"<p>Utility functions for working with energy-based models, including visualization tools.</p>"},{"location":"api/torchebm/utils/eqm_utils/","title":"Torchebm &gt; Utils &gt; Eqm_utils","text":""},{"location":"api/torchebm/utils/eqm_utils/#torchebm-utils-eqm_utils","title":"Torchebm &gt; Utils &gt; Eqm_utils","text":""},{"location":"api/torchebm/utils/eqm_utils/#contents","title":"Contents","text":""},{"location":"api/torchebm/utils/eqm_utils/#classes","title":"Classes","text":"<ul> <li><code>WandbLogger</code> - Simple wandb logging wrapper.</li> </ul>"},{"location":"api/torchebm/utils/eqm_utils/#functions","title":"Functions","text":"<ul> <li><code>center_crop_arr()</code> - Center crop and resize image to target size.</li> <li><code>create_npz_from_sample_folder()</code> - Build .npz file from folder of PNG samples.</li> <li><code>get_vae_encode_decode()</code> - Get VAE encoder/decoder functions for latent space operations.</li> <li><code>load_checkpoint()</code> - Load training checkpoint.</li> <li><code>parse_transport_args()</code> - Add transport-related arguments to parser.</li> <li><code>requires_grad()</code> - Set requires_grad flag for all model parameters.</li> <li><code>save_checkpoint()</code> - Save training checkpoint.</li> <li><code>update_ema()</code> - Update EMA model parameters.</li> </ul>"},{"location":"api/torchebm/utils/eqm_utils/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/utils/eqm_utils/#torchebm.utils.eqm_utils","title":"torchebm.utils.eqm_utils","text":"<p>Utilities for EqM training and sampling.</p>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/","title":"WandbLogger","text":""},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#methods-and-attributes","title":"Methods and Attributes","text":"<p>Simple wandb logging wrapper.</p> Source code in <code>torchebm/utils/eqm_utils.py</code> <pre><code>class WandbLogger:\n    r\"\"\"Simple wandb logging wrapper.\"\"\"\n\n    def __init__(self, enabled: bool = False):\n        self.enabled = enabled\n        if enabled:\n            try:\n                import wandb\n\n                self.wandb = wandb\n            except ImportError:\n                print(\"wandb not installed, disabling logging\")\n                self.enabled = False\n\n    def initialize(self, config: Dict[str, Any], entity: str, project: str, name: str):\n        r\"\"\"Initialize wandb run.\"\"\"\n        if self.enabled:\n            self.wandb.init(config=config, entity=entity, project=project, name=name)\n\n    def log(self, metrics: Dict[str, Any], step: int):\n        r\"\"\"Log metrics to wandb.\"\"\"\n        if self.enabled:\n            self.wandb.log(metrics, step=step)\n\n    def finish(self):\n        r\"\"\"Finish wandb run.\"\"\"\n        if self.enabled:\n            self.wandb.finish()\n</code></pre>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#torchebm.utils.eqm_utils.WandbLogger.enabled","title":"enabled  <code>instance-attribute</code>","text":"<pre><code>enabled = enabled\n</code></pre>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#torchebm.utils.eqm_utils.WandbLogger.wandb","title":"wandb  <code>instance-attribute</code>","text":"<pre><code>wandb = wandb\n</code></pre>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#torchebm.utils.eqm_utils.WandbLogger.initialize","title":"initialize","text":"<pre><code>initialize(config: Dict[str, Any], entity: str, project: str, name: str)\n</code></pre> <p>Initialize wandb run.</p> Source code in <code>torchebm/utils/eqm_utils.py</code> <pre><code>def initialize(self, config: Dict[str, Any], entity: str, project: str, name: str):\n    r\"\"\"Initialize wandb run.\"\"\"\n    if self.enabled:\n        self.wandb.init(config=config, entity=entity, project=project, name=name)\n</code></pre>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#torchebm.utils.eqm_utils.WandbLogger.log","title":"log","text":"<pre><code>log(metrics: Dict[str, Any], step: int)\n</code></pre> <p>Log metrics to wandb.</p> Source code in <code>torchebm/utils/eqm_utils.py</code> <pre><code>def log(self, metrics: Dict[str, Any], step: int):\n    r\"\"\"Log metrics to wandb.\"\"\"\n    if self.enabled:\n        self.wandb.log(metrics, step=step)\n</code></pre>"},{"location":"api/torchebm/utils/eqm_utils/classes/WandbLogger/#torchebm.utils.eqm_utils.WandbLogger.finish","title":"finish","text":"<pre><code>finish()\n</code></pre> <p>Finish wandb run.</p> Source code in <code>torchebm/utils/eqm_utils.py</code> <pre><code>def finish(self):\n    r\"\"\"Finish wandb run.\"\"\"\n    if self.enabled:\n        self.wandb.finish()\n</code></pre>"},{"location":"api/torchebm/utils/visualization/","title":"Visualization","text":""},{"location":"api/torchebm/utils/visualization/#torchebm-utils-visualization","title":"Torchebm &gt; Utils &gt; Visualization","text":""},{"location":"api/torchebm/utils/visualization/#contents","title":"Contents","text":""},{"location":"api/torchebm/utils/visualization/#functions","title":"Functions","text":"<ul> <li><code>plot_2d_energy_landscape()</code> - Plots a 2D energy landscape of a model.</li> <li><code>plot_3d_energy_landscape()</code> - Plots a 3D surface visualization of a 2D energy landscape.</li> <li><code>plot_sample_trajectories()</code> - Plots sample trajectories, optionally on an energy landscape background.</li> <li><code>plot_samples_on_energy()</code> - Plots samples on a 2D energy landscape.</li> </ul>"},{"location":"api/torchebm/utils/visualization/#api-reference","title":"API Reference","text":""},{"location":"api/torchebm/utils/visualization/#torchebm.utils.visualization","title":"torchebm.utils.visualization","text":""},{"location":"blog/","title":"Blog","text":""},{"location":"blog/#torchebm-blog","title":"TorchEBM Blog","text":"<p>Welcome to the TorchEBM blog! Here you'll find latest news, tutorials, research insights, and updates about the project.</p>"},{"location":"blog/#categories","title":"Categories","text":"<ul> <li> Tutorials</li> <li> Research</li> <li> Announcements</li> <li> Examples</li> </ul>"},{"location":"blog/#recent-posts","title":"Recent Posts","text":""},{"location":"blog/hamiltonian-mechanics/","title":"Hamiltonian Mechanics","text":"","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#hamiltonian-mechanics","title":"Hamiltonian Mechanics","text":"<p> Hamiltonian mechanics is a way to describe how physical systems, like planets or pendulums, move over  time, focusing on energy rather than just forces. By reframing complex dynamics through energy lenses,  this 19th-century physics framework now powers cutting-edge generative AI. It uses generalized coordinates \\( q \\) (like position) and their  conjugate momenta \\( p \\) (related to momentum), forming a phase space that captures the system's state. This approach  is particularly useful for complex systems with many parts, making it easier to find patterns and conservation laws.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#mathematical-reformation-from-second-order-to-phase-flow","title":"Mathematical Reformation: From Second-Order to Phase Flow","text":"<p>Newton's \\( F = m\\ddot{q} \\) requires solving second-order differential equations, which become unwieldy for constrained systems or when identifying conserved quantities. </p> <p>The Core Idea</p> <p>Hamiltonian mechanics splits \\( \\ddot{q} = F(q)/m \\) into two first-order equations by introducing conjugate momentum \\( p \\):</p> \\[\\begin{align*} \\dot{q} = \\frac{\\partial H}{\\partial p} &amp; \\text{(Position)}, \\quad \\dot{p} = -\\frac{\\partial H}{\\partial q} &amp; \\text{(Momentum)} \\end{align*}\\] <p>It decomposes acceleration into complementary momentum/position flows. This phase space perspective reveals hidden geometric structure.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#lagrangian-prelude-action-principles","title":"Lagrangian Prelude: Action Principles","text":"<p>The Lagrangian \\( \\mathcal{L}(q, \\dot{q}) = K - U \\) leads to Euler-Lagrange equations via variational calculus: $$ \\frac{d}{dt}\\left( \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}} \\right) - \\frac{\\partial \\mathcal{L}}{\\partial q} = 0 $$</p> <p>Kinetic Energy Symbol</p> <p>Note that the \\( K \\) in the \\( \\mathcal{L}(q, \\dot{q}) = K - U \\) is also represented as \\( T \\).</p> <p>But these remain second-order. The critical leap comes through Legendre Transformation \\( (\\dot{q} \\rightarrow p) \\). The Hamiltonian is derived from the Lagrangian through a Legendre transformation by defining the conjugate momentum  as \\( p_i = \\frac{\\partial \\mathcal{L}}{\\partial \\dot{q}_i} \\); then the Hamiltonian can be written as: $$ H(q,p) = \\sum_i p_i \\dot{q}_i - \\mathcal{L}(q, \\dot{q}) $$</p> Annotated \\( H(q,p) \\) \\[ H(q,p) = \\sum_i \\underbrace{p_i}_{\\text{Conjugate Momentum}} \\underbrace{\\dot{q}_i}_{\\text{Generalized Velocity}} - \\underbrace{\\mathcal{L}(q, \\dot{q})}_{\\text{Lagrangian}} \\] <p>We can write \\( H(q,p) \\) more intuitively as: $$ H(q,p) = K(p) + U(q) $$</p> <p>Proof?</p> <p>T is the Kinetic energy; for simplicity, I'll replace it with K.</p> <p>The negative sign arises because we are subtracting the Lagrangian from the sum of the products of momenta and  velocities. This ensures that the Hamiltonian represents the total energy of the system for conservative systems,  where the Lagrangian is \\( K - U \\) and the Hamiltonian becomes \\( K + U \\).</p> <p>For a simple system where \\( K = \\frac{1}{2}m\\dot{q}^2 \\) and \\( U = U(q) \\), the Hamiltonian would be:</p> <ul> <li>Kinetic Energy: \\( K = \\frac{1}{2}m\\dot{q}^2 \\)</li> <li>Potential Energy: \\( U = U(q) \\)</li> <li>Lagrangian: \\( \\mathcal{L} = \\frac{1}{2}m\\dot{q}^2 - U(q) \\)</li> <li>Conjugate Momentum: \\( p = m\\dot{q} \\)</li> <li>Hamiltonian: \\( H = p\\dot{q} - \\mathcal{L} = p\\frac{p}{m} - \\left(\\frac{1}{2}m\\left(\\frac{p}{m}\\right)^2 - U(q)\\right) = \\frac{p^2}{m} - \\frac{p^2}{2m} + U(q) = \\frac{p^2}{2m} + U(q) = K(p) + U(q) \\)</li> </ul> <p>This flips the script: instead of \\( \\dot{q} \\)-centric dynamics, we get symplectic phase flow.</p> <p>Why This Matters</p> <p>The Hamiltonian becomes the system's total energy \\( H = K + U \\) for many physical systems.  It also provides a framework where time evolution is a canonical transformation -  a symmetry preserving the fundamental Poisson bracket structure \\( \\{q_i, p_j\\} = \\delta_{ij} \\).</p> Canonical and Non-Canonical Transformations <p>A canonical transformation is a change of variables that preserves the form of Hamilton's equations. It's like changing the map projection without altering the landscape.</p> <p>Consider a simple translation: $$ Q = q + a, \\quad P = p + b $$ This transformation preserves the Hamiltonian structure and Poisson bracket: \\( \\{Q, P\\} = \\{q + a, p + b\\} = \\{q, p\\} = 1 = \\delta_{ij} \\)</p> <ul> <li>Preserves Hamiltonian structure.</li> <li>Maintains Poisson bracket invariance.</li> <li>Time evolution can be viewed as a canonical transformation.</li> </ul> <p>On the other hand, non-canonical transformation changes the form of Hamilton's equations.</p> <p>For example, consider the transformation:</p> \\[ Q = q^3, \\quad P = p^3 \\] <p>The Poisson bracket is:</p> <p>\\( \\{Q, P\\} = \\frac{\\partial Q}{\\partial q} \\frac{\\partial P}{\\partial p} - \\frac{\\partial Q}{\\partial p} \\frac{\\partial P}{\\partial q} = 3q^2 \\cdot 3p^2 - 0 = 9q^2p^2 \\neq 1 \\)</p> How to calculate those formula? <p>The Poisson bracket of two functions \\( f \\) and \\( g \\) is defined as: \\( \\{f, g\\} = \\sum_i \\left( \\frac{\\partial f}{\\partial q_i} \\frac{\\partial g}{\\partial p_i} - \\frac{\\partial f}{\\partial p_i} \\frac{\\partial g}{\\partial q_i} \\right) \\)</p> <p>Transformation 1: \\( Q = q + a, \\quad P = p + b \\)</p> <p>Partial Derivatives: </p> <ul> <li>\\( \\frac{\\partial Q}{\\partial q} = 1 \\)</li> <li>\\( \\frac{\\partial Q}{\\partial p} = 0 \\)</li> <li>\\( \\frac{\\partial P}{\\partial q} = 0 \\)</li> <li>\\( \\frac{\\partial P}{\\partial p} = 1 \\)</li> </ul> <p>These derivatives can be represented in matrix form as: \\( \\frac{\\partial (Q, P)}{\\partial (q, p)} = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\)</p> <p>This is a diagonal identity matrix, indicating that the transformation preserves the original structure.</p> <p>Poisson Bracket Calculation \\( \\{Q, P\\} = \\frac{\\partial Q}{\\partial q} \\frac{\\partial P}{\\partial p} - \\frac{\\partial Q}{\\partial p} \\frac{\\partial P}{\\partial q} = (1)(1) - (0)(0) = 1 \\)</p> <p>Transformation 2: \\( Q = q^3, \\quad P = p^3 \\)</p> <p>Partial Derivatives - \\( \\frac{\\partial Q}{\\partial q} = 3q^2 \\) - \\( \\frac{\\partial Q}{\\partial p} = 0 \\) - \\( \\frac{\\partial P}{\\partial q} = 0 \\) - \\( \\frac{\\partial P}{\\partial p} = 3p^2 \\)</p> <p>These derivatives can be represented as: \\( \\frac{\\partial (Q, P)}{\\partial (q, p)} = \\begin{pmatrix} 3q^2 &amp; 0 \\\\ 0 &amp; 3p^2 \\end{pmatrix} \\)</p> <p>This is a diagonal matrix but not the identity matrix, indicating that the transformation does not preserve the original structure.</p> <p>Poisson Bracket Calculation \\( \\{Q, P\\} = \\frac{\\partial Q}{\\partial q} \\frac{\\partial P}{\\partial p} - \\frac{\\partial Q}{\\partial p} \\frac{\\partial P}{\\partial q} = (3q^2)(3p^2) - (0)(0) = 9q^2p^2 \\)</p> <ul> <li>Transformation 1 preserves the Poisson bracket structure because it results in a constant value of 1, represented by an identity matrix.</li> <li>Transformation 2 does not preserve the Poisson bracket structure because the result depends on \\( q \\) and \\( p \\), represented by a non-identity diagonal matrix.</li> </ul> <p>This transformation is not canonical because it does not preserve the Poisson bracket structure.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#newton-vs-lagrange-vs-hamilton-a-philosophical-showdown","title":"Newton vs. Lagrange vs. Hamilton: A Philosophical Showdown","text":"Aspect Newtonian Lagrangian Hamiltonian State Variables Position \\( x \\) and velocity \\( \\dot{x} \\) Generalized coordinates \\( q \\) and velocities \\( \\dot{q} \\) Generalized coordinates \\( q \\) and conjugate momenta \\( p \\) Formulation Second-order differential equations \\( (F=ma) \\) Principle of least action (\\( \\delta \\int L \\, dt = 0 \\)) First-order differential equations from Hamiltonian function (Phase flow \\( (dH) \\)) Identifying Symmetries Manual identification or through specific methods Noether's theorem Canonical transformations and Poisson brackets Machine Learning Connection Physics-informed neural networks, simulations Optimal control, reinforcement learning Hamiltonian Monte Carlo (HMC) sampling, energy-based models Energy Conservation Not inherent (must be derived) Built-in through conservation laws Central (Hamiltonian is energy) General Coordinates Possible, but often cumbersome Natural fit Natural fit Time Reversibility Yes Yes Yes, especially in symplectic formulations","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#hamiltons-equations-the-geometry-of-phase-space","title":"Hamilton's Equations: The Geometry of Phase Space","text":"<p>The phase space is a mathematical space where we can represent the set of possible states of a physical system. For a system with \\( n \\) degrees of freedom, the phase space is a \\( 2n \\)-dimensional space, often visualized as a map where each point \\( (q, p) \\) represents a unique state. The evolution of the system is described by the motion of a point in this space, governed by Hamilton's equations.</p>      Your browser does not support the video tag.        Phase space portrait of a nonlinear pendulum showing oscillatory motion (closed orbits), rotational motion (wavy trajectories), and separatrices (red curves) connecting unstable equilibrium points. Position (q) and momentum (p) dynamics illustrate energy conservation principles fundamental to Hamiltonian systems.   <p>This formulation offers several advantages. It makes it straightforward to identify conserved quantities and symmetries through canonical transformations and Poisson brackets, which provides deeper insights into the system's behavior. For instance, Liouville's theorem states that the volume in phase space occupied by an ensemble of systems remains constant over time, expressed as:</p> \\[ \\frac{\\partial \\rho}{\\partial t} + \\{\\rho, H\\} = 0 \\] <p>or equivalently:</p> \\[ \\frac{\\partial \\rho}{\\partial t} + \\sum_i \\left(\\frac{\\partial \\rho}{\\partial q_i}\\frac{\\partial H}{\\partial p_i} - \\frac{\\partial \\rho}{\\partial p_i}\\frac{\\partial H}{\\partial q_i}\\right) = 0 \\] <p>where \\( \\rho(q, p, t) \\) is the density function. This helps us to represent the phase space flows and how they  preserve area under symplectic transformations. Its relation to symplectic geometry enables mathematical properties that are directly relevant to many numerical methods. For instance, it enables Hamiltonian Monte Carlo to perform well in high-dimensions by defining MCMC strategies that increases the chances of accepting a sample (particle). </p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#symplecticity-the-sacred-invariant","title":"Symplecticity: The Sacred Invariant","text":"<p>Hamiltonian flows preserve the symplectic 2-form \\( \\omega = \\sum_i dq_i \\wedge dp_i \\). </p> Symplectic 2-form \\( \\omega \\) <p>The symplectic 2-form, denoted by \\( \\omega = \\sum_i dq_i \\wedge dp_i \\), is a mathematical object used in  symplectic geometry. It measures the area of parallelograms formed by vectors in the tangent space of a phase space.</p> <ul> <li>\\( dq_i \\) and \\( dp_i \\): Infinitesimal changes in position and momentum coordinates.</li> <li>\\( \\wedge \\): The wedge product, which combines differential forms in an antisymmetric way meaning that \\( dq_i \\wedge dp_i = -dp_i \\wedge dq_i \\).</li> <li>\\( \\sum_i \\): Sum over all degrees of freedom.</li> </ul> <p>Imagine a phase space where each point represents a state of a physical system. The symplectic form assigns a  value to each pair of vectors, effectively measuring the area of the parallelogram they span. This area is  preserved under Hamiltonian flows.</p> <p>Key Properties</p> <ol> <li>Closed: \\( d\\omega = 0 \\) which means its exterior derivative is zero \\( d\\omega=0 \\). This property ensures that the form does not change under continuous transformations.</li> <li>Non-degenerate: The form is non-degenerate if \\( d\\omega(X,Y)=0 \\) for all \\( Y \\)s, then \\( X=0 \\). This ensures that every vector has a unique \"partner\" vector such that their pairing under \\( \\omega \\) is non-zero.</li> </ol> <p>Example</p> <p>For a simple harmonic oscillator with one degree of freedom, \\( \\omega = dq \\wedge dp \\). This measures the area of parallelograms in the phase space spanned by vectors representing changes in position and momentum.</p> <p>A Very Simplistic PyTorch Code: While PyTorch doesn't directly handle differential forms, you can conceptually represent the symplectic form using tensors:</p> <pre><code>import torch\n\n# Conceptual representation of dq and dp as tensors\ndq = torch.tensor([1.0])  \ndp = torch.tensor([1.0])  \n\n# \"Wedge product\" conceptually represented using an outer product\nomega = torch.outer(dq, dp) - torch.outer(dp, dq)\n\nprint(omega)\n</code></pre> <p>This code illustrates the antisymmetric nature of the wedge product.</p> <p>Numerically, this means good integrators must respect:</p> \\[ \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))}^T J \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} = J \\quad \\text{where } J = \\begin{pmatrix} 0 &amp; I \\\\ -I &amp; 0 \\end{pmatrix} \\] Breaking Down the Formula <ul> <li>Geometric numerical integration solves differential equations while preserving geometric properties of the system.</li> <li> <p>Symplecticity is a geometric property inherent to Hamiltonian systems. It ensures that the area of geometric  structures (e.g., parallelograms) in phase space \\( (q, p) \\) remains constant over time. This is encoded in the  symplectic form \\( \\omega = \\sum_i dq_i \\wedge dp_i \\).</p> </li> <li> <p>A numerical method is symplectic if it preserves \\( \\omega \\). The Jacobian matrix of the transformation  from \\( (q(t), p(t)) \\) to \\( (q(t + \\epsilon), p(t + \\epsilon)) \\) must satisfy the condition above.</p> </li> <li> <p>The Jacobian matrix \\( \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} \\)  quantifies how small changes in the initial state \\( (q(t), p(t)) \\) propagate to the next state \\( (q(t + \\epsilon), p(t + \\epsilon)) \\).</p> </li> <li> <p>\\( q(t) \\) and \\( p(t) \\) : Position and momentum at time \\( t \\).</p> </li> <li>\\( q(t + \\epsilon) \\) and \\( p(t + \\epsilon) \\) : Updated position and momentum after one time step \\( \\epsilon \\).</li> <li>\\( \\frac{\\partial}{\\partial (q(t), p(t))} \\) : Partial derivatives with respect to the initial state.</li> </ul>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#how-are-we-going-to-solve-it","title":"How are We Going to Solve it?","text":"<p>Numerical solvers for differential equations inevitably introduce errors that affect solution accuracy. These errors manifest as deviations from the true trajectory in phase space, particularly noticeable in energy-conserving systems like the harmonic oscillator. The errors fall into two main categories: local truncation error, arising from the approximation of continuous derivatives with discrete steps (proportional to \\( \\mathcal{O}(\\epsilon^n+1) \\) where \\( \\epsilon \\) is the step size and n depends on the method); and global accumulation error, which compounds over integration time.</p> <p>Forward Euler Method Fails at This!</p> <p>To overcome this, we turn to symplectic integrators\u2014methods that respect the underlying geometry of Hamiltonian  systems, leading us naturally to the Leapfrog Verlet method, a powerful symplectic alternative. \ud83d\ude80</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#key-issue-energy-drift-from-non-symplectic-updates","title":"Key Issue: Energy Drift from Non-Symplectic Updates","text":"<p>The forward Euler method (FEM) violates the geometric structure of Hamiltonian systems,  leading to energy drift in long-term simulations. Let\u2019s dissect why.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#forward-euler-in-hamiltonian-systems","title":"Forward Euler in Hamiltonian Systems","text":"<p>For a Hamiltonian \\( H(q, p) \\), the forward Euler updates position and momentum as: \\( q(t + \\epsilon) = q(t) + \\epsilon \\frac{\\partial H}{\\partial p}(q(t), p(t)),\\quad  p(t + \\epsilon) = p(t) - \\epsilon \\frac{\\partial H}{\\partial q}(q(t), p(t)) \\)</p> <p>Unlike Leapfrog Verlet, these updates do not split the position/momentum dependencies, breaking symplecticity.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#step-by-step-failure-harmonic-oscillator-example","title":"Step-by-Step Failure: Harmonic Oscillator Example","text":"<p>Hamiltonian: \\( H = \\frac{1}{2}(q^2 + p^2) \\quad \\text{(mass-spring system with m = k = 1 )} \\)</p> <p>Forward Euler Updates: \\( q(t + \\epsilon) = q(t) + \\epsilon p(t) \\quad \\text{(position update)} \\quad p(t + \\epsilon) = p(t) - \\epsilon q(t) \\quad \\text{(momentum update)} \\)</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#jacobian-matrix-analysis","title":"Jacobian Matrix Analysis","text":"<p>The Jacobian \\( M = \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} \\) becomes: \\( M = \\begin{pmatrix} 1 &amp; \\epsilon \\\\ -\\epsilon &amp; 1 \\end{pmatrix} \\)</p> <p>Symplectic Condition Check: Does \\( M^T J M = J \\), where \\( J = \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} \\)?</p> <ol> <li> <p>Transpose \\( M^T \\): \\(    M^T = \\begin{pmatrix}    1 &amp; -\\epsilon \\\\    \\epsilon &amp; 1    \\end{pmatrix}    \\)</p> </li> <li> <p>Compute \\( J M \\): \\(       J M = \\begin{pmatrix}       -\\epsilon &amp; 1 \\\\       -1 &amp; -\\epsilon       \\end{pmatrix}       \\)</p> </li> <li> <p>Final Product \\( M^T J M \\): \\(       M^T J M = \\begin{pmatrix}       0 &amp; 1 + \\epsilon^2 \\\\       -1 - \\epsilon^2 &amp; 0       \\end{pmatrix} \\neq J       \\)</p> </li> </ol> <p>The result violates \\( M^T J M = J \\), proving symplecticity fails unless \\( \\epsilon = 0 \\).</p> \\[ \\boxed{\\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))}^T J \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} \\neq J} \\]","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#practical-consequences-energy-drift","title":"Practical Consequences: Energy Drift","text":"<p>Why This Matters</p> <ul> <li>Energy Drift: FEM artificially injects/dissipates energy over time because \\( H(q,p) \\) is not conserved.  </li> <li>Phase Space Distortion: Volume preservation fails, corrupting long-term trajectories.  </li> <li>Unusable for HMC: Sampling in Hamiltonian Monte Carlo relies on symplectic integrators to maintain detailed balance.  </li> </ul> <p>Example: Simulating a harmonic oscillator with FEM shows spiraling/non-closing orbits in phase space, unlike the stable ellipses from Leapfrog Verlet.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#symplectic-numerical-integrators","title":"Symplectic Numerical Integrators","text":"","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#leapfrog-verlet","title":"Leapfrog Verlet","text":"<p>For a separable Hamiltonian \\( H(q,p) = K(p) + U(q) \\), where the corresponding probability distribution is given by:</p> \\[ P(q,p) = \\frac{1}{Z} e^{-U(q)} e^{-K(p)}, \\] <p>the Leapfrog Verlet integrator proceeds as follows:</p> \\[ \\begin{aligned} p_{i}\\left(t + \\frac{\\epsilon}{2}\\right) &amp;= p_{i}(t) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q_{i}}(q(t)) \\\\ q_{i}(t + \\epsilon) &amp;= q_{i}(t) + \\epsilon \\frac{\\partial K}{\\partial p_{i}}\\left(p\\left(t + \\frac{\\epsilon}{2}\\right)\\right) \\\\ p_{i}(t + \\epsilon) &amp;= p_{i}\\left(t + \\frac{\\epsilon}{2}\\right) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q_{i}}(q(t + \\epsilon)) \\end{aligned} \\] <p>This St\u00f6rmer-Verlet scheme preserves symplecticity exactly, with local error \\( \\mathcal{O}(\\epsilon^3) \\) and global  error \\( \\mathcal{O}(\\epsilon^2) \\). You can read more about   numerical methods and analysis in Python here.</p> <p>How Exactly?</p> <ol> <li> <p>Leapfrog Verlet Update Equations For a separable Hamiltonian \\( H(q, p) = K(p) + U(q) \\), the method splits into three component-wise steps:</p> <ol> <li> <p>Half-step momentum update: \\(    p_{i}\\left(t + \\frac{\\epsilon}{2}\\right) = p_{i}(t) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q_{i}}(q(t))    \\)</p> </li> <li> <p>Full-step position update: \\(    q_{i}(t + \\epsilon) = q_{i}(t) + \\epsilon \\frac{\\partial K}{\\partial p_{i}}\\left(p\\left(t + \\frac{\\epsilon}{2}\\right)\\right)    \\)</p> </li> <li> <p>Full-step momentum update: \\(    p_{i}(t + \\epsilon) = p_{i}\\left(t + \\frac{\\epsilon}{2}\\right) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q_{i}}(q(t + \\epsilon))    \\)</p> </li> </ol> </li> <li> <p>Jacobian Matrix Calculation For the harmonic oscillator \\( H(q, p) = \\frac{1}{2}(q^2 + p^2) \\), the updates simplify to:  </p> \\[ q(t + \\epsilon) = q(t) + \\epsilon p(t) - \\frac{\\epsilon^2}{2} q(t), \\quad p(t + \\epsilon) = p(t) - \\epsilon q(t) - \\frac{\\epsilon^2}{2} p(t). \\] <p>The Jacobian matrix \\( M = \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} \\) becomes: \\( M = \\begin{pmatrix} 1 - \\frac{\\epsilon^2}{2} &amp; \\epsilon \\\\ -\\epsilon &amp; 1 - \\frac{\\epsilon^2}{2} \\end{pmatrix}. \\)</p> </li> <li> <p>Transpose of \\( M \\) The transpose \\( M^T \\) swaps off-diagonal terms: \\( M^T = \\begin{pmatrix} 1 - \\frac{\\epsilon^2}{2} &amp; -\\epsilon \\\\ \\epsilon &amp; 1 - \\frac{\\epsilon^2}{2} \\end{pmatrix}. \\)</p> </li> <li> <p>Verify \\( M^T J M = J \\) Let \\( J = \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} \\). Compute \\( M^T J M \\):</p> <ol> <li> <p>Calculate: \\( J M = \\begin{pmatrix} -\\epsilon &amp; 1 - \\frac{\\epsilon^2}{2} \\\\ -\\left(1 - \\frac{\\epsilon^2}{2}\\right) &amp; -\\epsilon \\end{pmatrix}. \\)</p> </li> <li> <p>Calculate: \\( M^T J M = \\begin{pmatrix} 1 - \\frac{\\epsilon^2}{2} &amp; -\\epsilon \\\\ \\epsilon &amp; 1 - \\frac{\\epsilon^2}{2} \\end{pmatrix} \\begin{pmatrix} -\\epsilon &amp; 1 - \\frac{\\epsilon^2}{2} \\\\ -\\left(1 - \\frac{\\epsilon^2}{2}\\right) &amp; -\\epsilon \\end{pmatrix}. \\)</p> </li> </ol> <p>After matrix multiplication: \\( M^T J M = \\begin{pmatrix} 0 &amp; 1 \\\\ -1 &amp; 0 \\end{pmatrix} = J. \\)</p> </li> </ol> <p>The Leapfrog Verlet method satisfies \\( M^T J M = J \\), proving it preserves the symplectic structure. This matches its theoretical property as a symplectic integrator.</p> \\[ \\boxed{\\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))}^T J \\frac{\\partial (q(t + \\epsilon), p(t + \\epsilon))}{\\partial (q(t), p(t))} = J} \\]","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#why-symplectic-matters","title":"Why Symplectic Matters","text":"<p>They're the reversible neural nets of physics simulations!</p> <p>Symplectic integrators like Leapfrog Verlet are critical for long-term stability in Hamiltonian systems.  </p> <ul> <li>Phase space preservation: The volume in \\( (q, p) \\)-space is conserved exactly, avoiding artificial energy drift.  </li> <li>Approximate energy conservation: While energy \\( H(q,p) \\) is not perfectly conserved (due to \\( \\mathcal{O}(\\epsilon^2) \\) error), it oscillates near the true value over exponentially long timescales.  </li> <li>Practical relevance: This makes symplectic integrators indispensable in molecular dynamics and Hamiltonian Monte Carlo (HMC), where accurate sampling relies on stable trajectories.  </li> </ul>  Comparison of numerical integration methods for a simple harmonic oscillator in phase space. Color gradients  indicate error magnitude with brighter colors showing larger divergence from the exact solution (white).  Euler's method (a) exhibits energy growth, Modified Euler's method (b) shows improved stability, while  Leapfrog maintains excellent energy conservation at small stepsize (c) but develops geometric distortion  at larger stepsize (d).  <p>Euler's method (first-order) systematically injects energy into the system, causing the characteristic outward spiral seen in the plots. Modified Euler's method (second-order) significantly reduces this energy drift. Most importantly, symplectic integrators like the Leapfrog method preserve the geometric structure of Hamiltonian systems even with relatively large step sizes by maintaining phase space volume conservation. This structural preservation is why Leapfrog remains the preferred method for long-time simulations in molecular dynamics and astronomy, where energy conservation is critical despite the visible polygon-like discretization artifacts at large step sizes.</p> <p>Non-symplectic methods (e.g., Euler-Maruyama) often fail catastrophically in these settings.</p> Integrator Symplecticity Order Type Local Error Global Error Suitable For Computational Cost Euler Method 1 Explicit O(\u03b5\u00b2) O(\u03b5) Quick prototypes and Short-term simulations of general ODEs Low Symplectically Euler 1 Explicit O(\u03b5\u00b2) O(\u03b5) Simple Hamiltonian systems Low Leapfrog (Verlet) 2 Explicit O(\u03b5\u00b3) O(\u03b5\u00b2) Molecular dynamics, Long-term simulations of Hamiltonian systems Moderate Runge-Kutta 4 4 Explicit O(\u03b5\u2075) O(\u03b5\u2074) Short-term accuracy, General ODEs, but not recommended for long-term Hamiltonian systems High Forest-Ruth Integrator 4 Explicit O(\u03b5\u2075) O(\u03b5\u2074) High-accuracy long-term simulations High Yoshida 6<sup>th</sup>-order 6 Explicit O(\u03b5\u2077) O(\u03b5\u2076) High-accuracy High Heun\u2019s Method (RK2) 2 Explicit O(\u03b5\u00b3) O(\u03b5\u00b2) General ODEs requiring moderate accuracy Moderate Third-order Runge-Kutta 3 Explicit O(\u03b5\u2074) O(\u03b5\u00b3) When higher accuracy than RK2 is needed without the cost of RK4 High Implicit Midpoint Rule 2 Implicit (solving equations) O(\u03b5\u00b3) O(\u03b5\u00b2) Hamiltonian systems, stiff problems High Fourth-order Adams-Bashforth 4 Multi-step (explicit) O(\u03b5\u2075) O(\u03b5\u2074) Non-stiff problems with smooth solutions, after initial steps Low Backward Euler Method 1 Implicit (solving equations) O(\u03b5\u00b2) O(\u03b5) Stiff problems, where stability is crucial High","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#hamiltonian-monte-carlo","title":"Hamiltonian Monte Carlo","text":"<p>Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) method that leverages Hamiltonian dynamics to  efficiently sample from complex probability distributions, particularly in Bayesian statistics and machine learning.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#from-phase-space-to-probability-space","title":"From Phase Space to Probability Space","text":"<p>HMC interprets target distribution \\( P(z) \\) as a Boltzmann distribution:</p> \\[ P(z) = \\frac{1}{Z} e^{\\frac{-E(z)}{T}} \\] <p>Substituting into this formulation, the Hamiltonian gives us a joint density:</p> \\[  P(q,p) = \\frac{1}{Z} e^{-U(q)} e^{-K(p)} \\quad \\text{where } U(q) = -\\log[p(q), p(q|D)] \\] <p>where \\( p(q|D) \\) is the likelihood of the given data \\( D \\) and T=1 and therefore removed. We estimate our posterior distribution using the potential energy \\( U(q) \\) since \\( P(q,p) \\) consists of two independent probability distributions.</p> <p>Augment with artificial momentum \\( p \\sim \\mathcal{N}(0,M) \\), then simulate Hamiltonian dynamics to propose new \\( q' \\)  based on the distribution of the position variables \\( U(q) \\) which acts as the \"potential energy\" of the target distribution \\( P(q) \\), thereby creating valleys at high-probability regions.</p> <p>For more on HMC, check out this explanation or  this tutorial.</p> <ul> <li>Physical Systems: \\( H(q,p) = U(q) + K(p) \\) represents total energy  </li> <li>Sampling Systems: \\( H(q,p) = -\\log P(q) + \\frac{1}{2}p^T M^{-1} p \\) defines exploration dynamics  </li> </ul> <p>The kinetic energy with the popular form of \\( K(p) = \\frac{1}{2}p^T M^{-1} p \\), often Gaussian,  injects momentum to traverse these landscapes. Crucially, the mass matrix \\( M \\) plays the role of a  preconditioner - diagonal \\( M \\) adapts to parameter scales, while dense \\( M \\) can align with correlation  structure. \\( M \\) is symmetric, positive definite and typically diagonal.</p> <p>What is Positive Definite?</p> <p>Positive Definite: For any non-zero vector \\( x \\), the expression \\( x^T M x \\) is always positive. This ensures stability and efficiency.</p> <p></p>      Illustration of different quadratic forms in two variables that shows how different covariance matrices      influence the shape of these forms. The plots depict:     a) Positive Definite Form: A bowl-shaped surface where all eigenvalues are positive, indicating a minimum.     b) Negative Definite Form: An inverted bowl where all eigenvalues are negative, indicating a maximum.     c) Indefinite Form: A saddle-shaped surface with both positive and negative eigenvalues, indicating neither a maximum nor a minimum.     Each subplot includes the matrix \\( M \\) and the corresponding quadratic form \\( Q(x) = x^T M x \\).  <p></p> \\[ x^T M x &gt; 0 \\] Kinetic Energy Choices <ul> <li>Gaussian (Standard HMC): \\( K(p) = \\frac{1}{2}p^T M^{-1} p \\)   Yields Euclidean trajectories, efficient for moderate dimensions.  </li> <li>Relativistic (Riemannian HMC): \\( K(p) = \\sqrt{p^T M^{-1} p + c^2} \\)   Limits maximum velocity, preventing divergences in ill-conditioned spaces.  </li> <li>Adaptive (Surrogate Gradients): Learn \\( K(p) \\) via neural networks to match target geometry.</li> </ul> <p>Key Intuition</p> <p>The Hamiltonian \\( H(q,p) = U(q) + \\frac{1}{2}p^T M^{-1} p \\) creates an energy landscape where momentum carries  the sampler through high-probability regions, avoiding random walk behavior.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#the-hmc-algorithm","title":"The HMC Algorithm","text":"<p>The algorithm involves:</p> <ol> <li> <p>Initialization: Start with an initial position \\( q_0 \\) and sample momentum \\( p_0 \\sim \\mathcal{N}(0,M) \\).</p> </li> <li> <p>Leapfrog Integration: Use the leapfrog method to approximate Hamiltonian dynamics. For a step size \\( \\epsilon \\) and L steps, update:</p> </li> <li> <p>Half-step momentum: \\( p(t + \\frac{\\epsilon}{2}) = p(t) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q}(q(t)) \\)</p> </li> <li>Full-step position: \\( q(t + \\epsilon) = q(t) + \\epsilon \\frac{\\partial K}{\\partial p}(p(t + \\frac{\\epsilon}{2})) \\), where \\( K(p) = \\frac{1}{2} p^T M^{-1} p \\), so \\( \\frac{\\partial K}{\\partial p} = M^{-1} p \\)</li> <li>Full-step momentum: \\( p(t + \\epsilon) = p(t + \\frac{\\epsilon}{2}) - \\frac{\\epsilon}{2} \\frac{\\partial U}{\\partial q}(q(t + \\epsilon)) \\)</li> </ol> <p>This is repeated L times to get proposed \\( \\dot{q} \\) and \\( \\dot{p} \\).</p> <ol> <li>Metropolis-Hastings Acceptance: Accept the proposed \\( \\dot{q} \\) with probability \\( \\min(1, e^{H(q_0,p_0) - H(\\dot{q},\\dot{p})}) \\), where \\( H(q,p) = U(q) + K(p) \\).</li> </ol> <p>This process generates a Markov chain with stationary distribution \\( P(q) \\), leveraging Hamiltonian dynamics to take larger, more efficient steps compared to random-walk methods.</p> Why Better Than Random Walk? <p>HMC navigates high-dimensional spaces along energy contours -  like following mountain paths instead of wandering randomly!</p> Recap of the Hamilton's equations? \\[ \\begin{cases} \\dot{q} = \\nabla_p K(p) = M^{-1}p &amp; \\text{(Guided exploration)} \\\\ \\dot{p} = -\\nabla_q U(q) = \\nabla_q \\log P(q) &amp; \\text{(Bayesian updating)} \\end{cases} \\] <p>This coupled system drives \\( (q,p) \\) along iso-probability contours of \\( P(q) \\), with momentum rotating rather  than resetting at each step like in Random Walk Metropolis--think of following mountain paths instead of wandering randomly! The key parameters - integration time \\( \\tau = L\\epsilon \\) and step size \\( \\epsilon \\) - balance exploration vs. computational cost:  </p> <ul> <li>Short \\( \\tau \\): Local exploration, higher acceptance  </li> <li>Long \\( \\tau \\): Global moves, risk of U-turns (periodic orbits)  </li> </ul> <p>Key Parameters and Tuning</p> <p>Tuning \\( M \\) to match the covariance of \\( P(q) \\) (e.g., via warmup adaptation) and setting \\( \\tau \\sim \\mathcal{O}(1/\\lambda_{\\text{max}}) \\), where \\( \\lambda_{\\text{max}} \\) is the largest eigenvalue of \\( \\nabla^2 U \\), often yields optimal mixing.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#connection-with-energy-based-models","title":"Connection with Energy-Based Models","text":"<p>Energy-based models (EBMs) are a class of generative models that define a probability distribution over data points  using an energy function. The probability of a data point is proportional to \\( e^{-E(x)} \\), where \\( E(x) \\) is the  energy function. This formulation is directly analogous to the Boltzmann distribution in statistical physics, where the  probability is related to the energy of a state. In Hamiltonian mechanics, the Hamiltonian function \\( H(q, p) \\)  represents the total energy of the system, and the probability distribution in phase space is given  by \\( e^{-H(q,p)/T} \\), where \\( T \\) is the temperature.</p> <p>In EBMs, Hamiltonian Monte Carlo (HMC) is often used to sample from the model's distribution. HMC leverages  Hamiltonian dynamics to propose new states, which are then accepted or rejected based on the Metropolis-Hastings  criterion. This method is particularly effective for high-dimensional problems, as it reduces the correlation between  samples and allows for more efficient exploration of the state space. For instance, in image generation tasks, HMC  can sample from the distribution defined by the energy function, facilitating the generation of high-quality images.</p> <p>EBMs define probability through Hamiltonians:</p> \\[ p(x) = \\frac{1}{Z}e^{-E(x)} \\quad \\leftrightarrow \\quad H(q,p) = E(q) + K(p) \\]","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#potential-research-directions","title":"Potential Research Directions","text":"","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#symplecticity-in-machine-learning-models","title":"Symplecticity in Machine Learning Models","text":"Overview of the Hamiltonian Neural Networks architecture. Image from the HNN paper. <p>Incorporate the symplectic structure of Hamiltonian mechanics into machine learning models to preserve properties  like energy conservation, which is crucial for long-term predictions. Generalizing Hamiltonian Neural Networks (HNNs),  as discussed in Hamiltonian Neural Networks, to more complex systems or developing new architectures that preserve symplecticity</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#hmc-for-complex-distributions","title":"HMC for Complex Distributions:","text":"<p>HMC for sampling from complex, high-dimensional, and multimodal distributions, such as those encountered in deep learning. Combining HMC with other techniques, like parallel tempering, could handle distributions with multiple modes more  effectively.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#combining-hamiltonian-mechanics-with-other-ml-techniques","title":"Combining Hamiltonian Mechanics with Other ML Techniques:","text":"<p>Integrate Hamiltonian mechanics with reinforcement learning to guide exploration in continuous state and action spaces. Using it to model the environment could improve exploration strategies, as seen in potential applications in robotics.  Additionally, using Hamiltonian mechanics to define approximate posteriors in variational inference could lead to more  flexible and accurate approximations.   </p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#hamiltonian-gans","title":"Hamiltonian GANs","text":"<p>Employing Hamiltonian formalism as an inductive bias for the generation of physically plausible videos with neural networks. Imagine generator-discriminator dynamics governed by:</p> <p>The possibilities make phase space feel infinite...</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#want-to-team-up-on-this","title":"Want to Team Up on This \ud83e\udd13","text":"<p>If you are an ML researcher and are interested in collaborating on researching EBMs,  diffusion- and flow-based models, or have other relevant ideas in mind for generalization over out-of-distribution  data (downstream tasks can be anything in from molecular design to robotics motion planning to LLMs), please feel free to reach out!</p> <p>Also follow me on  Twitter /  BlueSky or  GitHub\u2014I\u2019m usually rambling about this stuff there.  Also on LinkedIn and  Medium /  TDS if you\u2019re curious.  To find more about my research interests, check out my  personal website.</p>","tags":["hamiltonian","sampling"]},{"location":"blog/hamiltonian-mechanics/#useful-links","title":"Useful Links","text":"<ul> <li>An Introduction to Multistep Methods: Leap-frog</li> <li>The beginners guide to Hamiltonian Monte Carlo</li> <li>Hamiltonian Monte Carlo</li> <li>Hamiltonian Monte Carlo - Stan - Stan explained</li> <li>Hamiltonian Mechanics For Dummies: An Intuitive Introduction.</li> <li>Hamiltonian mechanics Wikipedia page</li> <li>An introduction to Lagrangian and Hamiltonian mechanics Lecture notes</li> <li> <p>Hamiltonian Mechanics - Jeremy Tatum, University of Victoria</p> </li> <li> <p>Hamiltonian Neural Networks - Blog</p> </li> <li>Hamiltonian Neural Networks</li> <li>Other: Natural Intelligence - A blog by Sam Greydanus - Many interesting topics </li> </ul>","tags":["hamiltonian","sampling"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/","title":"Langevin Dynamics Sampling with TorchEBM","text":"","tags":["langevin","sampling","tutorial"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/#langevin-dynamics-sampling-with-torchebm","title":"Langevin Dynamics Sampling with TorchEBM","text":"<p>Langevin dynamics is a powerful sampling technique that allows us to draw samples from complex probability distributions. In this tutorial, we'll explore how to use TorchEBM's implementation of Langevin dynamics for sampling from various energy landscapes.</p>","tags":["langevin","sampling","tutorial"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/#basic-example-sampling-from-a-2d-gaussian","title":"Basic Example: Sampling from a 2D Gaussian","text":"<p>Let's start with a simple example of sampling from a 2D Gaussian distribution:</p> Basic Langevin Dynamics Sampling<pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom torchebm.core import GaussianEnergy\nfrom torchebm.samplers.langevin_dynamics import LangevinDynamics\n\n# Create energy function for a 2D Gaussian\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndim = 2  # dimension of the state space\nn_steps = 100  # steps between samples\nn_samples = 1000  # num of samples\nmean = torch.tensor([1.0, -1.0])\ncov = torch.tensor([[1.0, 0.5], [0.5, 2.0]])\nenergy_fn = GaussianEnergy(mean, cov, device=device)\n\n# Initialize sampler\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.01,\n    noise_scale=0.1,\n    device=device,\n)\n\n# Generate samples\ninitial_state = torch.zeros(n_samples, dim, device=device)\nsamples = sampler.sample(\n    x=initial_state,\n    n_steps=n_steps,\n    n_samples=n_samples,\n)\n\n# Plot results\nsamples = samples.cpu().numpy()\nplt.figure(figsize=(10, 5))\nplt.scatter(samples[:, 0], samples[:, 1], alpha=0.1)\nplt.title(\"Samples from 2D Gaussian using Langevin Dynamics\")\nplt.xlabel(\"x\u2081\")\nplt.ylabel(\"x\u2082\")\nplt.show()\n</code></pre>","tags":["langevin","sampling","tutorial"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/#advanced-example-double-well-potential","title":"Advanced Example: Double Well Potential","text":"<p>For a more interesting example, let's sample from a double well potential, which has two local minima:</p> Double Well Energy Sampling<pre><code>from torchebm.core import DoubleWellEnergy\n\n# Create energy function and sampler\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nenergy_fn = DoubleWellEnergy(barrier_height=2.0)\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.001,\n    noise_scale=0.1,\n    decay=0.1,  # for stability\n    device=device,\n)\n\n# Generate trajectory with diagnostics\ninitial_state = torch.tensor([0.0], device=device)\ntrajectory, diagnostics = sampler.sample(\n    x=initial_state,\n    n_steps=1000,\n    return_trajectory=True,\n    return_diagnostics=True,\n)\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n\n# Plot trajectory\nax1.plot(trajectory[0, :, 0].cpu().numpy())\nax1.set_title(\"Single Chain Trajectory\")\nax1.set_xlabel(\"Step\")\nax1.set_ylabel(\"Position\")\n\n# Plot energy over time\nax2.plot(diagnostics[:, 2, 0, 0].cpu().numpy())\nax2.set_title(\"Energy Evolution\")\nax2.set_xlabel(\"Step\")\nax2.set_ylabel(\"Energy\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["langevin","sampling","tutorial"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/#key-benefits-of-torchebms-langevin-dynamics-implementation","title":"Key Benefits of TorchEBM's Langevin Dynamics Implementation","text":"<ol> <li>GPU Acceleration - Sampling is performed efficiently on GPUs when available</li> <li>Flexible API - Easy to use with various energy functions and initialization strategies</li> <li>Diagnostic Tools - Track energy, gradient norms, and acceptance rates during sampling</li> <li>Configurable Parameters - Fine-tune step size, noise scale, and decay for optimal performance</li> </ol>","tags":["langevin","sampling","tutorial"]},{"location":"blog/langevin-dynamics-sampling-with-torchebm/#conclusion","title":"Conclusion","text":"<p>Langevin dynamics is a versatile sampling method for energy-based models, and TorchEBM makes it easy to use in your projects. Whether you're sampling from simple analytical distributions or complex neural network energy functions, the same API works seamlessly.</p> <p>Stay tuned for more tutorials on other samplers and energy functions! </p><p></p>","tags":["langevin","sampling","tutorial"]},{"location":"developer_guide/","title":"Developer Guide","text":""},{"location":"developer_guide/#torchebm-developer-guide","title":"TorchEBM Developer Guide","text":"<p>Welcome to the developer guide for TorchEBM! This is your central hub for everything you need to know to contribute to the project, understand its architecture, and follow our development best practices.</p> <p>Whether you're a new contributor or a seasoned developer, these guides are designed to be clear, concise, and easy to follow. Our goal is to make contributing to TorchEBM a smooth and rewarding experience.</p>"},{"location":"developer_guide/#a-path-to-contribution","title":"A Path to Contribution","text":"<p>We've organized our developer documentation to help you get up to speed quickly and efficiently.</p> <ul> <li> <p> Getting Started</p> <p>Your first stop. This guide walks you through setting up your development environment, our contribution workflow, and how to submit your first pull request.</p> </li> <li> <p> Code Guidelines</p> <p>Learn about our coding standards, from Python style and API design principles to our philosophy on testing. Essential reading for writing high-quality code.</p> </li> <li> <p> Architecture</p> <p>A deep dive into the heart of TorchEBM. Understand our design philosophy, core components, and how they all fit together.</p> </li> <li> <p> Performance</p> <p>Discover how to write high-performance code, leverage GPU acceleration, and other best practices for optimization.</p> </li> </ul> <p>We're thrilled to have you as part of our community and look forward to your contributions! </p>"},{"location":"developer_guide/architecture/","title":"Architecture","text":""},{"location":"developer_guide/architecture/#torchebm-architecture","title":"TorchEBM Architecture","text":"<p>This document provides a comprehensive overview of TorchEBM's architecture, from high-level design principles to the details of its core components.</p>"},{"location":"developer_guide/architecture/#design-philosophy","title":"Design Philosophy","text":"<p>TorchEBM is built on a foundation of modularity, performance, and ease of use. Our core philosophy is to provide a set of powerful, composable tools for energy-based modeling that are both highly efficient and intuitive for researchers and developers.</p> <ul> <li> <p> Modularity &amp; Composability</p> <p>Components are designed to be mixed and matched, allowing for flexible construction of complex models and algorithms.</p> </li> <li> <p> Performance</p> <p>The library is optimized for speed, leveraging PyTorch's vectorized operations and providing CUDA support for critical components.</p> </li> <li> <p> Intuitiveness</p> <p>APIs are designed to be clean, consistent, and well-documented, following standard PyTorch conventions.</p> </li> </ul>"},{"location":"developer_guide/architecture/#project-structure","title":"Project Structure","text":"<p>The repository is organized into the following key directories:</p> <pre><code>torchebm/\n\u251c\u2500\u2500 torchebm/              # Main package source code\n\u2502   \u251c\u2500\u2500 core/              # Core functionality and base classes\n\u2502   \u251c\u2500\u2500 samplers/          # Sampling algorithms\n\u2502   \u251c\u2500\u2500 losses/            # Loss functions for training\n\u2502   \u251c\u2500\u2500 models/            # Pre-built model architectures\n\u2502   \u2514\u2500\u2500 utils/             # Utility functions\n\u251c\u2500\u2500 tests/                 # Unit and integration tests\n\u251c\u2500\u2500 docs/                  # Documentation source\n\u251c\u2500\u2500 examples/              # Example usage scripts\n\u2514\u2500\u2500 setup.py               # Package installation script\n</code></pre>"},{"location":"developer_guide/architecture/#core-components","title":"Core Components","text":"<p>TorchEBM's functionality is centered around a few fundamental abstractions:</p>"},{"location":"developer_guide/architecture/#1-models-torchebmcorebasemodel","title":"1. Models (<code>torchebm.core.BaseModel</code>)","text":"<p>A Model defines the energy function \\( E(x) \\), which assigns a scalar energy value to each input state \\( x \\). This is the central component of any EBM. In TorchEBM, models are PyTorch modules (<code>nn.Module</code>) that implement a <code>forward(x)</code> method to compute the energy.</p>"},{"location":"developer_guide/architecture/#2-samplers-torchebmcorebasesampler","title":"2. Samplers (<code>torchebm.core.BaseSampler</code>)","text":"<p>A Sampler is an algorithm that generates samples from the probability distribution defined by an energy model, \\( p(x) = \\frac{e^{-E(x)}}{Z} \\). Samplers in TorchEBM are designed to work with any <code>BaseModel</code> instance. Examples include <code>LangevinDynamics</code> and <code>HamiltonianMonteCarlo</code>.</p>"},{"location":"developer_guide/architecture/#3-losses-torchebmcorebaseloss","title":"3. Losses (<code>torchebm.core.BaseLoss</code>)","text":"<p>A Loss function is used to train the parameters of a model. These typically rely on a sampler to generate \"negative\" samples from the model's current distribution to contrast with \"positive\" samples from the data. <code>ContrastiveDivergence</code> is a key example.</p>"},{"location":"developer_guide/architecture/#component-interactions","title":"Component Interactions","text":"<p>The components interact in a clear, defined workflow, particularly during training:</p> <pre><code>graph TD\n    subgraph \"Training Loop\"\n        Data[Data Samples] --&gt; Loss\n        Model --&gt; Sampler\n        Sampler --&gt; Loss\n        Loss -- Gradient --&gt; Optimizer\n        Optimizer -- Updates --&gt; Model\n    end\n\n    subgraph \"Inference/Sampling\"\n        Trained_Model[Trained Model] --&gt; Inference_Sampler[Sampler]\n        Inference_Sampler --&gt; Generated_Samples[Generated Samples]\n    end</code></pre> <ol> <li>A Loss function takes the Model and a batch of real data.</li> <li>It uses a Sampler to generate samples from the model's current distribution.</li> <li>The loss is computed based on the energies of the real and generated samples.</li> <li>The gradient of the loss is used to update the Model's parameters.</li> </ol> <p>This modular design allows you to, for example, swap out different samplers to see their effect on the training of a given model, without changing the model or the loss function. </p>"},{"location":"developer_guide/code_guidelines/","title":"Code Guidelines","text":""},{"location":"developer_guide/code_guidelines/#code-guidelines","title":"Code Guidelines","text":"<p>This document outlines the standards for writing code, designing APIs, and testing in TorchEBM. Following these guidelines ensures our codebase is consistent, readable, and maintainable.</p>"},{"location":"developer_guide/code_guidelines/#code-style","title":"Code Style","text":"<p>TorchEBM follows PEP 8 and uses automatic formatters to enforce a consistent style.</p>"},{"location":"developer_guide/code_guidelines/#automatic-formatting-and-linting","title":"Automatic Formatting and Linting","text":"<p>We use the following tools to maintain code quality. Please run them before committing your changes.</p> <ul> <li> <p> Black</p> <p>Formats Python code automatically and uncompromisingly.</p> <pre><code>black torchebm/ tests/\n</code></pre> </li> <li> <p> isort</p> <p>Sorts imports alphabetically and separates them into sections.</p> <pre><code>isort torchebm/ tests/\n</code></pre> </li> <li> <p> Flake8</p> <p>Linter to check for style and logical issues.</p> <pre><code>flake8 torchebm/ tests/\n</code></pre> </li> </ul>"},{"location":"developer_guide/code_guidelines/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Classes: <code>CamelCase</code> (e.g., <code>LangevinDynamics</code>)</li> <li>Functions &amp; Variables: <code>snake_case</code> (e.g., <code>compute_energy</code>)</li> <li>Constants: <code>UPPER_CASE</code> (e.g., <code>DEFAULT_STEP_SIZE</code>)</li> </ul>"},{"location":"developer_guide/code_guidelines/#docstrings-and-type-annotations","title":"Docstrings and Type Annotations","text":"<ul> <li>Use Google-style docstrings.</li> <li>Provide type hints for all function signatures.</li> </ul> <pre><code>from typing import Optional, Tuple\nimport torch\n\ndef sample_chain(\n    dim: int,\n    n_steps: int,\n    n_samples: int = 1\n) -&gt; Tuple[torch.Tensor, dict]:\n    \"\"\"Generate samples using a Markov chain.\n\n    Args:\n        dim: Dimensionality of the samples.\n        n_steps: Number of steps in the chain.\n        n_samples: Number of parallel chains to run.\n\n    Returns:\n        A tuple containing the final samples and a dictionary of diagnostics.\n    \"\"\"\n    # ... implementation ...\n</code></pre>"},{"location":"developer_guide/code_guidelines/#api-design-principles","title":"API Design Principles","text":"<p>Our API is designed to be intuitive, consistent, and flexible.</p>"},{"location":"developer_guide/code_guidelines/#core-philosophy","title":"Core Philosophy","text":"<ul> <li>Simplicity: Simple use cases should be simple. Advanced functionality should be available but not intrusive.</li> <li>Consistency: Similar operations should have similar interfaces. Parameter names and ordering should be consistent across the library.</li> <li>Explicitness: Configuration should be explicit, primarily through constructor arguments.</li> </ul>"},{"location":"developer_guide/code_guidelines/#key-patterns","title":"Key Patterns","text":"<ul> <li>Base Classes: Core components like models, samplers, and losses inherit from base classes (<code>BaseModel</code>, <code>BaseSampler</code>, <code>BaseLoss</code>) that define a common interface.</li> <li>Composition: Complex functionality is built by composing simpler components.</li> <li>Clear Return Values: Functions return a single value, a tuple for multiple values, or a dictionary for complex outputs with named fields. Diagnostic information is often returned in a separate dictionary.</li> </ul>"},{"location":"developer_guide/code_guidelines/#testing-guidelines","title":"Testing Guidelines","text":"<p>Comprehensive testing is crucial for the reliability of TorchEBM. We use <code>pytest</code> for all tests.</p>"},{"location":"developer_guide/code_guidelines/#testing-philosophy","title":"Testing Philosophy","text":"<ul> <li>Unit Tests: Test individual components in isolation.</li> <li>Integration Tests: Test how components interact.</li> <li>Numerical Tests: Verify the correctness and stability of numerical algorithms.</li> <li>Property-Based Tests: Use libraries like <code>hypothesis</code> to test that functions satisfy certain properties for a wide range of inputs.</li> </ul>"},{"location":"developer_guide/code_guidelines/#writing-tests","title":"Writing Tests","text":"<ul> <li>Test files are located in the <code>tests/</code> directory and mirror the structure of the <code>torchebm/</code> package.</li> <li>Test files must be named <code>test_*.py</code>.</li> <li>Test functions must be named <code>test_*</code>.</li> <li>Use <code>pytest.fixture</code> to create reusable test objects.</li> <li>Use <code>pytest.mark.parametrize</code> to test a function with multiple different inputs.</li> </ul>"},{"location":"developer_guide/code_guidelines/#running-tests","title":"Running Tests","text":"<p>Run all tests from the root of the repository:</p> <pre><code>pytest\n</code></pre> <p>To get a coverage report:</p> <pre><code>pytest --cov=torchebm\n</code></pre> <p>We aim for high test coverage across the library. Pull requests that decrease coverage will not be merged.</p>"},{"location":"developer_guide/getting_started/","title":"Getting Started","text":""},{"location":"developer_guide/getting_started/#getting-started-with-torchebm-development","title":"Getting Started with TorchEBM Development","text":"<p>Welcome to the TorchEBM development community! This guide provides everything you need to set up your environment, understand our workflow, and make your first contribution.</p>"},{"location":"developer_guide/getting_started/#ways-to-contribute","title":"Ways to Contribute","text":"<p>We welcome contributions of all kinds:</p> <ul> <li> <p> Report Bugs</p> <p>Find a bug? Report it on our issue tracker with a clear description and steps to reproduce.</p> </li> <li> <p> Suggest Features</p> <p>Have an idea for a new feature or an improvement? Share it in the discussions.</p> </li> <li> <p> Improve Documentation</p> <p>Help us make our documentation better by fixing typos, clarifying explanations, or adding new examples.</p> </li> <li> <p> Write Code</p> <p>Contribute directly to the codebase by fixing bugs, implementing new features, or improving performance.</p> </li> </ul>"},{"location":"developer_guide/getting_started/#development-setup","title":"Development Setup","text":"<p>Follow these steps to set up your local development environment.</p>"},{"location":"developer_guide/getting_started/#1-prerequisites","title":"1. Prerequisites","text":"<p>Make sure you have the following installed:</p> <ul> <li>Python 3.9+</li> <li>Git</li> <li>A GitHub Account</li> </ul>"},{"location":"developer_guide/getting_started/#2-fork-and-clone","title":"2. Fork and Clone","text":"<p>First, fork the TorchEBM repository on GitHub. Then, clone your fork locally:</p> <pre><code>git clone https://github.com/YOUR-USERNAME/torchebm.git\ncd torchebm\n</code></pre>"},{"location":"developer_guide/getting_started/#3-set-up-virtual-environment","title":"3. Set Up Virtual Environment","text":"<p>It's highly recommended to use a virtual environment:</p> <pre><code># Create a virtual environment\npython -m venv venv\n\n# Activate it (macOS/Linux)\nsource venv/bin/activate\n\n# Or on Windows\nvenv\\Scripts\\activate\n</code></pre>"},{"location":"developer_guide/getting_started/#4-install-dependencies","title":"4. Install Dependencies","text":"<p>Install TorchEBM in editable mode along with all development dependencies:</p> <pre><code>pip install -e \".[dev]\"\n</code></pre>"},{"location":"developer_guide/getting_started/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"developer_guide/getting_started/#1-create-a-branch","title":"1. Create a Branch","text":"<p>Create a new branch for your changes. Use a descriptive name, like <code>feature/new-sampler</code> or <code>fix/gradient-bug</code>.</p> <pre><code>git checkout -b feature/your-feature-name\n</code></pre>"},{"location":"developer_guide/getting_started/#2-make-changes","title":"2. Make Changes","text":"<p>Make your changes to the codebase. Be sure to follow our Code Guidelines.</p>"},{"location":"developer_guide/getting_started/#3-run-tests","title":"3. Run Tests","text":"<p>Before committing, run the tests to ensure your changes haven't broken anything:</p> <pre><code>pytest\n</code></pre>"},{"location":"developer_guide/getting_started/#4-commit-your-changes","title":"4. Commit Your Changes","text":"<p>We follow the Conventional Commits specification. Your commit messages should be structured as follows:</p> <pre><code>&lt;type&gt;: &lt;description&gt;\n\n[optional body]\n\n[optional footer]\n</code></pre> <p>Common types:</p> Type Description feat A new feature fix A bug fix docs Documentation only changes style Changes that do not affect the meaning of the code refactor A code change that neither fixes a bug nor adds a feature perf A code change that improves performance test Adding missing tests or correcting existing tests chore Changes to the build process or auxiliary tools <p>Example:</p> <pre><code>git commit -m \"feat: add support for adaptive step sizes in LangevinDynamics\"\n</code></pre>"},{"location":"developer_guide/getting_started/#5-create-a-pull-request","title":"5. Create a Pull Request","text":"<p>Push your branch to your fork and open a pull request to the <code>main</code> branch of the TorchEBM repository.</p> <pre><code>git push origin feature/your-feature-name\n</code></pre> <p>In your pull request description, clearly explain the changes you've made and reference any relevant issues.</p>"},{"location":"developer_guide/getting_started/#documentation-development","title":"Documentation Development","text":"<p>To work on the documentation locally, install the docs dependencies and serve the site:</p> <pre><code>pip install -e \".[docs]\"\nmkdocs serve\n</code></pre> <p>This will start a live-reloading server at <code>http://127.0.0.1:8000</code>.</p>"},{"location":"developer_guide/performance/","title":"Performance Optimization","text":""},{"location":"developer_guide/performance/#performance-optimization","title":"Performance Optimization","text":"<p>This document provides guidance on optimizing the performance of TorchEBM for both development and usage.</p>"},{"location":"developer_guide/performance/#performance-considerations","title":"Performance Considerations","text":"<p>Key Performance Areas</p> <p>When working with TorchEBM, pay special attention to these performance-critical areas:</p> <ol> <li>Sampling algorithms: These are iterative and typically the most compute-intensive</li> <li>Gradient calculations: Computing energy gradients is fundamental to many algorithms</li> <li>Batch processing: Effective vectorization for parallel processing</li> <li>GPU utilization: Proper device management and memory usage</li> </ol>"},{"location":"developer_guide/performance/#vectorization-techniques","title":"Vectorization Techniques","text":""},{"location":"developer_guide/performance/#batched-operations","title":"Batched Operations","text":"<p>TorchEBM extensively uses batching to improve performance:</p> <pre><code># Instead of looping over samples\nfor i in range(n_samples):\n    energy_i = energy_function(x[i])  # Slow\n\n# Use batched computation\nenergy = energy_function(x)  # Fast\n</code></pre>"},{"location":"developer_guide/performance/#parallel-sampling","title":"Parallel Sampling","text":"<p>Sample multiple chains in parallel by using batch dimensions:</p> <pre><code># Initialize batch of samples\nx = torch.randn(n_samples, dim, device=device)\n\n# One sampling step (all chains update together)\nx_new, _ = sampler.step(x)\n</code></pre>"},{"location":"developer_guide/performance/#gpu-acceleration","title":"GPU Acceleration","text":"<p>TorchEBM is designed to work efficiently on GPUs:</p>"},{"location":"developer_guide/performance/#device-management","title":"Device Management","text":"<pre><code># Create energy function and move to appropriate device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nenergy_fn = GaussianEnergy(mean, cov).to(device)\n\n# Create sampler with the same device\nsampler = LangevinDynamics(energy_fn, device=device)\n\n# Generate samples (automatically on the correct device)\nsamples, _ = sampler.sample(dim=2, n_steps=1000, n_samples=10000)\n</code></pre>"},{"location":"developer_guide/performance/#memory-management","title":"Memory Management","text":"<p>Memory management is critical for performance, especially on GPUs:</p> <pre><code># Avoid creating new tensors in loops\nfor step in range(n_steps):\n    # Bad: Creates new tensors each iteration\n    x = x - step_size * energy_fn.gradient(x) + noise_scale * torch.randn_like(x)\n\n    # Good: In-place operations\n    grad = energy_fn.gradient(x)\n    x.sub_(step_size * grad)\n    x.add_(noise_scale * torch.randn_like(x))\n</code></pre>"},{"location":"developer_guide/performance/#custom-cuda-kernels-to-be-added-see-also-curblas","title":"Custom CUDA Kernels (to be Added--See Also: cuRBLAS)","text":""},{"location":"developer_guide/performance/#sampling-efficiency","title":"Sampling Efficiency","text":"<p>Sampling efficiency can be improved using several techniques:</p> <ul> <li> <p> Step Size Adaptation</p> <p>Automatically adjust step sizes based on acceptance rates or other metrics.</p> <pre><code>if acceptance_rate &lt; 0.3:\n    step_size *= 0.9  # Decrease step size\nelif acceptance_rate &gt; 0.7:\n    step_size *= 1.1  # Increase step size\n</code></pre> </li> <li> <p> Burn-in Period</p> <p>Discard initial samples to reduce the impact of initialization.</p> <pre><code># Run burn-in period\nx = torch.randn(n_samples, dim)\nfor _ in range(burn_in_steps):\n    x, _ = sampler.step(x)\n\n# Start collecting samples\nsamples = []\nfor _ in range(n_steps):\n    x, _ = sampler.step(x)\n    samples.append(x.clone())\n</code></pre> </li> <li> <p> Thinning</p> <p>Reduce correlation between samples by keeping only every Nth sample.</p> <pre><code># Collect samples with thinning\nsamples = []\nfor i in range(n_steps):\n    x, _ = sampler.step(x)\n    if i % thinning == 0:\n        samples.append(x.clone())\n</code></pre> </li> <li> <p> Warm Starting</p> <p>Initialize sampling from a distribution close to the target.</p> <pre><code># Warm start from approximate distribution\nx = approximate_sampler.sample(n_samples, dim)\nsamples = sampler.sample(\n  n_steps=n_steps, \n  initial_samples=x\n)\n</code></pre> </li> </ul>"},{"location":"developer_guide/performance/#profiling-and-benchmarking-planned","title":"Profiling and Benchmarking (Planned)","text":""},{"location":"developer_guide/performance/#performance-benchmarks-planned","title":"Performance Benchmarks (Planned)","text":""},{"location":"developer_guide/performance/#performance-tips-and-best-practices","title":"Performance Tips and Best Practices","text":"<p>Common Pitfalls</p> <p>Avoid these common performance issues:</p> <ol> <li>Unnecessary CPU-GPU transfers: Keep data on the same device</li> <li>Small batch sizes: Too small batches underutilize hardware</li> <li>Unneeded gradient tracking: Disable gradients when not training</li> <li>Excessive logging: Logging every step can significantly slow down sampling</li> </ol>"},{"location":"developer_guide/performance/#general-tips","title":"General Tips","text":"<ol> <li>Use the right device: Always move computation to GPU when available</li> <li>Batch processing: Process data in batches rather than individually</li> <li>Reuse tensors: Avoid creating new tensors in inner loops</li> <li>Monitor memory: Use <code>torch.cuda.memory_summary()</code> to track memory usage</li> </ol>"},{"location":"developer_guide/performance/#sampling-tips","title":"Sampling Tips","text":"<ol> <li>Tune step sizes: Optimal step sizes balance exploration and stability</li> <li>Parallel chains: Use multiple chains to improve sample diversity</li> <li>Adaptive methods: Use adaptive samplers for complex distributions</li> <li>Mixed precision: Consider using mixed precision for larger models</li> </ol>"},{"location":"developer_guide/performance/#algorithm-specific-optimizations","title":"Algorithm-Specific Optimizations","text":""},{"location":"developer_guide/performance/#langevin-dynamics","title":"Langevin Dynamics","text":"<pre><code># Optimize step size for Langevin dynamics\n# Rule of thumb: step_size \u2248 O(d^(-1/3)) where d is dimension\nstep_size = min(0.01, 0.1 * dim**(-1/3))\n\n# Noise scale should be sqrt(2 * step_size) for standard Langevin\nnoise_scale = np.sqrt(2 * step_size)\n</code></pre>"},{"location":"developer_guide/performance/#hamiltonian-monte-carlo","title":"Hamiltonian Monte Carlo","text":"<pre><code># Optimize HMC parameters\n# Leapfrog steps should scale with dimension\nn_leapfrog_steps = max(5, int(np.sqrt(dim)))\n\n# Step size should decrease with dimension\nstep_size = min(0.01, 0.05 * dim**(-1/4))\n</code></pre>"},{"location":"developer_guide/performance/#multi-gpu-scaling-planned","title":"Multi-GPU Scaling (Planned)","text":""},{"location":"developer_guide/performance/#conclusion","title":"Conclusion","text":"<p>Performance optimization in TorchEBM involves careful attention to vectorization, GPU acceleration, memory management, and algorithm-specific tuning. By following these guidelines, you can achieve significant speedups in your energy-based modeling workflows. </p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#torchebm-examples","title":"TorchEBM Examples","text":"<p>This section contains practical examples that demonstrate how to use TorchEBM for energy-based modeling. Each example is fully tested and focuses on a specific use case or feature.</p> <ul> <li> Models and Energy Functions</li> <li> Datasets</li> <li> Samplers</li> <li> Training an EBM</li> <li> Visualization</li> </ul>"},{"location":"examples/#example-structure","title":"Example Structure","text":"<p>Example Format</p> <p>Each example follows a consistent structure to help you understand and apply the concepts:</p> <ol> <li>Overview: Brief explanation of the example and its purpose</li> <li>Code: Complete, runnable code for the example</li> <li>Explanation: Detailed explanation of key concepts and code sections</li> <li>Extensions: Suggestions for extending or modifying the example</li> </ol>"},{"location":"examples/#running-the-examples","title":"Running the Examples","text":"<p>All examples can be run using the examples main.py script:</p> <pre><code># Clone the repository\ngit clone https://github.com/soran-ghaderi/torchebm.git\ncd torchebm\n\n# Set up your environment\npip install -e .\n\n# List all available examples\npython examples/main.py --list\n\n# Run a specific example\npython examples/main.py samplers/langevin/visualization_trajectory\n</code></pre>"},{"location":"examples/#prerequisites","title":"Prerequisites","text":"<p>To run these examples, you'll need:</p> <ul> <li>Python 3.7+</li> <li>PyTorch 1.9+</li> <li>NumPy</li> <li>Matplotlib</li> </ul> <p>If you haven't installed TorchEBM yet, see the Installation guide.</p>"},{"location":"examples/#gpu-acceleration","title":"GPU Acceleration","text":"<p>Most examples support GPU acceleration and will automatically use CUDA if available:</p> <pre><code>import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nenergy_fn = GaussianEnergy(mean, cov).to(device)\n</code></pre>"},{"location":"examples/#whats-next","title":"What's Next?","text":"<p>After exploring these examples, you might want to:</p> <ol> <li>Check out the API Reference for detailed documentation</li> <li>Read the Developer Guide to learn about contributing</li> <li>Look at the roadmap for upcoming features </li> </ol>"},{"location":"examples/datasets/","title":"Working with Datasets","text":""},{"location":"examples/datasets/#working-with-datasets","title":"Working with Datasets","text":"<p>TorchEBM includes a suite of synthetic datasets primarily for 2D distributions, which are invaluable for testing models and algorithms. These are available in the <code>torchebm.datasets</code> module and are implemented as standard PyTorch <code>Dataset</code> classes, making them fully compatible with <code>DataLoader</code>.</p>"},{"location":"examples/datasets/#synthetic-2d-datasets","title":"Synthetic 2D Datasets","text":"<p>These datasets are useful for visualizing how an EBM learns complex, multimodal distributions.</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nfrom torchebm.datasets import (\n    GaussianMixtureDataset, EightGaussiansDataset, TwoMoonsDataset,\n    SwissRollDataset, CircleDataset, CheckerboardDataset,\n    PinwheelDataset, GridDataset\n)\n\ndef plot_datasets(datasets, titles):\n    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n    axes = axes.flatten()\n    for i, (data, title) in enumerate(zip(datasets, titles)):\n        ax = axes[i]\n        ax.scatter(data[:, 0], data[:, 1], s=5, alpha=0.7)\n        ax.set_title(title)\n        ax.grid(True, alpha=0.3)\n        ax.axis('equal')\n    plt.tight_layout()\n    plt.show()\n\nn_samples = 1000\nseed = 42\n\ndatasets_to_plot = [\n    GaussianMixtureDataset(n_samples=n_samples, n_components=8, std=0.07, radius=1.5, seed=seed).get_data(),\n    EightGaussiansDataset(n_samples=n_samples, std=0.05, scale=2.0, seed=seed).get_data(),\n    TwoMoonsDataset(n_samples=n_samples, noise=0.1, seed=seed).get_data(),\n    SwissRollDataset(n_samples=n_samples, noise=0.1, arclength=3.0, seed=seed).get_data(),\n    CircleDataset(n_samples=n_samples, noise=0.05, radius=1.0, seed=seed).get_data(),\n    CheckerboardDataset(n_samples=n_samples, range_limit=4.0, noise=0.05, seed=seed).get_data(),\n    PinwheelDataset(n_samples=n_samples, n_classes=5, noise=0.05, seed=seed).get_data(),\n    GridDataset(n_samples_per_dim=30, range_limit=2.0, noise=0.02, seed=seed).get_data()\n]\ndataset_titles = [\n    \"Gaussian Mixture\", \"Eight Gaussians\", \"Two Moons\", \"Swiss Roll\",\n    \"Circle\", \"Checkerboard\", \"Pinwheel\", \"2D Grid\"\n]\n\nplot_datasets(datasets_to_plot, dataset_titles)\n</code></pre> <ul> <li> <p> Gaussian Mixture</p> <p></p> <p>A mixture of eight distinct Gaussian distributions arranged in a circle.</p> </li> <li> <p> Eight Gaussians</p> <p></p> <p>A classic synthetic dataset with eight Gaussian modes in a circular pattern.</p> </li> <li> <p> Two Moons</p> <p></p> <p>Two interleaving half-circles, a common benchmark for nonlinear distributions.</p> </li> <li> <p> Swiss Roll</p> <p></p> <p>A spiral-shaped manifold, useful for testing manifold learning algorithms.</p> </li> <li> <p> Circle</p> <p></p> <p>Data points distributed on the circumference of a circle.</p> </li> <li> <p> Checkerboard</p> <p></p> <p>A grid-like pattern of clusters, challenging for models to capture.</p> </li> <li> <p> Pinwheel</p> <p></p> <p>A dataset with swirling arms, testing a model's ability to learn rotational structures.</p> </li> <li> <p> 2D Grid</p> <p></p> <p>A uniform grid of points, useful for evaluating coverage and mode detection.</p> </li> </ul>"},{"location":"examples/datasets/#using-with-dataloader","title":"Using with DataLoader","text":"<p>Since these are <code>torch.utils.data.Dataset</code> subclasses, they integrate seamlessly with <code>DataLoader</code> for batching during training.</p> <pre><code>dataset = TwoMoonsDataset(n_samples=2048, noise=0.05)\ndataloader = DataLoader(\n    dataset,\n    batch_size=256,\n    shuffle=True,\n    drop_last=True\n)\n\nfor batch in dataloader:\n    # Each batch is a tensor of shape [256, 2]\n    print(f\"Batch shape: {batch.shape}\")\n    break\n</code></pre>"},{"location":"examples/datasets/#training-example","title":"Training Example","text":"<p>Here\u2019s a brief example of how to use a dataset to train an EBM. This is a condensed version of the full training process covered in the next chapter.</p> <p></p><pre><code>import torch.nn as nn\nimport torch.optim as optim\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.losses import ContrastiveDivergence\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim=2, hidden_dim=128):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = MLPModel().to(device)\n\ndataset = TwoMoonsDataset(n_samples=2048, noise=0.05, device=device)\ndataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n\nsampler = LangevinDynamics(model=model, step_size=0.1, noise_scale=0.1)\nloss_fn = ContrastiveDivergence(model=model, sampler=sampler, n_steps=10)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(5):\n    for data_batch in dataloader:\n        optimizer.zero_grad()\n        loss, _ = loss_fn(data_batch)\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n</code></pre> This example demonstrates the core workflow: creating a dataset, feeding it to a <code>DataLoader</code>, and using the batches to train a model with a sampler and a loss function like <code>ContrastiveDivergence</code>. <p></p>"},{"location":"examples/models/","title":"Models and Energy Functions","text":""},{"location":"examples/models/#models-and-energy-functions","title":"Models and Energy Functions","text":"<p>At the core of any energy-based model (EBM) is the energy function, \\( E_{\\theta}(x) \\), which assigns a scalar energy value to each data point \\( x \\). This function is used to define a probability distribution \\( p_{\\theta}(x) = \\frac{e^{-E_{\\theta}(x)}}{Z(\\theta)} \\), where regions of low energy correspond to high probability.</p> <p>In TorchEBM, all energy functions are implemented as <code>torch.nn.Module</code> subclasses that inherit from the <code>torchebm.core.BaseModel</code> class.</p>"},{"location":"examples/models/#defining-a-custom-model","title":"Defining a Custom Model","text":"<p>You can create a custom energy function by subclassing <code>BaseModel</code> and implementing the <code>forward()</code> method. Here is an example of a simple energy function based on a Multi-Layer Perceptron (MLP).</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import BaseModel\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim: int, hidden_dim: int = 128):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.network(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MLPModel(input_dim=2).to(device)\nprint(model)\n</code></pre>"},{"location":"examples/models/#built-in-analytical-models","title":"Built-in Analytical Models","text":"<p>TorchEBM also provides several pre-built analytical models for common distributions and testing scenarios. These are useful for research and for understanding the behavior of samplers and training algorithms.</p>"},{"location":"examples/models/#gaussianmodel","title":"GaussianModel","text":"<p>This model implements the energy function for a multivariate Gaussian distribution.</p> \\[ E(x) = \\frac{1}{2} (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu) \\] <pre><code>import torch\nfrom torchebm.core import GaussianModel\n\nmean = torch.tensor([0.0, 0.0])\ncovariance = torch.eye(2)\ngaussian_model = GaussianModel(mean, covariance)\n</code></pre>"},{"location":"examples/models/#doublewellmodel","title":"DoubleWellModel","text":"<p>This model creates a double-well potential, which is useful for testing a sampler's ability to cross energy barriers.</p> \\[ E(x) = h \\sum_{i=1}^{n} (x_i^2 - b^2)^2 \\] <pre><code>import torch\nfrom torchebm.core import DoubleWellModel\n\ndouble_well_model = DoubleWellModel(barrier_height=2.0)\n</code></pre>"},{"location":"examples/models/#visualizing-energy-landscapes","title":"Visualizing Energy Landscapes","text":"<p>Understanding the shape of the energy landscape is crucial. Here's how you can visualize the 2D landscape of the <code>DoubleWellModel</code>.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nmodel = DoubleWellModel(barrier_height=2.0)\n\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-2, 2, 100)\nX, Y = np.meshgrid(x, y)\ngrid_points = torch.tensor(np.stack([X.flatten(), Y.flatten()], axis=1), dtype=torch.float32)\n\nwith torch.no_grad():\n    energy_values = model(grid_points).numpy().reshape(X.shape)\n\nplt.figure(figsize=(8, 6))\nplt.contourf(X, Y, energy_values, levels=50, cmap='viridis')\nplt.colorbar(label='Energy')\nplt.title('Energy Landscape of DoubleWellModel')\nplt.xlabel('$x_1$')\nplt.ylabel('$x_2$')\nplt.show()\n</code></pre> <p> </p> The `DoubleWellModel` has two low-energy regions (wells) separated by a high-energy barrier. <p>TorchEBM includes a variety of other analytical models such as <code>RosenbrockModel</code>, <code>AckleyModel</code>, and <code>RastriginModel</code> which are commonly used for benchmarking optimization and sampling algorithms. You can visualize them using the same technique.</p>"},{"location":"examples/samplers/","title":"Sampling from EBMs","text":""},{"location":"examples/samplers/#sampling-from-ebms","title":"Sampling from EBMs","text":"<p>Sampling is a fundamental operation for energy-based models. Since the partition function \\( Z(\\theta) \\) is intractable, we cannot sample from \\( p_{\\theta}(x) \\) directly. Instead, we use iterative Markov Chain Monte Carlo (MCMC) methods to generate samples. These samples are crucial for both training (e.g., with Contrastive Divergence) and inference.</p> <p>TorchEBM provides powerful and efficient MCMC samplers. Let's explore the two primary ones: <code>LangevinDynamics</code> and <code>HamiltonianMonteCarlo</code>.</p>"},{"location":"examples/samplers/#langevin-dynamics","title":"Langevin Dynamics","text":"<p>Langevin Dynamics is a gradient-based MCMC method. It explores the energy landscape by moving samples in the direction of the negative energy gradient (downhill), while adding Gaussian noise to prevent collapsing to a single mode and to ensure the samples eventually represent the true distribution.</p> <p>The update rule is:</p> \\[ x_{t+1} = x_t - \\frac{\\epsilon^2}{2} \\nabla_x E(x_t) + \\epsilon w_t, \\quad w_t \\sim \\mathcal{N}(0, I) \\] <p>where \\( \\epsilon \\) is the step size.</p>"},{"location":"examples/samplers/#basic-example","title":"Basic Example","text":"<p>Here's how to sample from a <code>GaussianModel</code> using <code>LangevinDynamics</code>.</p> <pre><code>import torch\nimport matplotlib.pyplot as plt\nfrom torchebm.core import GaussianModel\nfrom torchebm.samplers import LangevinDynamics\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmean = torch.tensor([1.0, -1.0])\ncov = torch.tensor([[1.0, 0.5], [0.5, 2.0]])\nmodel = GaussianModel(mean, cov).to(device)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    noise_scale=0.1,\n)\n\ninitial_particles = torch.randn(1000, 2, device=device)\nsamples = sampler.sample(x=initial_particles, n_steps=100)\n\nplt.figure(figsize=(6, 6))\nplt.scatter(samples[:, 0].cpu().numpy(), samples[:, 1].cpu().numpy(), alpha=0.5, s=10)\nplt.title(\"Samples from GaussianModel via Langevin Dynamics\")\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre> <p> </p> Samples generated from a Gaussian distribution using Langevin Dynamics."},{"location":"examples/samplers/#visualizing-sampler-trajectories","title":"Visualizing Sampler Trajectories","text":"<p>To understand how a sampler explores the energy landscape, it's useful to visualize its trajectory. Let's use a more complex, multimodal energy function to see how <code>LangevinDynamics</code> navigates it.</p> <pre><code>import numpy as np\nimport torch.nn as nn\nfrom torchebm.core import BaseModel\n\nclass MultimodalModel(BaseModel):\n    def __init__(self):\n        super().__init__()\n        self.centers = nn.Parameter(torch.tensor([\n            [-1.5, -1.5], [1.5, 1.5], [-1.5, 1.5], [1.5, -1.5]\n        ]), requires_grad=False)\n        self.weights = nn.Parameter(torch.tensor([1.0, 1.0, 0.8, 0.8]), requires_grad=False)\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        dists = torch.cdist(x, self.centers)\n        energy = -torch.logsumexp(-0.5 * dists.pow(2) * self.weights, dim=-1)\n        return energy\n\nmodel = MultimodalModel().to(device)\nsampler = LangevinDynamics(model=model, step_size=0.1, noise_scale=0.1)\n\ninitial_particles = torch.zeros(5, 2, device=device) # 5 chains\ntrajectory = sampler.sample(x=initial_particles, n_steps=200, return_trajectory=True)\n\n#  The plotting code (omitted for brevity, see full example for details)\n# This would involve creating a contour plot of the energy landscape\n# and overlaying the trajectories.\n</code></pre> <p> </p>      Five Langevin Dynamics chains exploring a multimodal energy landscape. The chains (colored lines) start at the center and are drawn towards the low-energy regions (modes).    <p>This visualization reveals that while Langevin Dynamics finds low-energy regions, chains can sometimes get \"stuck\" in local minima, highlighting a common challenge in MCMC sampling.</p>"},{"location":"examples/samplers/#hamiltonian-monte-carlo-hmc","title":"Hamiltonian Monte Carlo (HMC)","text":"<p>Hamiltonian Monte Carlo is a more advanced MCMC method that uses Hamiltonian dynamics from physics to propose more effective moves. By introducing an auxiliary momentum variable, HMC can make large moves that still have a high probability of being accepted, making it more efficient for exploring complex, high-dimensional distributions compared to the more random-walk nature of Langevin Dynamics.</p>"},{"location":"examples/samplers/#basic-example_1","title":"Basic Example","text":"<p>Sampling from our <code>GaussianModel</code> with HMC is just as easy.</p> <pre><code>import torch\nfrom torchebm.core import GaussianModel\nfrom torchebm.samplers import HamiltonianMonteCarlo\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmean = torch.tensor([1.0, -1.0])\ncov = torch.tensor([[1.0, 0.5], [0.5, 2.0]])\nmodel = GaussianModel(mean, cov).to(device)\n\nhmc_sampler = HamiltonianMonteCarlo(\n    model=model,\n    step_size=0.1,\n    n_leapfrog_steps=10\n)\n\ninitial_particles = torch.randn(1000, 2, device=device)\nsamples = hmc_sampler.sample(x=initial_particles, n_steps=25) # HMC often needs fewer steps\n\n# Plotting is the same as before\n</code></pre> <p> </p> Samples generated from a Gaussian distribution using Hamiltonian Monte Carlo."},{"location":"examples/samplers/#key-hmc-parameters","title":"Key HMC Parameters","text":"<p>HMC has two main tuning parameters: -   <code>step_size</code>: The step size for the leapfrog integrator that simulates the dynamics. -   <code>n_leapfrog_steps</code>: The number of leapfrog steps to take for each proposal. The total trajectory time is <code>step_size * n_leapfrog_steps</code>.</p> <p>Tuning these is key to HMC's performance. A good heuristic is to aim for an acceptance rate of around 60-90%, which can be monitored via the diagnostics returned by the sampler.</p>"},{"location":"examples/samplers/#sampler-diagnostics","title":"Sampler Diagnostics","text":"<p>Both samplers can return diagnostic information. For HMC, this includes the acceptance rate of the Metropolis-Hastings correction step, which is a crucial indicator of sampler performance.</p> <p></p><pre><code># To get diagnostics, set return_diagnostics=True\nsamples, diagnostics = hmc_sampler.sample(\n    x=initial_particles,\n    n_steps=25,\n    return_diagnostics=True\n)\n\n# Acceptance rate is in the last dimension of the diagnostics tensor\nacceptance_rate = diagnostics['acceptance_rate'].mean()\nprint(f\"Average acceptance rate: {acceptance_rate:.2f}\")\n</code></pre> An acceptance rate that is too high (e.g., &gt;95%) suggests the <code>step_size</code> might be too small, leading to inefficient exploration. A rate that is too low (e.g., &lt;50%) indicates the <code>step_size</code> is too large, causing proposals to be rejected too often. <p></p>"},{"location":"examples/training/","title":"Training an EBM","text":""},{"location":"examples/training/#training-an-energy-based-model","title":"Training an Energy-Based Model","text":"<p>This guide walks through the complete process of training an energy-based model using TorchEBM. We will train a simple MLP-based model to learn a 2D Gaussian mixture distribution, a classic \"hello world\" for EBMs that is easy to visualize.</p>"},{"location":"examples/training/#the-core-idea-contrastive-divergence","title":"The Core Idea: Contrastive Divergence","text":"<p>Training an EBM involves minimizing the KL divergence between the data distribution \\( p_{data}(x) \\) and the model distribution \\( p_{\\theta}(x) \\). The gradient of the log-likelihood is:</p> \\[ \\nabla_{\\theta} \\log p_{\\theta}(x) = \\mathbb{E}_{x \\sim p_{data}} [-\\nabla_{\\theta} E_{\\theta}(x)] - \\mathbb{E}_{x \\sim p_{\\theta}} [-\\nabla_{\\theta} E_{\\theta}(x)] \\] <p>The first term pushes the energy down for real data (\"positive samples\"), and the second term pushes the energy up for data generated by the model (\"negative samples\").</p> <p>Since we cannot sample directly from \\( p_{\\theta} \\), we use an MCMC procedure like Langevin Dynamics to generate the negative samples. Contrastive Divergence (CD) is an algorithm that approximates this gradient by running the MCMC chain for only a few steps, initialized from the real data.</p>"},{"location":"examples/training/#step-1-set-up-environment","title":"Step 1: Set Up Environment","text":"<p>First, we import the necessary components from PyTorch and TorchEBM.</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.losses import ContrastiveDivergence\nfrom torchebm.datasets import GaussianMixtureDataset\n</code></pre>"},{"location":"examples/training/#step-2-define-the-model-and-dataset","title":"Step 2: Define the Model and Dataset","text":"<p>We'll use a simple MLP as our energy model and a <code>GaussianMixtureDataset</code> as our target distribution.</p> <pre><code># Define the energy model using a simple MLP\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim: int, hidden_dim: int = 128):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, 1),\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.network(x).squeeze(-1)\n\n# Set up device and dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndataset = GaussianMixtureDataset(\n    n_samples=2048,\n    n_components=8,\n    std=0.1,\n    radius=1.5,\n    device=device,\n    seed=42,\n)\ndataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n</code></pre>"},{"location":"examples/training/#step-3-initialize-training-components","title":"Step 3: Initialize Training Components","text":"<p>Next, we initialize the model, the sampler for generating negative samples, the <code>ContrastiveDivergence</code> loss function, and the optimizer.</p> <pre><code># Model\nmodel = MLPModel(input_dim=2).to(device)\n\n# Sampler\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    noise_scale=0.1,\n)\n\n# Loss Function\nloss_fn = ContrastiveDivergence(\n    model=model, \n    sampler=sampler, \n    n_steps=10 # k in CD-k\n)\n\n# Optimizer\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n</code></pre>"},{"location":"examples/training/#step-4-the-training-loop","title":"Step 4: The Training Loop","text":"<p>The training loop is a standard PyTorch loop. In each step, we pass a batch of real data to the <code>loss_fn</code>, which performs the following steps internally: 1.  Calculates the energy of the real data (<code>positive phase</code>). 2.  Initializes MCMC chains from the real data batch. 3.  Runs the <code>sampler</code> for <code>n_steps</code> to generate negative samples. 4.  Calculates the energy of the negative samples (<code>negative phase</code>). 5.  Computes the CD loss and returns it.</p> <pre><code>print(\"Starting training...\")\nfor epoch in range(100):\n    for data_batch in dataloader:\n        optimizer.zero_grad()\n        loss, negative_samples = loss_fn(data_batch)\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch [{epoch+1}/100], Loss: {loss.item():.4f}\")\n</code></pre>"},{"location":"examples/training/#step-5-visualizing-the-results","title":"Step 5: Visualizing the Results","text":"<p>Throughout training, it's crucial to visualize the learned energy landscape and the samples generated by the model. This helps diagnose issues and understand how the model is learning.</p> <pre><code># Helper function to plot energy landscape and samples\n@torch.no_grad()\ndef visualize_training(model, real_data, sampler, epoch):\n    plt.figure(figsize=(8, 8))\n\n    # Create a grid to plot the energy landscape\n    plot_range = 2.5\n    grid_size = 100\n    x_coords = torch.linspace(-plot_range, plot_range, grid_size, device=device)\n    y_coords = torch.linspace(-plot_range, plot_range, grid_size, device=device)\n    xv, yv = torch.meshgrid(x_coords, y_coords, indexing=\"xy\")\n    grid = torch.stack([xv.flatten(), yv.flatten()], dim=1)\n\n    # Get energy values and convert to a probability density for visualization\n    energy_values = model(grid).cpu().numpy().reshape(grid_size, grid_size)\n    prob_density = np.exp(-energy_values)\n\n    # Plot the landscape\n    plt.contourf(xv.cpu().numpy(), yv.cpu().numpy(), prob_density, levels=50, cmap=\"viridis\")\n\n    # Generate model samples for visualization\n    initial_noise = torch.randn(500, 2, device=device)\n    model_samples = sampler.sample(x=initial_noise, n_steps=200).cpu().numpy()\n\n    # Plot real and model samples\n    plt.scatter(real_data[:, 0], real_data[:, 1], s=10, alpha=0.5, label=\"Real Data\", c=\"white\")\n    plt.scatter(model_samples[:, 0], model_samples[:, 1], s=10, alpha=0.5, label=\"Model Samples\", c=\"red\")\n\n    plt.title(f\"Epoch {epoch}\")\n    plt.legend()\n    plt.show()\n\n# Visualize after training\nmodel.eval()\nvisualize_training(model, dataset.get_data().cpu().numpy(), sampler, 100)\n</code></pre> <p>The visualization on the left shows the model early in training, where the energy landscape is still diffuse. On the right, after 100 epochs, the model has learned to assign low energy (high probability, bright regions) to the areas where the data lives, and the model samples (red dots) closely match the real data distribution (white dots).</p>"},{"location":"examples/visualization/","title":"Visualization","text":""},{"location":"examples/visualization/#visualization-in-torchebm","title":"Visualization in TorchEBM","text":"<p>Visualizing the behavior of energy-based models is essential for understanding and debugging them. This guide covers key visualization techniques for EBMs, focusing on energy landscapes and sampler trajectories.</p>"},{"location":"examples/visualization/#visualizing-2d-energy-landscapes","title":"Visualizing 2D Energy Landscapes","text":"<p>For models that operate on 2D data, we can directly visualize the energy function as a surface or contour plot. This shows us where the model has learned to assign low energy (high probability).</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import DoubleWellModel\n\nmodel = DoubleWellModel(barrier_height=2.0)\n\nx = np.linspace(-2, 2, 100)\ny = np.linspace(-2, 2, 100)\nX, Y = np.meshgrid(x, y)\ngrid_points = torch.tensor(np.stack([X.flatten(), Y.flatten()], axis=1), dtype=torch.float32)\n\nwith torch.no_grad():\n    energy_values = model(grid_points).numpy().reshape(X.shape)\n\nplt.figure(figsize=(8, 6))\nplt.contourf(X, Y, energy_values, levels=50, cmap='viridis')\nplt.colorbar(label='Energy')\nplt.title('Energy Landscape of a Double Well Model')\nplt.show()\n</code></pre> <p> </p> A 2D contour plot of the `DoubleWellModel` energy landscape."},{"location":"examples/visualization/#visualizing-sampling-trajectories","title":"Visualizing Sampling Trajectories","text":"<p>To understand how samplers explore the state space, we can plot their trajectories on top of the energy landscape. This is particularly insightful for complex, multimodal distributions.</p> <pre><code>from torchebm.samplers import LangevinDynamics\nfrom torchebm.core import MultimodalModel # A custom model with 4 modes\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MultimodalModel().to(device)\nsampler = LangevinDynamics(model=model, step_size=0.1)\n\ninitial_particles = torch.zeros(5, 2, device=device) # 5 chains starting at the origin\ntrajectory = sampler.sample(x=initial_particles, n_steps=200, return_trajectory=True)\n\n# Plotting (on top of the energy landscape from the previous example)\n# (Contour plot code omitted for brevity)\ncolors = plt.cm.viridis(np.linspace(0, 1, 5))\nfor i in range(5):\n    traj_chain = trajectory[i].cpu().numpy()\n    plt.plot(traj_chain[:, 0], traj_chain[:, 1], color=colors[i], alpha=0.7)\n    plt.scatter(traj_chain[0, 0], traj_chain[0, 1], color='red', s=50, zorder=3) # Start\n    plt.scatter(traj_chain[-1, 0], traj_chain[-1, 1], color='blue', s=50, zorder=3) # End\nplt.show()\n</code></pre> <p> </p> Trajectories of five Langevin Dynamics chains exploring a multimodal landscape."},{"location":"examples/visualization/#comparing-ground-truth-and-model-samples","title":"Comparing Ground Truth and Model Samples","text":"<p>A critical evaluation is to compare the distribution of samples from the trained model against the real data distribution.</p> <p></p><pre><code># Assume `model_samples` are generated from a trained model\n# Assume `real_samples` are from the dataset\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n\nax1.set_title(\"Real Data Distribution\")\nax1.scatter(real_samples[:, 0], real_samples[:, 1], s=10, alpha=0.5)\n\nax2.set_title(\"Model Sample Distribution\")\nax2.scatter(model_samples[:, 0], model_samples[:, 1], s=10, alpha=0.5, c='red')\n\nplt.show()\n</code></pre> This side-by-side comparison provides a quick qualitative assessment of how well the model has learned the target distribution. For more quantitative measures, you can use metrics like Maximum Mean Discrepancy (MMD) or analyze summary statistics.<p></p>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#getting-started-with-torchebm","title":"Getting Started with TorchEBM","text":"<p>Welcome to the TorchEBM tutorials section! These comprehensive tutorials will help you understand how to use TorchEBM effectively for your energy-based modeling tasks.</p>"},{"location":"tutorials/#core-concepts","title":"Core Concepts","text":"<ul> <li> Energy Models</li> <li> Samplers</li> <li> Loss Functions</li> <li> Training</li> <li> Visualization</li> </ul>"},{"location":"tutorials/#quick-start","title":"Quick Start","text":"<p>If you're new to energy-based models, we recommend the following learning path:</p> <ol> <li>Follow the Installation/Introduction guide to set up TorchEBM and understand basic concepts</li> <li>Read the Energy Models API to understand model implementations</li> <li>Explore the Samplers guide to learn how to generate samples</li> <li>Study the Training guide to learn how to train your models</li> </ol>"},{"location":"tutorials/#basic-example","title":"Basic Example","text":"<p>Here's a simple example to get you started with TorchEBM:</p> <pre><code>import torch\nfrom torchebm.core import GaussianModel\nfrom torchebm.samplers.langevin_dynamics import LangevinDynamics\n\n# Create an energy model (2D Gaussian)\nenergy_fn = GaussianModel(\n    mean=torch.zeros(2),\n    cov=torch.eye(2)\n)\n\n# Create a sampler\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.01\n)\n\n# Generate samples\nsamples = sampler.sample(\n    dim=2, n_steps=100, n_samples=1000\n)\n\n# Print sample statistics\nprint(f\"Sample mean: {samples.mean(0)}\")\nprint(f\"Sample std: {samples.std(0)}\")\n</code></pre>"},{"location":"tutorials/#common-patterns","title":"Common Patterns","text":"<p>Here are some common patterns you'll encounter throughout the guides:</p>"},{"location":"tutorials/#energy-model-definition","title":"Energy Model Definition","text":"<pre><code>from torchebm.core import BaseModel\nimport torch\n\n\nclass MyEnergyModel(BaseModel):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return torch.sum(x ** 2, dim=-1)\n</code></pre>"},{"location":"tutorials/#sampler-usage","title":"Sampler Usage","text":"<pre><code>from torchebm.samplers.langevin_dynamics import LangevinDynamics\n\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.01\n)\n\nsamples = sampler.sample(\n    dim=2, n_steps=100, n_samples=1000\n)\n</code></pre>"},{"location":"tutorials/#next-steps","title":"Next Steps","text":"<p>Once you're familiar with the basics, you can:</p> <ul> <li>Explore detailed Examples that demonstrate TorchEBM in action</li> <li>Check the API Reference for comprehensive documentation</li> <li>Learn how to contribute to TorchEBM in the Developer Guide</li> </ul> <p>Remember that all examples in these guides are tested with the latest version of TorchEBM, and you can run them in your own environment to gain hands-on experience. </p>"},{"location":"tutorials/custom_neural_networks/","title":"Custom Neural Networks","text":""},{"location":"tutorials/custom_neural_networks/#custom-neural-network-models","title":"Custom Neural Network Models","text":"<p>Energy-based models (EBMs) are highly flexible, and one of their key advantages is that the model can be parameterized using neural networks. This guide explains how to create and use neural network-based models in TorchEBM.</p>"},{"location":"tutorials/custom_neural_networks/#overview","title":"Overview","text":"<p>Neural networks provide a powerful way to represent complex energy landscapes that can't be easily defined analytically. By using neural networks as models:</p> <ul> <li>You can capture complex, high-dimensional distributions</li> <li>The model can be learned from data</li> <li>You gain the expressivity of modern deep learning architectures</li> </ul>"},{"location":"tutorials/custom_neural_networks/#basic-neural-network-model","title":"Basic Neural Network Model","text":"<p>To create a neural network-based model in TorchEBM, you need to subclass the <code>BaseModel</code> base class and implement the <code>forward</code> method:</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import BaseModel\n\n\nclass NeuralNetModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=128):\n        super().__init__()\n\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#design-considerations","title":"Design Considerations","text":"<p>When designing neural network models, consider the following:</p>"},{"location":"tutorials/custom_neural_networks/#network-architecture","title":"Network Architecture","text":"<p>The choice of architecture depends on the data type and complexity:</p> <ul> <li>MLPs: Good for generic, low-dimensional data</li> <li>CNNs: Effective for images and data with spatial structure</li> <li>Transformers: Useful for sequential data or when attention mechanisms are beneficial</li> <li>Graph Neural Networks: For data with graph structure</li> </ul>"},{"location":"tutorials/custom_neural_networks/#output-requirements","title":"Output Requirements","text":"<p>Remember the following key points:</p> <ol> <li>The model should output a scalar value for each sample in the batch</li> <li>Lower energy values should correspond to higher probability density</li> <li>The neural network must be differentiable for gradient-based sampling methods to work</li> </ol>"},{"location":"tutorials/custom_neural_networks/#scale-and-normalization","title":"Scale and Normalization","text":"<p>Energy values should be properly scaled to avoid numerical issues:</p> <ul> <li>Very large energy values can cause instability in sampling</li> <li>Models that grow too quickly may cause sampling algorithms to fail</li> </ul>"},{"location":"tutorials/custom_neural_networks/#example-mlp-model-for-2d-data","title":"Example: MLP Model for 2D Data","text":"<p>Here's a complete example with a simple MLP model:</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import (\n    BaseModel,\n    CosineScheduler,\n)\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.losses import ContrastiveDivergence\nfrom torchebm.datasets import GaussianMixtureDataset\nfrom torch.utils.data import DataLoader\n\nSEED = 42\ntorch.manual_seed(SEED)\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim=2, hidden_dim=64):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1),\n        )\n\n    def forward(self, x):\n        return self.model(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndataset = GaussianMixtureDataset(\n    n_samples=1000,\n    n_components=5,\n    std=0.1,\n    radius=1.5,\n    device=device,\n    seed=SEED,\n)\n\ndataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n\nmodel = MLPModel(input_dim=2, hidden_dim=64).to(device)\nSAMPLER_NOISE_SCALE = CosineScheduler(\n    initial_value=2e-1, final_value=1e-2, total_steps=50\n)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.01,\n    device=device,\n    noise_scale=SAMPLER_NOISE_SCALE,\n)\n\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=10,\n    persistent=False,\n    device=device,\n)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nn_epochs = 200\nfor epoch in range(n_epochs):\n    epoch_loss = 0.0\n\n    for batch in dataloader:\n        optimizer.zero_grad()\n\n        loss, neg_samples = loss_fn(batch)\n\n        loss.backward()\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {epoch_loss / len(dataloader):.4f}\")\n\ndef generate_samples(model, n_samples=500):\n    sampler = LangevinDynamics(model=model, step_size=0.005, device=device)\n\n    initial_samples = torch.randn(n_samples, 2).to(device)\n\n    with torch.no_grad():\n        samples = sampler.sample(\n            initial_state=initial_samples,\n            dim=initial_samples.shape[-1],\n            n_samples=n_samples,\n            n_steps=1000,\n        )\n\n    return samples.cpu()\n\nsamples = generate_samples(model)\nprint(f\"Generated {len(samples)} samples from the energy-based model\")\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#example-convolutional-model-for-images","title":"Example: Convolutional Model for Images","text":"<p>For image data, convolutional architectures are more appropriate:</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import BaseModel\n\n\nclass ConvolutionalModel(BaseModel):\n    def __init__(self, channels=1, width=28, height=28):\n        super().__init__()\n\n        self.conv_net = nn.Sequential(\n            nn.Conv2d(channels, 32, kernel_size=3, stride=1, padding=1),\n            nn.SELU(),\n            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n            nn.SELU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.SELU(),\n            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n            nn.SELU(),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.SELU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n            nn.SELU(),\n        )\n\n        feature_size = 128 * (width // 8) * (height // 8)\n\n        self.energy_head = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(feature_size, 128),\n            nn.SELU(),\n            nn.Linear(128, 1)\n        )\n\n    def forward(self, x):\n        if x.ndim == 3:\n            x = x.unsqueeze(0)\n        elif x.ndim == 2:\n            x = x.unsqueeze(0).unsqueeze(0)\n\n        features = self.conv_net(x)\n        energy = self.energy_head(features).squeeze(-1)\n\n        return energy\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#advanced-pattern-composed-models","title":"Advanced Pattern: Composed Models","text":"<p>You can combine multiple analytical models with multiple neural networks for best of both worlds:</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import BaseModel, GaussianModel\n\n\nclass CompositionalModel(BaseModel):\n    def __init__(self, input_dim=2, hidden_dim=64):\n        super().__init__()\n\n        self.analytical_component = GaussianModel(\n            mean=torch.zeros(input_dim),\n            cov=torch.eye(input_dim)\n        )\n\n        self.neural_component = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n        self.alpha = nn.Parameter(torch.tensor(0.5))\n\n    def forward(self, x):\n        analytical_energy = self.analytical_component(x)\n\n        neural_energy = self.neural_component(x).squeeze(-1)\n\n        alpha = torch.sigmoid(self.alpha)\n        combined_energy = alpha * analytical_energy + (1 - alpha) * neural_energy\n\n        return combined_energy\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#training-strategies","title":"Training Strategies","text":"<p>Training neural network models requires special techniques:</p>"},{"location":"tutorials/custom_neural_networks/#contrastive-divergence","title":"Contrastive Divergence","text":"<p>A common approach is contrastive divergence, which minimizes the energy of data samples while maximizing the energy of samples from the model:</p> <pre><code>loss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=10,  # Number of MCMC steps\n    persistent=False,  # Set to True for Persistent Contrastive Divergence\n    device=device,\n)\n\ndef train_step_contrastive_divergence(data_batch):\n    optimizer.zero_grad()\n\n    loss, neg_samples = loss_fn(data_batch)\n\n    loss.backward()\n\n    optimizer.step()\n\n    return loss.item()\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#score-matching","title":"Score Matching","text":"<p>Score matching is another approach that avoids the need for MCMC sampling:</p> <pre><code>sm_loss_fn = ScoreMatching(\n    model=model,\n    hessian_method=\"hutchinson\",\n    hutchinson_samples=5,\n    device=device,\n)\n\nbatch_loss = train_step_contrastive_divergence(data_batch)\n</code></pre>"},{"location":"tutorials/custom_neural_networks/#tips-for-neural-network-models","title":"Tips for Neural Network Models","text":"<ol> <li>Start Simple: Begin with a simple architecture and gradually increase complexity</li> <li>Regularization: Use weight decay or spectral normalization to prevent extreme energy values</li> <li>Gradient Clipping: Apply gradient clipping during training to prevent instability</li> <li>Initialization: Careful initialization of weights can help convergence</li> <li>Monitoring: Track energy values during training to ensure they stay in a reasonable range</li> <li>Batch Normalization: Use with caution as it can affect the shape of the energy landscape</li> <li>Residual Connections: Can help with gradient flow in deeper networks</li> </ol>"},{"location":"tutorials/custom_neural_networks/#conclusion","title":"Conclusion","text":"<p>Neural network models provide a powerful way to model complex distributions in energy-based models. By leveraging the flexibility of deep learning architectures, you can create expressive models that capture intricate patterns in your data.</p> <p>Remember to carefully design your architecture, choose appropriate training methods, and monitor the behavior of your model during training and sampling. </p>"},{"location":"tutorials/getting_started/","title":"Getting Started","text":""},{"location":"tutorials/getting_started/#getting-started-with-torchebm","title":"Getting Started with TorchEBM","text":"<p>This guide provides a hands-on introduction to TorchEBM. You'll learn how to install the library, understand its core components, and train your first Energy-Based Model (EBM) on a synthetic dataset.</p>"},{"location":"tutorials/getting_started/#1-installation","title":"1. Installation","text":"<p>TorchEBM can be installed from PyPI. Ensure you have PyTorch installed first.</p> <pre><code>pip install torchebm\n</code></pre> <p>Prerequisites</p> <ul> <li>Python 3.8+</li> <li>PyTorch 1.10.0+</li> <li>CUDA is optional but highly recommended for performance.</li> </ul>"},{"location":"tutorials/getting_started/#2-the-core-concepts","title":"2. The Core Concepts","text":"<p>An Energy-Based Model defines a probability distribution over data \\(x\\) through an energy function \\(E(x)\\). The probability is defined as \\(p(x) = \\frac{e^{-E(x)}}{Z}\\), where lower energy corresponds to higher probability.</p> <p>TorchEBM is built around two key components:</p> <ol> <li>Energy Functions: These are learnable functions (often neural networks) that map input data to a scalar energy value.</li> <li>Samplers: These are algorithms, typically based on Markov Chain Monte Carlo (MCMC), used to draw samples from the probability distribution defined by the energy function.</li> </ol> <p>Let's explore these concepts with code.</p>"},{"location":"tutorials/getting_started/#concept-1-the-energy-function","title":"Concept 1: The Energy Function","text":"<p>An energy function is a <code>torch.nn.Module</code> that takes a tensor <code>x</code> of shape <code>(batch_size, *dims)</code> and returns a tensor of energy values of shape <code>(batch_size,)</code>.</p> <p>TorchEBM provides several pre-built energy functions for testing and experimentation. Here's how to use the <code>GaussianEnergy</code> function, which models a multivariate normal distribution.</p> <pre><code>import torch\nfrom torchebm.core import GaussianEnergy\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nenergy_fn = GaussianEnergy(\n    mean=torch.zeros(2, device=device),\n    cov=torch.eye(2, device=device)\n).to(device)\n\nx = torch.tensor([[0.0, 0.0], [1.0, 1.0], [2.0, 2.0]], device=device)\n\nenergy = energy_fn(x)\n\nprint(f\"Input shape: {x.shape}\")\nprint(f\"Energy shape: {energy.shape}\")\nprint(f\"Energies:\\n{energy}\")\n</code></pre> <p>The point <code>[0.0, 0.0]</code> is the mean of the distribution and thus has the lowest energy. As points move away from the mean, their energy increases.</p>"},{"location":"tutorials/getting_started/#concept-2-the-sampler","title":"Concept 2: The Sampler","text":"<p>Samplers generate data points from the distribution defined by an energy function. They typically work by starting from random initial points and iteratively refining them to have lower energy (higher probability).</p> <p>Let's use the <code>LangevinDynamics</code> sampler to draw samples from our <code>GaussianEnergy</code> distribution.</p> <pre><code>from torchebm.samplers import LangevinDynamics\n\nsampler = LangevinDynamics(\n    energy_function=energy_fn,\n    step_size=0.1,\n    noise_scale=1.0\n).to(device)\n\nsamples = sampler.sample(\n    dim=2,\n    n_samples=1000,\n    n_steps=100\n)\n\nprint(f\"Generated samples shape: {samples.shape}\")\n</code></pre> <p>You have now sampled from your first energy-based model! These samples approximate a 2D Gaussian distribution.</p>"},{"location":"tutorials/getting_started/#3-training-your-first-ebm","title":"3. Training Your First EBM","text":"<p>Now let's put everything together and train an EBM with a neural network as the energy function. The goal is to train the model to represent a synthetic \"two moons\" dataset.</p>"},{"location":"tutorials/getting_started/#step-1-create-a-dataset","title":"Step 1: Create a Dataset","text":"<p>First, we'll generate a <code>TwoMoonsDataset</code> and create a <code>DataLoader</code> to iterate through it in batches.</p> <pre><code>import torch\nfrom torch.utils.data import DataLoader\nfrom torchebm.datasets import TwoMoonsDataset\n\ndataset = TwoMoonsDataset(n_samples=5000)\n\ndataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n</code></pre>"},{"location":"tutorials/getting_started/#step-2-define-a-neural-energy-function","title":"Step 2: Define a Neural Energy Function","text":"<p>Next, we'll create a simple Multi-Layer Perceptron (MLP) to serve as our energy function. This network will take 2D points as input and output a single energy value for each.</p> <pre><code>import torch.nn as nn\nfrom torchebm.core import BaseEnergyFunction\n\nclass NeuralEnergy(BaseEnergyFunction):\n    def __init__(self, input_dim=2, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\nneural_energy_fn = NeuralEnergy().to(device)\n</code></pre>"},{"location":"tutorials/getting_started/#step-3-set-up-the-training-components","title":"Step 3: Set up the Training Components","text":"<p>To train the EBM, we need three things:</p> <ol> <li>A Loss Function: We'll use <code>ContrastiveDivergence</code>, a standard loss function for EBMs. It works by pushing down the energy of real data (\"positive\" samples) and pushing up the energy of generated data (\"negative\" samples).</li> <li>A Sampler: The loss function needs a sampler to generate the negative samples. We'll use <code>LangevinDynamics</code> again.</li> <li>An Optimizer: A standard PyTorch optimizer like <code>Adam</code>.</li> </ol> <pre><code>from torchebm.losses import ContrastiveDivergence\nfrom torchebm.samplers import LangevinDynamics\nfrom torch.optim import Adam\n\nsampler = LangevinDynamics(\n    energy_function=neural_energy_fn,\n    step_size=10.0,\n    noise_scale=0.1,\n    n_steps=60\n)\n\ncd_loss = ContrastiveDivergence(sampler=sampler)\n\noptimizer = Adam(neural_energy_fn.parameters(), lr=1e-4)\n</code></pre>"},{"location":"tutorials/getting_started/#step-4-the-training-loop","title":"Step 4: The Training Loop","text":"<p>Now we'll write a standard PyTorch training loop. For each batch of real data, we calculate the contrastive divergence loss and update the model's weights.</p> <p></p><pre><code>for epoch in range(100):\n    for batch_data in dataloader:\n        real_samples = batch_data.to(device)\n\n        optimizer.zero_grad()\n\n        loss = cd_loss(real_samples, neural_energy_fn)\n\n        loss.backward()\n        optimizer.step()\n\n    if (epoch + 1) % 10 == 0:\n        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n\nprint(\"Training finished!\")\n</code></pre> This loop adjusts the weights of our neural network so that its energy landscape matches the \"two moons\" data distribution.<p></p>"},{"location":"tutorials/getting_started/#next-steps","title":"Next Steps","text":"<p>Congratulations on training your first Energy-Based Model with TorchEBM!</p> <ul> <li>Learn more about the different Samplers available.</li> <li>Explore other Loss Functions for training EBMs.</li> <li>See how to create Custom Neural Networks for more complex energy functions.</li> <li>Check out the Visualization guide to see how you can plot your energy landscapes and samples.</li> </ul>"},{"location":"tutorials/loss_functions/","title":"Loss Functions","text":""},{"location":"tutorials/loss_functions/#loss-functions","title":"Loss Functions","text":"<p>Training energy-based models involves estimating and minimizing the difference between the model distribution and the data distribution. TorchEBM provides various loss functions to accomplish this.</p>"},{"location":"tutorials/loss_functions/#contrastive-divergence","title":"Contrastive Divergence","text":"<p>Contrastive Divergence (CD) is one of the most popular methods for training energy-based models. It uses MCMC sampling to generate negative examples from the current model.</p>"},{"location":"tutorials/loss_functions/#basic-usage","title":"Basic Usage","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchebm.core import BaseModel\nfrom torchebm.losses import ContrastiveDivergence\nfrom torchebm.samplers import LangevinDynamics\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MLPModel(input_dim=2, hidden_dim=64).to(device)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    device=device\n)\n\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=10\n)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndata_batch = torch.randn(128, 2).to(device)\noptimizer.zero_grad()\nloss, negative_samples = loss_fn(data_batch)\nloss.backward()\noptimizer.step()\n</code></pre>"},{"location":"tutorials/loss_functions/#advanced-options","title":"Advanced Options","text":"<p>The <code>ContrastiveDivergence</code> loss function in TorchEBM supports several advanced options:</p>"},{"location":"tutorials/loss_functions/#persistent-contrastive-divergence-pcd","title":"Persistent Contrastive Divergence (PCD)","text":"<p>PCD maintains a buffer of negative samples across training iterations, which can lead to better mixing. You can enable it by setting <code>persistent=True</code>.</p> <pre><code>loss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=10,\n    persistent=True,\n    buffer_size=1024\n)\n</code></pre>"},{"location":"tutorials/loss_functions/#using-schedulers-for-sampling-parameters","title":"Using Schedulers for Sampling Parameters","text":"<p>You can use schedulers to dynamically adjust the sampler's step size or noise scale during training:</p> <pre><code>from torchebm.core import CosineScheduler, ExponentialDecayScheduler, LinearScheduler\n\nstep_size_scheduler = CosineScheduler(\n    start_value=3e-2,\n    end_value=5e-3,\n    n_steps=100\n)\n\nnoise_scheduler = CosineScheduler(\n    start_value=3e-1,\n    end_value=1e-2,\n    n_steps=100\n)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=step_size_scheduler,\n    noise_scale=noise_scheduler,\n    device=device\n)\n\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=10,\n    persistent=True\n)\n</code></pre>"},{"location":"tutorials/loss_functions/#score-matching-methods","title":"Score Matching Methods","text":"<p>Score Matching is another approach for training EBMs that avoids the need for MCMC sampling. It directly optimizes the score function (gradient of log-density).</p>"},{"location":"tutorials/loss_functions/#score-matching","title":"Score Matching","text":"<p>This is the standard form of score matching, which requires computing the Hessian of the model's energy function. This can be computationally expensive.</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchebm.core import BaseModel\nfrom torchebm.losses import ScoreMatching\nfrom torchebm.datasets import GaussianMixtureDataset\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SiLU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SiLU(),\n            nn.Linear(hidden_dim, 1),\n        )\n\n    def forward(self, x):\n        return self.net(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MLPModel(input_dim=2).to(device)\n\nsm_loss_fn = ScoreMatching(\n    model=model,\n    device=device\n)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ndataset = GaussianMixtureDataset(n_samples=500, n_components=4, std=0.1, seed=123).get_data()\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nfor epoch in range(10):\n    epoch_loss = 0.0\n    for batch_data in dataloader:\n        batch_data = batch_data.to(device)\n\n        optimizer.zero_grad()\n        loss = sm_loss_fn(batch_data)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_loss = epoch_loss / len(dataloader)\n    print(f\"Epoch {epoch+1}/10, Loss: {avg_loss:.6f}\")\n</code></pre>"},{"location":"tutorials/loss_functions/#sliced-score-matching","title":"Sliced Score Matching","text":"<p>To make score matching more efficient and scalable, Sliced Score Matching (SSM) approximates the trace of the Hessian using Hutchinson's trick with random projections.</p> <pre><code>from torchebm.losses import SlicedScoreMatching\n\nssm_loss_fn = SlicedScoreMatching(\n    model=model,\n    n_projections=5\n)\noptimizer.zero_grad()\nloss = ssm_loss_fn(data_batch)\nloss.backward()\noptimizer.step()\n</code></pre>"},{"location":"tutorials/loss_functions/#denoising-score-matching","title":"Denoising Score Matching","text":"<p>Denoising score matching (DSM) is another efficient alternative. It adds noise to the data points and learns the score of the noised data distribution, avoiding the need to compute the Hessian.</p> <pre><code>from torchebm.losses import DenoisingScoreMatching\n\ndsm_loss_fn = DenoisingScoreMatching(\n    model=model,\n    sigma=0.1\n)\n\noptimizer.zero_grad()\nloss = dsm_loss_fn(data_batch)\nloss.backward()\noptimizer.step()\n</code></pre>"},{"location":"tutorials/loss_functions/#complete-training-example-with-loss-function","title":"Complete Training Example with Loss Function","text":"<p>Here's a complete example showing how to train an EBM using Contrastive Divergence loss:</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.losses import ContrastiveDivergence\nfrom torchebm.datasets import TwoMoonsDataset\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nINPUT_DIM = 2\nHIDDEN_DIM = 16\nBATCH_SIZE = 256\nEPOCHS = 100\nLEARNING_RATE = 1e-3\nCD_K = 10\nUSE_PCD = True\n\ndataset = TwoMoonsDataset(n_samples=3000, noise=0.05, seed=42, device=device)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n\nmodel = MLPModel(INPUT_DIM, HIDDEN_DIM).to(device)\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    device=device,\n)\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=CD_K,\n    persistent=USE_PCD,\n    buffer_size=BATCH_SIZE\n).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nlosses = []\nprint(\"Starting training...\")\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0.0\n\n    for i, data_batch in enumerate(dataloader):\n        optimizer.zero_grad()\n\n        loss, negative_samples = loss_fn(data_batch)\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_epoch_loss = epoch_loss / len(dataloader)\n    losses.append(avg_epoch_loss)\n    print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {avg_epoch_loss:.4f}\")\n\nplt.figure(figsize=(10, 6))\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('docs/assets/images/loss_functions/cd_training_loss.png')\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/loss_functions/#choosing-the-right-loss-function","title":"Choosing the Right Loss Function","text":"<p>Different loss functions are suitable for different scenarios:</p> <ul> <li>Contrastive Divergence: A good general-purpose method, especially for complex energy landscapes.</li> <li>Persistent CD: Can provide better mixing properties than standard CD, but requires more memory for the replay buffer.</li> <li>Score Matching: Avoids MCMC sampling but can be numerically unstable and computationally expensive in high dimensions.</li> <li>Sliced Score Matching: A scalable and more stable version of Score Matching, suitable for high-dimensional data.</li> <li>Denoising Score Matching: More stable than standard score matching and computationally efficient, making it a good choice for many problems.</li> </ul>"},{"location":"tutorials/loss_functions/#tips-for-stable-training","title":"Tips for Stable Training","text":"<ol> <li>Regularization: Add L2 regularization to prevent the energy from collapsing.</li> <li>Gradient Clipping: Use <code>torch.nn.utils.clip_grad_norm_</code> to prevent unstable updates.</li> <li>Learning Rate: Use a small learning rate, especially at the beginning of training.</li> <li>Sampling Steps: Increase the number of sampling steps (<code>k_steps</code> in CD) for better quality negative samples.</li> <li>Batch Size: Use larger batch sizes for more stable gradient estimates.</li> <li>Parameter Schedulers: Use schedulers for sampler parameters to improve mixing during MCMC.</li> <li>Monitor Energy Values: Ensure the energy values for positive and negative samples do not collapse or diverge. </li> </ol>"},{"location":"tutorials/parallel_sampling/","title":"Parallel Sampling","text":""},{"location":"tutorials/parallel_sampling/#parallel-sampling","title":"Parallel Sampling","text":"<p>This guide explains how to efficiently sample from models in parallel using TorchEBM.</p>"},{"location":"tutorials/parallel_sampling/#overview","title":"Overview","text":"<p>Parallel sampling allows you to generate multiple samples simultaneously, leveraging modern hardware like GPUs for significant speedups. TorchEBM is designed for efficient parallel sampling, making it easy to generate thousands or even millions of samples with minimal code.</p>"},{"location":"tutorials/parallel_sampling/#basic-parallel-sampling","title":"Basic Parallel Sampling","text":"<p>The simplest way to perform parallel sampling is to initialize multiple chains and let TorchEBM handle the parallelization:</p> <pre><code>import torch\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\nimport torch.nn as nn\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MLPModel(input_dim=2, hidden_dim=32).to(device)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    noise_scale=0.01,\n    device=device\n)\n\nn_samples = 10000\ndim = 2\ninitial_points = torch.randn(n_samples, dim, device=device)\n\nsamples = sampler.sample(\n    x=initial_points,\n    n_steps=1000,\n    return_trajectory=False\n)\n\nprint(f\"Generated {samples.shape[0]} samples of dimension {samples.shape[1]}\")\n</code></pre>"},{"location":"tutorials/parallel_sampling/#gpu-acceleration","title":"GPU Acceleration","text":"<p>For maximum performance, TorchEBM leverages GPU acceleration when available. This provides dramatic speedups for parallel sampling:</p> <pre><code>import time\nimport torch\nfrom torchebm.core import DoubleWellModel\nfrom torchebm.samplers import LangevinDynamics\n\nmodel = DoubleWellModel()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.01,\n    device=device\n)\n\nn_samples = 50000\ndim = 2\n\ninitial_points = torch.randn(n_samples, dim, device=device)\n\nstart_time = time.time()\nsamples = sampler.sample(\n    x=initial_points,\n    n_steps=1000,\n    return_trajectory=False\n)\nend_time = time.time()\n\nprint(f\"Generated {n_samples} samples in {end_time - start_time:.2f} seconds\")\nprint(f\"Average time per sample: {(end_time - start_time) / n_samples * 1000:.4f} ms\")\n</code></pre>"},{"location":"tutorials/parallel_sampling/#batch-processing-for-large-sample-sets","title":"Batch Processing for Large Sample Sets","text":"<p>When generating a very large number of samples, you might need to process them in batches to avoid memory issues:</p> <pre><code>import torch\nimport numpy as np\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = MLPModel(input_dim=2, hidden_dim=64).to(device)\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.01,\n    device=device\n)\n\ntotal_samples = 1000000\ndim = 2\nbatch_size = 10000\nnum_batches = total_samples // batch_size\n\nall_samples = np.zeros((total_samples, dim))\n\nfor i in range(num_batches):\n    print(f\"Generating batch {i+1}/{num_batches}\")\n\n    initial_points = torch.randn(batch_size, dim, device=device)\n\n    batch_samples = sampler.sample(\n        x=initial_points,\n        n_steps=1000,\n        return_trajectory=False\n    )\n\n    start_idx = i * batch_size\n    end_idx = (i + 1) * batch_size\n    all_samples[start_idx:end_idx] = batch_samples.cpu().numpy()\n\nprint(f\"Generated {total_samples} samples in total\")\n</code></pre>"},{"location":"tutorials/parallel_sampling/#multi-gpu-sampling","title":"Multi-GPU Sampling","text":"<p>For even larger-scale sampling, you can distribute the workload across multiple GPUs:</p> <pre><code>import torch\nimport torch.multiprocessing as mp\nfrom torchebm.core import DoubleWellModel\nfrom torchebm.samplers import LangevinDynamics\n\ndef sample_on_device(rank, n_samples, n_steps, result_queue):\n    device = torch.device(f\"cuda:{rank}\" if torch.cuda.is_available() else \"cpu\")\n\n    model = DoubleWellModel().to(device)\n    sampler = LangevinDynamics(\n        model=model,\n        step_size=0.01,\n        device=device\n    )\n\n    initial_points = torch.randn(n_samples, 2, device=device)\n    samples = sampler.sample(\n        x=initial_points,\n        n_steps=n_steps,\n        return_trajectory=False\n    )\n\n    result_queue.put(samples.cpu())\n\ndef main():\n    n_gpus = torch.cuda.device_count()\n    if n_gpus == 0:\n        print(\"No GPUs available, using CPU\")\n        n_gpus = 1\n\n    print(f\"Using {n_gpus} device(s) for sampling\")\n\n    total_samples = 100000\n    samples_per_device = total_samples // n_gpus\n    n_steps = 1000\n\n    result_queue = mp.Queue()\n\n    processes = []\n    for rank in range(n_gpus):\n        p = mp.Process(\n            target=sample_on_device,\n            args=(rank, samples_per_device, n_steps, result_queue)\n        )\n        p.start()\n        processes.append(p)\n\n    all_samples = []\n    for _ in range(n_gpus):\n        all_samples.append(result_queue.get())\n\n    for p in processes:\n        p.join()\n\n    all_samples = torch.cat(all_samples, dim=0)\n    print(f\"Generated {all_samples.shape[0]} samples\")\n\nif __name__ == \"__main__\":\n    mp.set_start_method('spawn')\n    main()\n</code></pre>"},{"location":"tutorials/parallel_sampling/#performance-tips-for-parallel-sampling","title":"Performance Tips for Parallel Sampling","text":"<ol> <li> <p>Use the correct device: Always specify the device when creating samplers to ensure proper hardware acceleration.</p> </li> <li> <p>Batch size tuning: Find the optimal batch size for your hardware. Too small wastes parallelism, too large may cause memory issues.</p> </li> <li> <p>Data type optimization: Consider using <code>torch.float16</code> (half precision) for even faster sampling on compatible GPUs:</p> </li> </ol> <pre><code>initial_points = torch.randn(10000, 2, device=device, dtype=torch.float16)\nmodel = model.half()\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.01,\n    device=device\n)\nsamples = sampler.sample(x=initial_points, n_steps=1000)\n</code></pre> <ol> <li> <p>Minimize data transfers: Keep data on the GPU as much as possible. CPU-GPU transfers are slow.</p> </li> <li> <p>Pre-allocate memory: For repetitive sampling, reuse the same tensor to avoid repeated allocations.</p> </li> </ol>"},{"location":"tutorials/parallel_sampling/#conclusion","title":"Conclusion","text":"<p>Parallel sampling in TorchEBM allows you to efficiently generate large numbers of samples from your energy-based models. By leveraging GPU acceleration and batch processing, you can significantly speed up sampling, enabling more efficient model evaluation and complex applications.</p> <p>Whether you're generating samples for visualization, evaluation, or downstream tasks, TorchEBM's parallel sampling capabilities provide the performance and scalability you need. </p>"},{"location":"tutorials/samplers/","title":"Samplers","text":""},{"location":"tutorials/samplers/#sampling-algorithms","title":"Sampling Algorithms","text":"<p>Sampling from energy-based models is a core task in TorchEBM. This guide explains the different sampling algorithms available and how to use them effectively.</p>"},{"location":"tutorials/samplers/#overview-of-sampling","title":"Overview of Sampling","text":"<p>In energy-based models, we need to sample from the probability distribution defined by the model:</p> \\[p(x) = \\frac{e^{-E(x)}}{Z}\\] <p>Since the normalizing constant Z is typically intractable, we use Markov Chain Monte Carlo (MCMC) methods to generate samples without needing to compute Z.</p>"},{"location":"tutorials/samplers/#langevin-dynamics","title":"Langevin Dynamics","text":"<p>Langevin Dynamics is a gradient-based MCMC method that updates samples using the energy gradient plus Gaussian noise. It's one of the most commonly used samplers in energy-based models due to its simplicity and effectiveness.</p>"},{"location":"tutorials/samplers/#basic-usage","title":"Basic Usage","text":"<pre><code>import torch\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\nimport torch.nn as nn\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\nmodel = MLPModel(input_dim=2, hidden_dim=32)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nlangevin_sampler = LangevinDynamics(\n    model=model,\n    step_size=0.1,\n    noise_scale=0.01,\n    device=device\n)\n\ninitial_points = torch.randn(100, 2, device=device)\nsamples = langevin_sampler.sample(\n    x=initial_points,\n    n_steps=1000,\n    return_trajectory=False\n)\n\nprint(samples.shape)\n</code></pre>"},{"location":"tutorials/samplers/#parameters","title":"Parameters","text":"<ul> <li><code>model</code>: The model to sample from</li> <li><code>step_size</code>: Step size for gradient updates (controls exploration vs. stability)</li> <li><code>noise_scale</code>: Scale of the noise (default is sqrt(2*step_size))</li> <li><code>device</code>: The device to perform sampling on (e.g., \"cuda\" or \"cpu\")</li> </ul>"},{"location":"tutorials/samplers/#advanced-features","title":"Advanced Features","text":"<p>The <code>LangevinDynamics</code> sampler in TorchEBM comes with several advanced features:</p>"},{"location":"tutorials/samplers/#returning-trajectories","title":"Returning Trajectories","text":"<p>For visualization or analysis, you can get the full trajectory of the sampling process:</p> <pre><code>trajectory = langevin_sampler.sample(\n    x=initial_points,\n    n_steps=1000,\n    return_trajectory=True\n)\n\nprint(trajectory.shape)  # Shape: [n_samples, n_steps, dim]\n</code></pre>"},{"location":"tutorials/samplers/#dynamic-parameter-scheduling","title":"Dynamic Parameter Scheduling","text":"<p>TorchEBM allows you to dynamically adjust the step size and noise scale during sampling using schedulers:</p> <pre><code>from torchebm.core import CosineScheduler, LinearScheduler, ExponentialDecayScheduler\n\nstep_size_scheduler = CosineScheduler(\n    start_value=3e-2,\n    end_value=5e-3,\n    n_steps=100\n)\n\nnoise_scheduler = CosineScheduler(\n    start_value=3e-1,\n    end_value=1e-2,\n    n_steps=100\n)\n\ndynamic_sampler = LangevinDynamics(\n    model=model,\n    step_size=step_size_scheduler,\n    noise_scale=noise_scheduler,\n    device=device\n)\n</code></pre>"},{"location":"tutorials/samplers/#hamiltonian-monte-carlo-hmc","title":"Hamiltonian Monte Carlo (HMC)","text":"<p>HMC uses Hamiltonian dynamics to make more efficient proposals, leading to better exploration of the distribution:</p> <pre><code>from torchebm.samplers import HamiltonianMonteCarlo\nfrom torchebm.core import DoubleWellModel\n\nmodel = DoubleWellModel()\n\nhmc_sampler = HamiltonianMonteCarlo(\n    model=model,\n    step_size=0.1,\n    n_leapfrog_steps=10,\n    device=device\n)\n\nsamples = hmc_sampler.sample(\n    x=torch.randn(100, 2, device=device),\n    n_steps=500,\n    return_trajectory=False\n)\n</code></pre>"},{"location":"tutorials/samplers/#integration-with-loss-functions","title":"Integration with Loss Functions","text":"<p>Samplers in TorchEBM are designed to work seamlessly with loss functions for training energy-based models:</p> <pre><code>from torchebm.losses import ContrastiveDivergence\n\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=langevin_sampler,\n    k_steps=10,\n    persistent=True,\n    buffer_size=1024\n)\n\noptimizer.zero_grad()\nloss, negative_samples = loss_fn(data_batch)\nloss.backward()\noptimizer.step()\n</code></pre>"},{"location":"tutorials/samplers/#parallel-sampling","title":"Parallel Sampling","text":"<p>TorchEBM supports parallel sampling to speed up the generation of multiple samples:</p> <pre><code>n_samples = 1000\ndim = 2\ninitial_points = torch.randn(n_samples, dim, device=device)\n\nsamples = langevin_sampler.sample(\n    x=initial_points,\n    n_steps=1000,\n    return_trajectory=False\n)\n</code></pre>"},{"location":"tutorials/samplers/#sampler-visualizations","title":"Sampler Visualizations","text":"<p>Visualizing the sampling process can help understand the behavior of your model. Here's an example showing how to visualize Langevin Dynamics trajectories:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchebm.core import DoubleWellModel, LinearScheduler, WarmupScheduler\nfrom torchebm.samplers import LangevinDynamics\n\nmodel = DoubleWellModel(barrier_height=5.0)\n\nscheduler_linear = LinearScheduler(\n    initial_value=0.05,\n    final_value=0.03,\n    total_steps=100\n)\n\nscheduler = WarmupScheduler(\n    main_scheduler=scheduler_linear,\n    warmup_steps=10,\n    warmup_init_factor=0.01\n)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=scheduler\n\n)\n\ninitial_point = torch.tensor([[-2.0, 0.0]], dtype=torch.float32)\n\ntrajectory = sampler.sample(\n    x=initial_point,\n    dim=2,\n    n_steps=1000,\n    return_trajectory=True\n)\n\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = np.zeros_like(X)\n\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        point = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32).unsqueeze(0)\n        Z[i, j] = model(point).item()\n\nplt.figure(figsize=(10, 8))\nplt.contourf(X, Y, Z, 50, cmap='viridis', alpha=0.7)\nplt.colorbar(label='Energy')\n\ntraj_x = trajectory[0, :, 0].numpy()\ntraj_y = trajectory[0, :, 1].numpy()\n\nplt.plot(traj_x, traj_y, 'r-', linewidth=1, alpha=0.7)\nplt.scatter(traj_x[0], traj_y[0], c='black', s=50, marker='o', label='Start')\nplt.scatter(traj_x[-1], traj_y[-1], c='blue', s=50, marker='*', label='End')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Langevin Dynamics Trajectory')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.savefig('langevin_trajectory.png')\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/samplers/#choosing-a-sampler","title":"Choosing a Sampler","text":"<ul> <li>Langevin Dynamics: Good for general-purpose sampling, especially with neural network models</li> <li>Hamiltonian Monte Carlo: Better exploration of complex energy landscapes, but more computationally expensive</li> <li>Metropolis-Adjusted Langevin Algorithm (MALA): Similar to Langevin Dynamics but with an accept/reject step</li> </ul>"},{"location":"tutorials/samplers/#performance-tips","title":"Performance Tips","text":"<ol> <li>Use GPU acceleration: Batch processing of samples on GPU can significantly speed up sampling</li> <li>Adjust step size: Too large \u2192 unstable sampling; too small \u2192 slow mixing</li> <li>Dynamic scheduling: Use parameter schedulers to automatically adjust step size and noise during sampling</li> <li>Monitor energy values: Track energy values to ensure proper mixing and convergence 5**Multiple chains**: Run multiple chains from different starting points to better explore the distribution</li> </ol>"},{"location":"tutorials/samplers/#custom-samplers","title":"Custom Samplers","text":"<p>TorchEBM provides flexible base classes for creating your own custom sampling algorithms. All samplers inherit from the <code>BaseSampler</code> abstract base class which defines the core interfaces and functionalities.</p>"},{"location":"tutorials/samplers/#creating-a-custom-sampler","title":"Creating a Custom Sampler","text":"<p>To implement a custom sampler, you need to subclass <code>BaseSampler</code> and implement at minimum the <code>sample()</code> method:</p> <pre><code>from torchebm.core import BaseSampler, BaseModel\nimport torch\nfrom typing import Optional, Union, Tuple, List, Dict\n\nclass MyCustomSampler(BaseSampler):\n    def __init__(\n        self,\n        model: BaseModel,\n        my_parameter: float = 0.1,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super().__init__(model=model, dtype=dtype, device=device)\n        self.my_parameter = my_parameter\n\n        self.register_scheduler(\"my_parameter\", ConstantScheduler(my_parameter))\n\n    def custom_step(self, x: torch.Tensor) -&gt; torch.Tensor:\n        param_value = self.get_scheduled_value(\"my_parameter\")\n\n        gradient = self.model.gradient(x)\n\n        noise = torch.randn_like(x)\n        new_x = x - param_value * gradient + noise * 0.01\n\n        return new_x\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n        *args,\n        **kwargs,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        self.reset_schedulers()\n\n        if x is None:\n            x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n        else:\n            x = x.to(self.device)\n\n        if return_trajectory:\n            trajectory = torch.empty(\n                (n_samples, n_steps, dim), dtype=self.dtype, device=self.device\n            )\n\n        if return_diagnostics:\n            diagnostics = self._setup_diagnostics(dim, n_steps, n_samples=n_samples)\n\n        for i in range(n_steps):\n            self.step_schedulers()\n\n            x = self.custom_step(x)\n\n            if return_trajectory:\n                trajectory[:, i, :] = x\n\n            if return_diagnostics:\n                pass\n\n        if return_trajectory:\n            if return_diagnostics:\n                return trajectory, diagnostics\n            return trajectory\n        if return_diagnostics:\n            return x, diagnostics\n        return x\n\n    def _setup_diagnostics(self, dim: int, n_steps: int, n_samples: int = None) -&gt; torch.Tensor:\n        \"\"\"Optional method to setup diagnostic storage\"\"\"\n        if n_samples is not None:\n            return torch.empty(\n                (n_steps, 3, n_samples, dim), device=self.device, dtype=self.dtype\n            )\n        else:\n            return torch.empty((n_steps, 3, dim), device=self.device, dtype=self.dtype)\n</code></pre>"},{"location":"tutorials/samplers/#key-components","title":"Key Components","text":"<p>When implementing a custom sampler, consider these key aspects:</p> <ol> <li> <p>Model: All samplers work with a model that defines the target distribution.</p> </li> <li> <p>Parameter Scheduling: Use the built-in scheduler system to manage parameters that change during sampling:    </p><pre><code>self.register_scheduler(\"step_size\", ConstantScheduler(0.01))\n\ncurrent_step_size = self.get_scheduled_value(\"step_size\")\n\nself.step_schedulers()\n</code></pre><p></p> </li> <li> <p>Device and Precision Management: The base class handles device placement and precision settings:    </p><pre><code>my_sampler = my_sampler.to(\"cuda:0\")\n</code></pre><p></p> </li> <li> <p>Diagnostics Collection: Implement <code>_setup_diagnostics()</code> to collect sampling statistics.</p> </li> </ol>"},{"location":"tutorials/samplers/#example-simplified-langevin-dynamics","title":"Example: Simplified Langevin Dynamics","text":"<p>Here's a simplified example of a Langevin dynamics sampler:</p> <pre><code>class SimpleLangevin(BaseSampler):\n    def __init__(\n        self,\n        model: BaseModel,\n        step_size: float = 0.01,\n        noise_scale: float = 1.0,\n        dtype: torch.dtype = torch.float32,\n        device: Optional[Union[str, torch.device]] = None,\n    ):\n        super().__init__(model=model, dtype=dtype, device=device)\n        self.register_scheduler(\"step_size\", ConstantScheduler(step_size))\n        self.register_scheduler(\"noise_scale\", ConstantScheduler(noise_scale))\n\n    def langevin_step(self, x: torch.Tensor) -&gt; torch.Tensor:\n        step_size = self.get_scheduled_value(\"step_size\")\n        noise_scale = self.get_scheduled_value(\"noise_scale\")\n\n        gradient = self.model.gradient(x)\n        noise = torch.randn_like(x)\n\n        new_x = (\n            x \n            - step_size * gradient \n            + torch.sqrt(torch.tensor(2.0 * step_size)) * noise_scale * noise\n        )\n        return new_x\n\n    @torch.no_grad()\n    def sample(\n        self,\n        x: Optional[torch.Tensor] = None,\n        dim: int = 10,\n        n_steps: int = 100,\n        n_samples: int = 1,\n        thin: int = 1,\n        return_trajectory: bool = False,\n        return_diagnostics: bool = False,\n    ) -&gt; Union[torch.Tensor, Tuple[torch.Tensor, List[dict]]]:\n        self.reset_schedulers()\n\n        if x is None:\n            x = torch.randn(n_samples, dim, dtype=self.dtype, device=self.device)\n        else:\n            x = x.to(self.device)\n\n        if return_trajectory:\n            trajectory = torch.empty(\n                (n_samples, n_steps, dim), dtype=self.dtype, device=self.device\n            )\n\n        for i in range(n_steps):\n            self.step_schedulers()\n            x = self.langevin_step(x)\n\n            if return_trajectory:\n                trajectory[:, i, :] = x\n\n        if return_trajectory:\n            return trajectory\n        return x\n</code></pre>"},{"location":"tutorials/samplers/#tips-for-custom-samplers","title":"Tips for Custom Samplers","text":"<ol> <li> <p>Performance: Use <code>@torch.no_grad()</code> for the sampling loop to disable gradient computation.</p> </li> <li> <p>GPU Compatibility: Handle device placement correctly, especially when generating random noise.</p> </li> <li> <p>Validation: Ensure your sampler works with simple distributions before moving to complex ones.</p> </li> <li> <p>Diagnostics: Implement helpful diagnostics to monitor convergence and sampling quality.</p> </li> <li> <p>Mixed Precision: For better performance on modern GPUs, use the built-in mixed precision support.</p> </li> </ol>"},{"location":"tutorials/training/","title":"Training EBMs","text":""},{"location":"tutorials/training/#training-energy-based-models","title":"Training Energy-Based Models","text":"<p>This guide covers the fundamental techniques for training energy-based models (EBMs) using TorchEBM. We'll explore various training methods, loss functions, and optimization strategies to help you effectively train your models.</p>"},{"location":"tutorials/training/#overview","title":"Overview","text":"<p>Training energy-based models involves estimating the parameters of a model such that the corresponding probability distribution matches a target data distribution. Unlike in traditional supervised learning, this is often an unsupervised task where the goal is to learn the underlying structure of the data.</p> <p>The training process typically involves:</p> <ol> <li>Defining a model (parameterized by a neural network or analytical form)</li> <li>Choosing a training method and loss function</li> <li>Optimizing the model parameters</li> <li>Evaluating the model using sampling and visualization techniques</li> </ol>"},{"location":"tutorials/training/#defining-a-model","title":"Defining a Model","text":"<p>In TorchEBM, you can create custom models by subclassing <code>BaseModel</code>:</p> <pre><code>import torch\nimport torch.nn as nn\nfrom torchebm.core import BaseModel\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim: int, hidden_dim: int = 64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        return self.network(x).squeeze(-1)\n</code></pre>"},{"location":"tutorials/training/#training-with-contrastive-divergence","title":"Training with Contrastive Divergence","text":"<p>Contrastive Divergence (CD) is one of the most common methods for training EBMs. Here's a complete example of training with CD using TorchEBM:</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport os\n\nfrom torchebm.core import BaseModel, CosineScheduler\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.losses import ContrastiveDivergence\nfrom torchebm.datasets import TwoMoonsDataset\n\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(42)\n\nos.makedirs(\"training_plots\", exist_ok=True)\n\nINPUT_DIM = 2\nHIDDEN_DIM = 16\nBATCH_SIZE = 256\nEPOCHS = 200\nLEARNING_RATE = 1e-3\n\nSAMPLER_STEP_SIZE = CosineScheduler(start_value=3e-2, end_value=5e-3, n_steps=100)\nSAMPLER_NOISE_SCALE = CosineScheduler(start_value=3e-1, end_value=1e-2, n_steps=100)\n\nCD_K = 10\nUSE_PCD = True\nVISUALIZE_EVERY = 20\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\ndataset = TwoMoonsDataset(n_samples=3000, noise=0.05, seed=42, device=device)\nreal_data_for_plotting = dataset.get_data()\ndataloader = DataLoader(\n    dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n)\n\nmodel = MLPModel(INPUT_DIM, HIDDEN_DIM).to(device)\nsampler = LangevinDynamics(\n    model=model,\n    step_size=SAMPLER_STEP_SIZE,\n    noise_scale=SAMPLER_NOISE_SCALE,\n    device=device,\n)\nloss_fn = ContrastiveDivergence(\n    model=model,\n    sampler=sampler,\n    k_steps=CD_K,\n    persistent=USE_PCD,\n    buffer_size=BATCH_SIZE,\n).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\nlosses = []\nprint(\"Starting training...\")\nfor epoch in range(EPOCHS):\n    model.train()\n    epoch_loss = 0.0\n\n    for i, data_batch in enumerate(dataloader):\n        optimizer.zero_grad()\n\n        loss, negative_samples = loss_fn(data_batch)\n\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_epoch_loss = epoch_loss / len(dataloader)\n    losses.append(avg_epoch_loss)\n    print(f\"Epoch [{epoch+1}/{EPOCHS}], Average Loss: {avg_epoch_loss:.4f}\")\n\n    if (epoch + 1) % VISUALIZE_EVERY == 0 or epoch == 0:\n        print(\"Generating visualization...\")\n        plot_energy_and_samples(\n            model=model,\n            real_samples=real_data_for_plotting,\n            sampler=sampler,\n            epoch=epoch + 1,\n            device=device,\n            plot_range=2.5,\n            k_sampling=200,\n        )\n\n# Plot the training loss\nplt.figure(figsize=(10, 6))\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.grid(True, alpha=0.3)\nplt.savefig('docs/assets/images/training/cd_training_loss.png')\nplt.show()\n</code></pre>"},{"location":"tutorials/training/#visualization-during-training","title":"Visualization During Training","text":"<p>It's important to visualize the model's progress during training. Here's a helper function to plot the energy landscape and samples:</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import BaseModel\nfrom torchebm.samplers import LangevinDynamics\n\n@torch.no_grad()\ndef plot_energy_and_samples(\n    model: BaseModel,\n    real_samples: torch.Tensor,\n    sampler: LangevinDynamics,\n    epoch: int,\n    device: torch.device,\n    grid_size: int = 100,\n    plot_range: float = 3.0,\n    k_sampling: int = 100,\n):\n    plt.figure(figsize=(8, 8))\n\n    x_coords = torch.linspace(-plot_range, plot_range, grid_size, device=device)\n    y_coords = torch.linspace(-plot_range, plot_range, grid_size, device=device)\n    xv, yv = torch.meshgrid(x_coords, y_coords, indexing=\"xy\")\n    grid = torch.stack([xv.flatten(), yv.flatten()], dim=1)\n\n    model.eval()\n    energy_values = model(grid).cpu().numpy().reshape(grid_size, grid_size)\n\n    log_prob_values = -energy_values\n    log_prob_values = log_prob_values - np.max(log_prob_values)\n    prob_density = np.exp(log_prob_values)\n\n    plt.contourf(\n        xv.cpu().numpy(),\n        yv.cpu().numpy(),\n        prob_density,\n        levels=50,\n        cmap=\"viridis\",\n    )\n    plt.colorbar(label=\"exp(-Energy) (unnormalized density)\")\n\n    vis_start_noise = torch.randn(\n        500, real_samples.shape[1], device=device\n    )\n    model_samples_tensor = sampler.sample(x=vis_start_noise, n_steps=k_sampling)\n    model_samples = model_samples_tensor.cpu().numpy()\n\n    real_samples_np = real_samples.cpu().numpy()\n    plt.scatter(\n        real_samples_np[:, 0],\n        real_samples_np[:, 1],\n        s=10,\n        alpha=0.5,\n        label=\"Real Data\",\n        c=\"white\",\n        edgecolors=\"k\",\n        linewidths=0.5,\n    )\n    plt.scatter(\n        model_samples[:, 0],\n        model_samples[:, 1],\n        s=10,\n        alpha=0.5,\n        label=\"Model Samples\",\n        c=\"red\",\n        edgecolors=\"darkred\",\n        linewidths=0.5,\n    )\n\n    plt.xlim(-plot_range, plot_range)\n    plt.ylim(-plot_range, plot_range)\n    plt.title(f\"Epoch {epoch}\")\n    plt.xlabel(\"X1\")\n    plt.ylabel(\"X2\")\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.savefig(f\"docs/assets/images/training/ebm_training_epoch_{epoch}.png\")\n    plt.close()\n</code></pre>"},{"location":"tutorials/training/#training-with-score-matching","title":"Training with Score Matching","text":"<p>An alternative to Contrastive Divergence is Score Matching, which doesn't require MCMC sampling:</p> <pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\n\nfrom torchebm.core import BaseModel\nfrom torchebm.losses import ScoreMatching\nfrom torchebm.datasets import GaussianMixtureDataset\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = MLPModel(input_dim=2).to(device)\nsm_loss_fn = ScoreMatching(\n    model=model,\n    hessian_method=\"hutchinson\",\n    hutchinson_samples=5,\n    device=device,\n)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\ndataset = GaussianMixtureDataset(\n    n_samples=500, n_components=4, std=0.1, seed=123\n).get_data()\ndataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nlosses = []\nfor epoch in range(50):\n    epoch_loss = 0.0\n    for batch_data in dataloader:\n        batch_data = batch_data.to(device)\n\n        optimizer.zero_grad()\n        loss = sm_loss_fn(batch_data)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_loss = epoch_loss / len(dataloader)\n    losses.append(avg_loss)\n    print(f\"Epoch {epoch+1}/50, Loss: {avg_loss:.6f}\")\n\n# Plot the training loss\nplt.figure(figsize=(10, 6))\nplt.plot(losses)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Score Matching Training Loss')\nplt.grid(True, alpha=0.3)\nplt.savefig('docs/assets/images/training/sm_training_loss.png')\nplt.show()\n</code></pre>"},{"location":"tutorials/training/#comparing-training-methods","title":"Comparing Training Methods","text":"<p>Here's how the major training methods for EBMs compare:</p> Method Pros Cons Best For Contrastive Divergence (CD) - Simple to implement- Computationally efficient- Works well for simple distributions - May not converge to true gradient- Limited mode exploration with short MCMC runs- Can lead to poor samples Restricted Boltzmann Machines, simpler energy-based models Persistent CD (PCD) - Better mode exploration than CD- More accurate gradient estimation- Improved sample quality - Requires maintaining persistent chains- Can be unstable with high learning rates- Chains can get stuck in metastable states Deep Boltzmann Machines, models with complex energy landscapes Score Matching - Avoids MCMC sampling- Consistent estimator- Stable optimization - Requires computing Hessian diagonals- High computational cost in high dimensions- Need for second derivatives Continuous data, models with tractable derivatives Denoising Score Matching - Avoids explicit Hessian computation- More efficient than standard score matching- Works well for high-dimensional data - Performance depends on noise distribution- Trade-off between noise level and estimation accuracy- May smooth out important details Image modeling, high-dimensional continuous distributions Sliced Score Matching - Linear computational complexity- No Hessian computation needed- Scales well to high dimensions - Approximation depends on number of projections- Less accurate with too few random projections- Still requires gradient computation High-dimensional problems where other score matching variants are too expensive"},{"location":"tutorials/training/#advanced-training-techniques","title":"Advanced Training Techniques","text":""},{"location":"tutorials/training/#gradient-clipping","title":"Gradient Clipping","text":"<p>Gradient clipping is essential for stable EBM training:</p> <pre><code>torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\noptimizer.step()\n</code></pre>"},{"location":"tutorials/training/#regularization-techniques","title":"Regularization Techniques","text":"<p>Adding regularization can help stabilize training:</p> <pre><code>weight_decay = 1e-4\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=weight_decay)\n\nfrom torch.nn.utils import spectral_norm\n\nclass RegularizedMLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            spectral_norm(nn.Linear(input_dim, hidden_dim)),\n            nn.ReLU(),\n            spectral_norm(nn.Linear(hidden_dim, hidden_dim)),\n            nn.ReLU(),\n            spectral_norm(nn.Linear(hidden_dim, 1))\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n</code></pre>"},{"location":"tutorials/training/#tips-for-successful-training","title":"Tips for Successful Training","text":"<ol> <li>Start Simple: Begin with a simple model and dataset, then increase complexity</li> <li>Monitor Energy Values: Watch for energy collapse (very negative values) which indicates instability</li> <li>Adjust Sampling Parameters: Tune MCMC step size and noise scale for effective exploration</li> <li>Use Persistent CD: For complex distributions, persistent CD often yields better results</li> <li>Visualize Frequently: Regularly check the energy landscape and samples to track progress</li> <li>Gradient Clipping: Always use gradient clipping to prevent explosive gradients</li> <li>Parameter Scheduling: Use schedulers for learning rate, step size, and noise scale</li> <li>Batch Normalization: Consider adding batch normalization in your energy network</li> <li>Ensemble Methods: Train multiple models and ensemble their predictions for better results</li> <li>Patience: EBM training can be challenging - be prepared to experiment with hyperparameters </li> </ol>"},{"location":"tutorials/visualization/","title":"Visualization","text":""},{"location":"tutorials/visualization/#visualization-in-torchebm","title":"Visualization in TorchEBM","text":"<p>Data visualization is an essential tool for understanding, analyzing, and communicating the behavior of energy-based models. This guide covers various visualization techniques available in TorchEBM to help you gain insights into energy landscapes, sampling processes, and model performance.</p>"},{"location":"tutorials/visualization/#energy-landscape-visualization","title":"Energy Landscape Visualization","text":"<p>Visualizing energy landscapes is crucial for understanding the structure of the probability distribution you're working with. TorchEBM provides utilities to create both 2D and 3D visualizations of models.</p>"},{"location":"tutorials/visualization/#basic-energy-landscape-visualization","title":"Basic Energy Landscape Visualization","text":"<p>Here's a simple example to visualize a 2D model:</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import DoubleWellModel\n\nmodel = DoubleWellModel(barrier_height=2.0)\n\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = np.zeros_like(X)\n\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        point = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32).unsqueeze(0)\n        Z[i, j] = model(point).item()\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\nsurf = ax.plot_surface(X, Y, Z, cmap='viridis', alpha=0.8)\nax.set_xlabel('x')\nax.set_ylabel('y')\nax.set_zlabel('Energy')\nax.set_title('Double Well Energy Landscape')\nplt.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/visualization/#visualizing-energy-as-probability-density","title":"Visualizing Energy as Probability Density","text":"<p>Often, it's more intuitive to visualize the probability density (exp(-Energy)) rather than the energy itself:</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import DoubleWellModel\n\nmodel = DoubleWellModel(barrier_height=2.0)\n\ngrid_size = 100\nplot_range = 3.0\nx_coords = np.linspace(-plot_range, plot_range, grid_size)\ny_coords = np.linspace(-plot_range, plot_range, grid_size)\nX, Y = np.meshgrid(x_coords, y_coords)\nZ = np.zeros_like(X)\n\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        point = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32).unsqueeze(0)\n        Z[i, j] = model(point).item()\n\nlog_prob_values = -Z\nlog_prob_values = log_prob_values - np.max(log_prob_values)\nprob_density = np.exp(log_prob_values)\nplt.figure(figsize=(10, 8))\ncontour = plt.contourf(X, Y, prob_density, levels=50, cmap='viridis')\nplt.colorbar(label='exp(-Energy) (unnormalized density)')\nplt.xlabel('X1')\nplt.ylabel('X2')\nplt.title('Double Well Probability Density')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/visualization/#sampling-trajectory-visualization","title":"Sampling Trajectory Visualization","text":"<p>Visualizing the trajectory of sampling algorithms can provide insights into their behavior and convergence properties.</p>"},{"location":"tutorials/visualization/#visualizing-langevin-dynamics-trajectories","title":"Visualizing Langevin Dynamics Trajectories","text":"<pre><code>from torchebm.core import DoubleWellModel, LinearScheduler, WarmupScheduler\nfrom torchebm.samplers import LangevinDynamics\n\nmodel = DoubleWellModel(barrier_height=5.0)\n\nscheduler_linear = LinearScheduler(\n    initial_value=0.05,\n    final_value=0.03,\n    total_steps=100\n)\n\nscheduler = WarmupScheduler(\n    main_scheduler=scheduler_linear,\n    warmup_steps=10,\n    warmup_init_factor=0.01\n)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=scheduler\n\n)\n\ninitial_point = torch.tensor([[-2.0, 0.0]], dtype=torch.float32)\n\ntrajectory = sampler.sample(\n    x=initial_point,\n    dim=2,\n    n_steps=1000,\n    return_trajectory=True\n)\n\nx = np.linspace(-3, 3, 100)\ny = np.linspace(-3, 3, 100)\nX, Y = np.meshgrid(x, y)\nZ = np.zeros_like(X)\n\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        point = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32).unsqueeze(0)\n        Z[i, j] = model(point).item()\n\nplt.figure(figsize=(10, 8))\nplt.contourf(X, Y, Z, 50, cmap='viridis', alpha=0.7)\nplt.colorbar(label='Energy')\n\ntraj_x = trajectory[0, :, 0].numpy()\ntraj_y = trajectory[0, :, 1].numpy()\n\nplt.plot(traj_x, traj_y, 'r-', linewidth=1, alpha=0.7)\nplt.scatter(traj_x[0], traj_y[0], c='black', s=50, marker='o', label='Start')\nplt.scatter(traj_x[-1], traj_y[-1], c='blue', s=50, marker='*', label='End')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Langevin Dynamics Trajectory')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.savefig('langevin_trajectory.png')\nplt.show()\n</code></pre>"},{"location":"tutorials/visualization/#visualizing-multiple-chains","title":"Visualizing Multiple Chains","text":"<pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import RastriginModel\nfrom torchebm.samplers import LangevinDynamics\n\ntorch.manual_seed(44)\nnp.random.seed(43)\n\nmodel = RastriginModel(a=10.0)\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.008\n)\n\ndim = 2\nn_steps = 1000\nnum_chains = 5\n\ninitial_points = torch.randn(num_chains, dim) * 3\n\ntrajectories = sampler.sample(\n    x=initial_points,\n    dim=dim,\n    n_samples=num_chains,\n    n_steps=n_steps,\n    return_trajectory=True\n)\n\nx = np.linspace(-5, 5, 100)\ny = np.linspace(-5, 5, 100)\nX, Y = np.meshgrid(x, y)\nZ = np.zeros_like(X)\nprint(trajectories.shape)\n\nfor i in range(X.shape[0]):\n    for j in range(X.shape[1]):\n        point = torch.tensor([X[i, j], Y[i, j]], dtype=torch.float32).unsqueeze(0)\n        Z[i, j] = model(point).item()\n\nplt.figure(figsize=(12, 10))\ncontour = plt.contourf(X, Y, Z, 50, cmap='viridis', alpha=0.7)\nplt.colorbar(label='Energy')\n\ncolors = ['red', 'blue', 'green', 'orange', 'purple']\nfor i in range(num_chains):\n    traj_x = trajectories[i, :, 0].numpy()\n    traj_y = trajectories[i, :, 1].numpy()\n\n    plt.plot(traj_x, traj_y, alpha=0.7, linewidth=1, c=colors[i],\n             label=f'Chain {i + 1}')\n\n    plt.scatter(traj_x[0], traj_y[0], c='black', s=50, marker='o')\n    plt.scatter(traj_x[-1], traj_y[-1], c=colors[i], s=100, marker='*')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Multiple Langevin Dynamics Sampling Chains on Rastrigin Potential')\nplt.legend()\nplt.tight_layout()\nplt.savefig('multiple_chains.png')\nplt.show()\n</code></pre>"},{"location":"tutorials/visualization/#distribution-visualization","title":"Distribution Visualization","text":"<p>Visualizing the distribution of samples can help assess the quality of your sampling algorithm.</p>"},{"location":"tutorials/visualization/#comparing-generated-samples-with-ground-truth","title":"Comparing Generated Samples with Ground Truth","text":"<pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy import stats\nfrom torchebm.core import GaussianModel\nfrom torchebm.samplers import LangevinDynamics\n\nmean = torch.tensor([1.0, -1.0])\ncov = torch.tensor([[1.0, 0.5], [0.5, 1.0]])\nmodel = GaussianModel(mean=mean, cov=cov)\n\nsampler = LangevinDynamics(\n    model=model,\n    step_size=0.01\n)\n\nn_samples = 5000\nburn_in = 200\n\nx = torch.randn(n_samples, 2)\n\nsamples = sampler.sample(\n    x=x,\n    n_steps=1000,\n    burn_in=burn_in,\n    return_trajectory=False\n)\n\nsamples_np = samples.numpy()\nmean_np = mean.numpy()\ncov_np = cov.numpy()\n\nx = np.linspace(-3, 5, 100)\ny = np.linspace(-5, 3, 100)\nX, Y = np.meshgrid(x, y)\npos = np.dstack((X, Y))\n\nrv = stats.multivariate_normal(mean_np, cov_np)\nZ = rv.pdf(pos)\n\nfig = plt.figure(figsize=(15, 5))\n\nax1 = fig.add_subplot(131)\nax1.contourf(X, Y, Z, 50, cmap='Blues')\nax1.set_title('Ground Truth Density')\nax1.set_xlabel('x')\nax1.set_ylabel('y')\n\nax2 = fig.add_subplot(132)\nh = ax2.hist2d(samples_np[:, 0], samples_np[:, 1], bins=50, cmap='Reds', density=True)\nplt.colorbar(h[3], ax=ax2, label='Density')\nax2.set_title('Sampled Distribution')\nax2.set_xlabel('x')\nax2.set_ylabel('y')\n\nax3 = fig.add_subplot(133)\nax3.scatter(samples_np[:, 0], samples_np[:, 1], alpha=0.5, s=3)\nax3.set_title('Sample Points')\nax3.set_xlabel('x')\nax3.set_ylabel('y')\nax3.set_xlim(ax2.get_xlim())\nax3.set_ylim(ax2.get_ylim())\n\nplt.tight_layout()\nplt.savefig('distribution_comparison_updated.png')\nplt.show()\n</code></pre>"},{"location":"tutorials/visualization/#energy-evolution-visualization","title":"Energy Evolution Visualization","text":"<p>Tracking how energy values evolve during sampling can help assess convergence.</p> <pre><code>import numpy as np\nimport torch\nimport matplotlib.pyplot as plt\nfrom torchebm.core import DoubleWellModel, GaussianModel, CosineScheduler\nfrom torchebm.samplers import LangevinDynamics\n\n\nSAMPLER_STEP_SIZE = CosineScheduler(\n    initial_value=1e-2, final_value=1e-3, total_steps=50\n)\n\nSAMPLER_NOISE_SCALE = CosineScheduler(\n    initial_value=2e-1, final_value=1e-2, total_steps=50\n)\n\nmodel = GaussianModel(mean=torch.tensor([0.0, 0.0]), cov=torch.eye(2) * 0.5)\nsampler = LangevinDynamics(\n    model=model,\n    step_size=SAMPLER_STEP_SIZE,\n    noise_scale=SAMPLER_NOISE_SCALE\n)\n\ndim = 2\nn_steps = 200\ninitial_point = torch.tensor([[-2.0, 0.0]], dtype=torch.float32)\n\nenergy_values = []\ncurrent_sample = initial_point.clone()\n\nfor i in range(n_steps):\n    noise = torch.randn_like(current_sample)\n    current_sample = sampler.langevin_step(current_sample, noise)\n    energy_values.append(model(current_sample).item())\n\nenergy_values_np = np.array(energy_values)\n\nplt.figure(figsize=(10, 6))\nplt.plot(energy_values_np)\nplt.xlabel('Step')\nplt.ylabel('Energy')\nplt.title('Energy Evolution During Langevin Dynamics Sampling')\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('energy_evolution_updated.png')\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/visualization/#visualizing-training-progress-with-different-loss-functions","title":"Visualizing Training Progress with Different Loss Functions","text":"<p>You can also visualize how different loss functions affect the training dynamics:</p> <pre><code>import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torchebm.core import BaseModel\nfrom torchebm.losses import ContrastiveDivergence, ScoreMatching\nfrom torchebm.samplers import LangevinDynamics\nfrom torchebm.datasets import TwoMoonsDataset\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass MLPModel(BaseModel):\n    def __init__(self, input_dim, hidden_dim=64):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.SELU(),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x).squeeze(-1)\n\ndef train_and_record_loss(loss_type, n_epochs=100):\n    model = MLPModel(input_dim=2, hidden_dim=32).to(device)\n\n    sampler = LangevinDynamics(\n        model=model,\n        step_size=0.1,\n        device=device\n    )\n\n    if loss_type == 'CD':\n        loss_fn = ContrastiveDivergence(\n            model=model,\n            sampler=sampler,\n            k_steps=10,\n            persistent=True\n        )\n    elif loss_type == 'SM':\n        loss_fn = ScoreMatching(\n            model=model,\n            hutchinson_samples=5\n        )\n\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    losses = []\n\n    for epoch in range(n_epochs):\n        epoch_loss = 0.0\n        for batch in dataloader:\n            optimizer.zero_grad()\n            loss = loss_fn(batch)\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n\n        avg_loss = epoch_loss / len(dataloader)\n        losses.append(avg_loss)\n        if (epoch + 1) % 10 == 0:\n            print(f\"{loss_type} - Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n\n    return losses\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndataset = TwoMoonsDataset(n_samples=1000, noise=0.1, device=device)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n\ncd_losses = train_and_record_loss('CD')\nsm_losses = train_and_record_loss('SM')\n\nplt.figure(figsize=(10, 6))\nplt.plot(cd_losses, label='Contrastive Divergence')\nplt.plot(sm_losses, label='Score Matching')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss Comparison')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('loss_comparison.png')\nplt.show()\n</code></pre> <p></p>"},{"location":"tutorials/visualization/#conclusion","title":"Conclusion","text":"<p>Effective visualization is key to understanding and debugging energy-based models. TorchEBM provides tools for visualizing energy landscapes, sampling trajectories, and model performance. These visualizations can help you gain insights into your models and improve their design and performance.</p> <p>Remember to adapt these examples to your specific needs - you might want to visualize higher-dimensional spaces using dimensionality reduction techniques, or create specialized plots for your particular application. </p>"},{"location":"blog/archive/2025/","title":"2025","text":""},{"location":"blog/archive/2025/#2025","title":"2025","text":""},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2024/#2024","title":"2024","text":""},{"location":"blog/category/research/","title":"Research","text":""},{"location":"blog/category/research/#research","title":"Research","text":""},{"location":"blog/category/tutorials/","title":"Tutorials","text":""},{"location":"blog/category/tutorials/#tutorials","title":"Tutorials","text":""},{"location":"blog/category/examples/","title":"Examples","text":""},{"location":"blog/category/examples/#examples","title":"Examples","text":""}]}